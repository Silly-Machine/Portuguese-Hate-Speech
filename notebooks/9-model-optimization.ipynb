{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unable warnings\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Directory adjustment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import os\n",
    "# Back to main folder\n",
    "path = os.path.dirname(os.getcwd())+\"/\"\n",
    "os.chdir(path)\n",
    "sys.path.append(path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETL\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import MultiIndex, Int64Index\n",
    "# ML preprocessing\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Natural language processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import spacy\n",
    "import re \n",
    "\n",
    "# Vectorization\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models import KeyedVectors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tracking\n",
    "from src.experiment.tracking import experiment\n",
    "\n",
    "# Pipe\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.control import version\n",
    "\n",
    "df_train, df_test = version().split(test_size=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set and split train and test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set target and features\n",
    "target = \"label\"\n",
    "features = \"text\"\n",
    "\n",
    "# Set train and test\n",
    "X_train, y_train = df_train[features], df_train[target]\n",
    "X_test, y_test = df_test[features], df_test[target]\n",
    "\n",
    "# Set k-fold criteria\n",
    "k_fold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "# Class weights\n",
    "pos = len(df_train.query(\"label==1\"))\n",
    "neg = len(df_train.query(\"label==0\"))\n",
    "\n",
    "weight_for_0 = (1 / neg) * (len(df_train) / 2.0)\n",
    "weight_for_1 = (1 / pos) * (len(df_train) / 2.0)\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model optimization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a classifier pipeline\n",
    "vectorizer = TfidfVectorizer(\n",
    "    lowercase=False,\n",
    "    analyzer=\"word\",\n",
    "    norm=\"l2\",\n",
    "    ngram_range=(1, 2),\n",
    "    max_features=1500,\n",
    "    min_df=5,\n",
    ")\n",
    "\n",
    "classifier = LinearSVC(\n",
    "    penalty=\"l2\",\n",
    "    loss=\"squared_hinge\",\n",
    "    dual=True,\n",
    "    tol=1e-6,\n",
    "    C=1.1,\n",
    "    multi_class=\"crammer_singer\",\n",
    "    fit_intercept=True,\n",
    "    intercept_scaling=1,\n",
    "    class_weight=class_weight,\n",
    "    random_state=42,\n",
    "    max_iter=1000,\n",
    ")\n",
    "\n",
    "ml_pipe = Pipeline([(\"vectorizer\", vectorizer), (\"classifier\", classifier)])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_list = [\n",
    "    {0: weight_for_0, 1: weight_for_1},\n",
    "    {0: weight_for_0, 1: weight_for_1 * 1.1},\n",
    "]\n",
    "\n",
    "grid_params = {\n",
    "    \"classifier__C\": [1.1],\n",
    "    \"classifier__class_weight\": weights_list,\n",
    "    \"vectorizer__analyzer\": [\"word\", \"char_wb\"],\n",
    "    \"vectorizer__ngram_range\": [(1, 2), (1, 5)],\n",
    "    \"vectorizer__max_features\": [1500, 2500],\n",
    "    \"vectorizer__sublinear_tf\": [True],\n",
    "    \"vectorizer__min_df\": [1, 2, 3],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:   0.7042666070483065\n",
      "Best Estimator:   Pipeline(steps=[('vectorizer',\n",
      "                 TfidfVectorizer(analyzer='char_wb', lowercase=False,\n",
      "                                 max_features=2500, min_df=2,\n",
      "                                 ngram_range=(1, 5), sublinear_tf=True)),\n",
      "                ('classifier',\n",
      "                 LinearSVC(C=1.1,\n",
      "                           class_weight={0: 0.7298340961098398,\n",
      "                                         1: 1.5877411325451152},\n",
      "                           multi_class='crammer_singer', random_state=42,\n",
      "                           tol=1e-06))])\n"
     ]
    }
   ],
   "source": [
    "# Parameters search\n",
    "grid = GridSearchCV(ml_pipe, grid_params, cv=k_fold, scoring=\"f1_weighted\")\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Score:  \", grid.best_score_)\n",
    "print(\"Best Estimator:  \", grid.best_estimator_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MLFLOW] [START] server already running\n",
      "[MLFLOW][EXECUTION] running experiment\n",
      "[MLFLOW][FINISHED] experiment executed successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.820728</td>\n",
       "      <td>0.547619</td>\n",
       "      <td>0.719577</td>\n",
       "      <td>0.684174</td>\n",
       "      <td>0.734509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.755155</td>\n",
       "      <td>0.642458</td>\n",
       "      <td>0.719577</td>\n",
       "      <td>0.698806</td>\n",
       "      <td>0.719577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.786577</td>\n",
       "      <td>0.591260</td>\n",
       "      <td>0.719577</td>\n",
       "      <td>0.688918</td>\n",
       "      <td>0.724916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>388.000000</td>\n",
       "      <td>179.000000</td>\n",
       "      <td>0.719577</td>\n",
       "      <td>567.000000</td>\n",
       "      <td>567.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0           1  accuracy   macro avg  weighted avg\n",
       "precision    0.820728    0.547619  0.719577    0.684174      0.734509\n",
       "recall       0.755155    0.642458  0.719577    0.698806      0.719577\n",
       "f1-score     0.786577    0.591260  0.719577    0.688918      0.724916\n",
       "support    388.000000  179.000000  0.719577  567.000000    567.000000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set experiment\n",
    "lab = experiment(\n",
    "    exp_name=\"Hate Speech\",\n",
    "    model_name=\"Linear SVC\",\n",
    "    model=grid.best_estimator_,\n",
    ")\n",
    "\n",
    "# Evaluate experiment\n",
    "y_pred = lab.run(X_train, y_train, X_test, y_test, predictions=True)\n",
    "pd.DataFrame(classification_report(y_test, y_pred, output_dict=True))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('hate-seepch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7304d3c1a35396b9e299acc644b89f0e56d4154029b20ed6ab08effb23ac070c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
