{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unable warnings\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Directory adjustment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import os\n",
    "# Back to main folder\n",
    "path = os.path.dirname(os.getcwd())+\"/\"\n",
    "os.chdir(path)\n",
    "sys.path.append(path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETL\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import MultiIndex, Int64Index\n",
    "# ML preprocessing\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Natural language processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import spacy\n",
    "import re \n",
    "\n",
    "# Vectorization\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models import KeyedVectors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipe\n",
    "from sklearn.pipeline import Pipeline\n",
    "# Models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "# Metrics\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from src.ModelAnalysis import ranking_recall\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set and split train and test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data\n",
    "df = pd.read_csv('data/corpus/augmented_corpus_fortuna.csv')\n",
    "\n",
    "# Set target and features\n",
    "target = 'label'\n",
    "features = 'text_stop'\n",
    "\n",
    "# Break apart dataset\n",
    "X = df[features].values.astype('U')\n",
    "y = df[target]\n",
    "\n",
    "\n",
    "# Split train abd test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Set k-fold criteria\n",
    "k_fold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "# Class weights\n",
    "pos = len(df.query('label==1'))\n",
    "neg = len(df.query('label==0'))\n",
    "weight_for_0 = (1 / neg) * (len(df) / 2.0)\n",
    "weight_for_1 = (1 / pos) * (len(df) / 2.0)*1.1\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model otimzation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.838415</td>\n",
       "      <td>0.525105</td>\n",
       "      <td>0.706349</td>\n",
       "      <td>0.681760</td>\n",
       "      <td>0.739780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.707851</td>\n",
       "      <td>0.703081</td>\n",
       "      <td>0.706349</td>\n",
       "      <td>0.705466</td>\n",
       "      <td>0.706349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.767620</td>\n",
       "      <td>0.601198</td>\n",
       "      <td>0.706349</td>\n",
       "      <td>0.684409</td>\n",
       "      <td>0.715228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>777.000000</td>\n",
       "      <td>357.000000</td>\n",
       "      <td>0.706349</td>\n",
       "      <td>1134.000000</td>\n",
       "      <td>1134.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0           1  accuracy    macro avg  weighted avg\n",
       "precision    0.838415    0.525105  0.706349     0.681760      0.739780\n",
       "recall       0.707851    0.703081  0.706349     0.705466      0.706349\n",
       "f1-score     0.767620    0.601198  0.706349     0.684409      0.715228\n",
       "support    777.000000  357.000000  0.706349  1134.000000   1134.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vectorizer\n",
    "vectorizer = TfidfVectorizer(lowercase=False,\n",
    "                             analyzer=\"word\",\n",
    "                             norm='l2',\n",
    "                             ngram_range=(1, 2),\n",
    "                             max_features=1500,\n",
    "                             min_df=5)\n",
    "\n",
    "classifier = LinearSVC(penalty='l2',\n",
    "                       loss='squared_hinge',\n",
    "                       dual=True,\n",
    "                       tol=1e-6, C=1.1,\n",
    "                       multi_class='crammer_singer',\n",
    "                       fit_intercept=True,\n",
    "                       intercept_scaling=1,\n",
    "                       class_weight=class_weight,\n",
    "                       random_state=42,\n",
    "                       max_iter=1000)\n",
    "\n",
    "# Pipe\n",
    "ml_pipe = Pipeline([('vectorizer', vectorizer),\n",
    "                    ('classifier', classifier)])\n",
    "\n",
    "# Train\n",
    "ml_pipe.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_predict = ml_pipe.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "report = classification_report(y_test, y_predict, output_dict=True)\n",
    "pd.DataFrame(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision 0.5251046025104602\n",
      "accuracy 0.7063492063492064\n",
      "recall 0.7030812324929971\n",
      "auc 0.7054659701718526\n",
      "f1 0.6011976047904192\n"
     ]
    }
   ],
   "source": [
    "print('precision', precision_score(y_test, y_predict))\n",
    "print('accuracy', accuracy_score(y_test, y_predict))\n",
    "print('recall', recall_score(y_test, y_predict))\n",
    "print('auc', roc_auc_score(y_test, y_predict))\n",
    "print('f1', f1_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# # Vectorizer\n",
    "# vectorizer = TfidfVectorizer(lowercase=False,\n",
    "#                              analyzer=\"word\",\n",
    "#                              norm='l2',\n",
    "#                              ngram_range=(1, 2),\n",
    "#                              max_features=1500)\n",
    "\n",
    "# # Models\n",
    "# classifier_1 = LinearSVC()\n",
    "\n",
    "# classifier_2 = DecisionTreeClassifier(\n",
    "#     random_state=42, class_weight=class_weight)\n",
    "\n",
    "\n",
    "# classifier_3 = RandomForestClassifier(\n",
    "#     random_state=42, class_weight=class_weight)\n",
    "# # Vote\n",
    "\n",
    "# models_vote = VotingClassifier(\n",
    "#     estimators=[('M1', classifier_1),\n",
    "#                 ('M2', classifier_2),\n",
    "#                 ('M3', classifier_3)],\n",
    "#     voting='hard')\n",
    "\n",
    "# # Pipe\n",
    "# ml_pipe = Pipeline([('vectorizer', vectorizer),\n",
    "#                     ('classifier', models_vote)])\n",
    "\n",
    "# # Train\n",
    "# ml_pipe.fit(X_train, y_train)\n",
    "\n",
    "# # Predict\n",
    "# y_predict = ml_pipe.predict(X_test)\n",
    "\n",
    "# # Evaluate\n",
    "# report = classification_report(y_test, y_predict, output_dict=True)\n",
    "# pd.DataFrame(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.experimental import enable_halving_search_cv\n",
    "# from sklearn.model_selection import HalvingGridSearchCV\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from sklearn import metrics\n",
    "# from sklearn.metrics import recall_score\n",
    "# from sklearn.utils.fixes import loguniform\n",
    "\n",
    "# # Set k-fold criteria\n",
    "# k_fold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "# scores = cross_val_score(ml_pipe, X, y, cv=k_fold)\n",
    "# print(f\"{scores.mean()} accuracy with a standard deviation of {scores.std()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_params = {'classifier__C': [0.5, 1.0, 1.5, 2.0, 2.5, 3],\n",
    "#                'classifier__penalty': ['l2'],\n",
    "#                'classifier__loss': ['hinge', 'squared_hinge'],\n",
    "#                'classifier__multi_class': ['ovr', 'crammer_singer'],\n",
    "#                'classifier__class_weight': [{1: 1, 0: 1}, class_weight]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Parameters search\n",
    "# grid = HalvingGridSearchCV(ml_pipe, grid_params, cv=k_fold)\n",
    "# grid.fit(X_train, y_train)\n",
    "# print(\"Best Score:  \", grid.best_score_)\n",
    "# # Pipe\n",
    "# # scores = cross_val_score(grid, X, y, cv=k_fold)\n",
    "# # print(f\"{scores.mean()} accuracy with a standard deviation of {scores.std()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Predict\n",
    "# y_predict = grid.predict(X_test)\n",
    "\n",
    "# # Evaluate\n",
    "# report = classification_report(y_test, y_predict, output_dict=True)\n",
    "# pd.DataFrame(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('hate-seepch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7304d3c1a35396b9e299acc644b89f0e56d4154029b20ed6ab08effb23ac070c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
