{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unable warnings\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Directory adjustment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Back to main folder\n",
    "path = os.path.dirname(os.getcwd()) + \"/\"\n",
    "os.chdir(path)\n",
    "sys.path.append(path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETL\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Natural language processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.TextVectorization import MeanEmbeddingVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from src.transformers.text import TextNormalizer\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim import models\n",
    "import gensim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tracking\n",
    "from src.experiment.tracking import experiment\n",
    "\n",
    "# ML preprocessing\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Pipe\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Deep neural network\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data version control (DVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.control import version\n",
    "\n",
    "df_train, df_test = version().split(test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data manipulation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set target and features\n",
    "target = \"label\"\n",
    "features = \"text\"\n",
    "\n",
    "# Set train and test\n",
    "X_train, y_train = df_train[features], df_train[target]\n",
    "X_test, y_test = df_test[features], df_test[target]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  MLP with Tf-idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text normalizer\n",
    "wordlist = [\n",
    "    \"nomeusuario\",\n",
    "    \"paginaweb\",\n",
    "    \"emailusario\",\n",
    "    \"numerotelefone\",\n",
    "    \"simbolomonetario\",\n",
    "]\n",
    "\n",
    "normalizer = TextNormalizer(\n",
    "    stopwords=True, wordlist=wordlist, stemmer=False, lemma=False\n",
    ")\n",
    "\n",
    "# Text vectorizer\n",
    "vectorizer = TfidfVectorizer(\n",
    "    lowercase=False,\n",
    "    analyzer=\"word\",\n",
    "    norm=\"l2\",\n",
    "    ngram_range=(1, 2),\n",
    "    max_features=1500,\n",
    "    sublinear_tf=True,\n",
    ")\n",
    "\n",
    "# Classfier\n",
    "classifier = MLPClassifier(\n",
    "    warm_start=True,\n",
    "    hidden_layer_sizes=(100),\n",
    "    activation=\"relu\",\n",
    "    solver=\"lbfgs\",\n",
    "    learning_rate=\"adaptive\",\n",
    "    random_state=42,\n",
    "    max_iter=30,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MLFLOW] [START] server already running\n",
      "[MLFLOW][EXECUTION] running experiment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/10/26 20:24:50 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-09-16; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'minhasoma'}\n",
      "2022/10/26 20:24:54 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-09-16; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'minhasoma'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MLFLOW][FINISHED] experiment executed successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.794903</td>\n",
       "      <td>0.606452</td>\n",
       "      <td>0.743386</td>\n",
       "      <td>0.700677</td>\n",
       "      <td>0.735576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.842986</td>\n",
       "      <td>0.526611</td>\n",
       "      <td>0.743386</td>\n",
       "      <td>0.684798</td>\n",
       "      <td>0.743386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.818239</td>\n",
       "      <td>0.563718</td>\n",
       "      <td>0.743386</td>\n",
       "      <td>0.690978</td>\n",
       "      <td>0.738112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>777.000000</td>\n",
       "      <td>357.000000</td>\n",
       "      <td>0.743386</td>\n",
       "      <td>1134.000000</td>\n",
       "      <td>1134.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0           1  accuracy    macro avg  weighted avg\n",
       "precision    0.794903    0.606452  0.743386     0.700677      0.735576\n",
       "recall       0.842986    0.526611  0.743386     0.684798      0.743386\n",
       "f1-score     0.818239    0.563718  0.743386     0.690978      0.738112\n",
       "support    777.000000  357.000000  0.743386  1134.000000   1134.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a classifier pipeline\n",
    "ml_pipe = Pipeline(\n",
    "    [(\"normalizer\", normalizer), (\"vectorizer\", vectorizer), (\"classifier\", classifier)]\n",
    ")\n",
    "# Set experiment\n",
    "lab = experiment(\n",
    "    exp_name=\"Hate Speech\",\n",
    "    model_name=\"MLP\",\n",
    "    model=ml_pipe,\n",
    ")\n",
    "# Evaluate experiment\n",
    "y_pred = lab.run(X_train, y_train, X_test, y_test, predictions=True)\n",
    "pd.DataFrame(classification_report(y_test, y_pred, output_dict=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP with word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a corpus\n",
    "corpus = X_train\n",
    "cores = multiprocessing.cpu_count()\n",
    "\n",
    "# Train a own word2vec model\n",
    "my_embedding_50d = gensim.models.Word2Vec(\n",
    "    corpus,\n",
    "    vector_size=50,\n",
    "    window=4,\n",
    "    min_count=10,\n",
    "    sg=1,\n",
    "    workers=cores - 1,\n",
    "    batch_words=10000,\n",
    "    alpha=0.1,\n",
    "    min_alpha=0.0001,\n",
    "    negative=20,\n",
    ")\n",
    "\n",
    "my_embedding_100d = gensim.models.Word2Vec(\n",
    "    corpus,\n",
    "    vector_size=50,\n",
    "    window=4,\n",
    "    min_count=10,\n",
    "    sg=1,\n",
    "    workers=cores - 1,\n",
    "    batch_words=10000,\n",
    "    alpha=0.1,\n",
    "    min_alpha=0.0001,\n",
    "    negative=20,\n",
    ")\n",
    "\n",
    "my_embedding_300d = gensim.models.Word2Vec(\n",
    "    corpus,\n",
    "    vector_size=300,\n",
    "    window=4,\n",
    "    min_count=10,\n",
    "    sg=1,\n",
    "    workers=cores - 1,\n",
    "    batch_words=10000,\n",
    "    alpha=0.1,\n",
    "    min_alpha=0.0001,\n",
    "    negative=20,\n",
    ")\n",
    "\n",
    "\n",
    "# Make embedding dictionary {token:vector}\n",
    "my_embedding_50d = dict(\n",
    "    zip(my_embedding_50d.wv.index_to_key, my_embedding_50d.wv.vectors)\n",
    ")\n",
    "\n",
    "my_embedding_100d = dict(\n",
    "    zip(my_embedding_100d.wv.index_to_key, my_embedding_100d.wv.vectors)\n",
    ")\n",
    "\n",
    "my_embedding_300d = dict(\n",
    "    zip(my_embedding_300d.wv.index_to_key, my_embedding_300d.wv.vectors)\n",
    ")\n",
    "\n",
    "# Embeddings\n",
    "embedding = {\n",
    "    \"skip_50\": my_embedding_50d,\n",
    "    \"skip_100\": my_embedding_100d,\n",
    "    \"skip_300\": my_embedding_300d,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi embedding test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MLFLOW] [START] server already running\n",
      "[MLFLOW][EXECUTION] running experiment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/10/26 20:25:16 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-09-16; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'minhasoma'}\n",
      "2022/10/26 20:25:21 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-09-16; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'minhasoma'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MLFLOW] [FINISHED] experiment executed successfully\n",
      "model:MLP_skip_50 - acc:0.7257495590828924 - rec:0.5686274509803921 - auc:0.683284124460595 - f1:0.5662482566248257 \n",
      "\n",
      "[MLFLOW] [START] server already running\n",
      "[MLFLOW][EXECUTION] running experiment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/10/26 20:25:35 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-09-16; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'minhasoma'}\n",
      "2022/10/26 20:25:40 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-09-16; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'minhasoma'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MLFLOW] [FINISHED] experiment executed successfully\n",
      "model:MLP_skip_100 - acc:0.7098765432098766 - rec:0.5742296918767507 - auc:0.6732152320387614 - f1:0.5548037889039241 \n",
      "\n",
      "[MLFLOW] [START] server already running\n",
      "[MLFLOW][EXECUTION] running experiment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/10/26 20:25:54 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-09-16; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'minhasoma'}\n",
      "2022/10/26 20:25:58 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-09-16; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'minhasoma'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MLFLOW] [FINISHED] experiment executed successfully\n",
      "model:MLP_skip_300 - acc:0.6922398589065256 - rec:0.5658263305322129 - auc:0.6580740404269816 - f1:0.5365205843293491 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for embedding_name, w2v in embedding.items():\n",
    "\n",
    "    # Build pipeline\n",
    "    temp_pipe = Pipeline(\n",
    "        [\n",
    "            (\"normalizer\", normalizer),\n",
    "            (\"vectorizer\", MeanEmbeddingVectorizer(w2v)),\n",
    "            (\"classifier\", classifier),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # Set experiment\n",
    "    lab = experiment(\n",
    "        exp_name=\"Hate Speech\",\n",
    "        model_name=f\"MLP_{embedding_name}\",\n",
    "        model=ml_pipe,\n",
    "    )\n",
    "\n",
    "    # Evaluate experiment\n",
    "    y_pred = lab.run(X_train, y_train, X_test, y_test, predictions=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('hate-seepch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7304d3c1a35396b9e299acc644b89f0e56d4154029b20ed6ab08effb23ac070c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
