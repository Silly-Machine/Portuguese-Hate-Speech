{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unable warnings\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Directory adjustment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Back to main folder\n",
    "path = os.path.dirname(os.getcwd()) + \"/\"\n",
    "os.chdir(path)\n",
    "sys.path.append(path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETL\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Natural language processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from gensim import models\n",
    "import gensim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML preprocessing\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Deep learnig model\n",
    "#from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.pipeline import Pipeline\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Bidirectional\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Train  metrics\n",
    "METRICS = [\n",
    "    tf.keras.metrics.TruePositives(name='tp'),\n",
    "    tf.keras.metrics.FalsePositives(name='fp'),\n",
    "    tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "    tf.keras.metrics.FalseNegatives(name='fn'),\n",
    "    tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "    tf.keras.metrics.Precision(name='precision'),\n",
    "    tf.keras.metrics.Recall(name='recall'),\n",
    "    tf.keras.metrics.AUC(name='auc'),\n",
    "    tf.keras.metrics.AUC(name='prc', curve='PR'),  # precision-recall curve\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='./artifacts/1', creation_time=1665929754799, experiment_id='1', last_update_time=1665929754799, lifecycle_stage='active', name='Hate Speech', tags={}>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "mlflow.set_tracking_uri('http://127.0.0.1:5000')\n",
    "mlflow.set_experiment('Hate Speech')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data\n",
    "df = pd.read_csv(\"data/corpus/augmented_corpus_fortuna.csv\")\n",
    "\n",
    "# Set target and features\n",
    "target = \"label\"\n",
    "features = \"text_nonstop\"\n",
    "count = f\"length_{features}\"\n",
    "pos = len(df.query('label==1'))\n",
    "neg = len(df.query('label==0'))\n",
    "\n",
    "\n",
    "# Break apart dataset\n",
    "X = df[features].values.astype(\"U\")\n",
    "y = df[target]\n",
    "\n",
    "# Split train abd test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Set k-fold criteria\n",
    "k_fold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Classes balancing\n",
    "longest_text = df[count].max()\n",
    "initial_bias = np.log([pos/neg])\n",
    "\n",
    "weight_for_0 = (1 / neg) * (len(df) / 2.0)\n",
    "weight_for_1 = (1 / pos) * (len(df) / 2.0)\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preset parameters\n",
    "experiment_parameters = {\"classifier\": \"LSTM\",\n",
    "                         \"class_weight\": class_weight,\n",
    "                         \"epochs\": 200,\n",
    "                         \"units\": 50,\n",
    "                         \"dropout\": 0.4,\n",
    "                         \"recurrent_dropout\": 0.2,\n",
    "                         \"kernel_initializer\": 'glorot_uniform',\n",
    "                         \"loss\": \"binary_crossentropy\",\n",
    "                         \"optimizer\": \"adamax\",\n",
    "                         \"batch_size\": 64}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import TextVectorization\n",
    "from keras.layers import Input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TextVectorization(max_tokens=1500, standardize=\"lower_and_strip_punctuation\",\n",
    "                                     split=\"whitespace\", output_mode=\"tf-idf\", ngrams=(1, 2))\n",
    "tfidf_vectorizer.adapt(X_train, batch_size=32)\n",
    "vocab = tfidf_vectorizer.get_vocabulary()\n",
    "out = tfidf_vectorizer(X_train[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "71/71 [==============================] - 2s 12ms/step - loss: 0.8993 - tp: 456.0000 - fp: 818.0000 - tn: 2289.0000 - fn: 973.0000 - accuracy: 0.6052 - precision: 0.3579 - recall: 0.3191 - auc: 0.5247 - prc: 0.3378 - val_loss: 0.5866 - val_tp: 79.0000 - val_fp: 25.0000 - val_tn: 752.0000 - val_fn: 278.0000 - val_accuracy: 0.7328 - val_precision: 0.7596 - val_recall: 0.2213 - val_auc: 0.6626 - val_prc: 0.5294\n",
      "Epoch 2/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.7109 - tp: 614.0000 - fp: 678.0000 - tn: 2429.0000 - fn: 815.0000 - accuracy: 0.6709 - precision: 0.4752 - recall: 0.4297 - auc: 0.6319 - prc: 0.4611 - val_loss: 0.5626 - val_tp: 107.0000 - val_fp: 45.0000 - val_tn: 732.0000 - val_fn: 250.0000 - val_accuracy: 0.7399 - val_precision: 0.7039 - val_recall: 0.2997 - val_auc: 0.7049 - val_prc: 0.5744\n",
      "Epoch 3/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.6543 - tp: 626.0000 - fp: 534.0000 - tn: 2573.0000 - fn: 803.0000 - accuracy: 0.7052 - precision: 0.5397 - recall: 0.4381 - auc: 0.6728 - prc: 0.5038 - val_loss: 0.5616 - val_tp: 112.0000 - val_fp: 43.0000 - val_tn: 734.0000 - val_fn: 245.0000 - val_accuracy: 0.7460 - val_precision: 0.7226 - val_recall: 0.3137 - val_auc: 0.7152 - val_prc: 0.5833\n",
      "Epoch 4/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.5724 - tp: 725.0000 - fp: 463.0000 - tn: 2644.0000 - fn: 704.0000 - accuracy: 0.7427 - precision: 0.6103 - recall: 0.5073 - auc: 0.7400 - prc: 0.5889 - val_loss: 0.5535 - val_tp: 125.0000 - val_fp: 54.0000 - val_tn: 723.0000 - val_fn: 232.0000 - val_accuracy: 0.7478 - val_precision: 0.6983 - val_recall: 0.3501 - val_auc: 0.7281 - val_prc: 0.5875\n",
      "Epoch 5/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.5418 - tp: 744.0000 - fp: 399.0000 - tn: 2708.0000 - fn: 685.0000 - accuracy: 0.7610 - precision: 0.6509 - recall: 0.5206 - auc: 0.7651 - prc: 0.6144 - val_loss: 0.5520 - val_tp: 132.0000 - val_fp: 57.0000 - val_tn: 720.0000 - val_fn: 225.0000 - val_accuracy: 0.7513 - val_precision: 0.6984 - val_recall: 0.3697 - val_auc: 0.7338 - val_prc: 0.5933\n",
      "Epoch 6/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.4920 - tp: 772.0000 - fp: 344.0000 - tn: 2763.0000 - fn: 657.0000 - accuracy: 0.7793 - precision: 0.6918 - recall: 0.5402 - auc: 0.8018 - prc: 0.6772 - val_loss: 0.5497 - val_tp: 169.0000 - val_fp: 97.0000 - val_tn: 680.0000 - val_fn: 188.0000 - val_accuracy: 0.7487 - val_precision: 0.6353 - val_recall: 0.4734 - val_auc: 0.7446 - val_prc: 0.5913\n",
      "Epoch 7/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.4680 - tp: 819.0000 - fp: 330.0000 - tn: 2777.0000 - fn: 610.0000 - accuracy: 0.7928 - precision: 0.7128 - recall: 0.5731 - auc: 0.8254 - prc: 0.7091 - val_loss: 0.5508 - val_tp: 155.0000 - val_fp: 89.0000 - val_tn: 688.0000 - val_fn: 202.0000 - val_accuracy: 0.7434 - val_precision: 0.6352 - val_recall: 0.4342 - val_auc: 0.7441 - val_prc: 0.5901\n",
      "Epoch 8/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.4333 - tp: 873.0000 - fp: 298.0000 - tn: 2809.0000 - fn: 556.0000 - accuracy: 0.8117 - precision: 0.7455 - recall: 0.6109 - auc: 0.8507 - prc: 0.7524 - val_loss: 0.5592 - val_tp: 180.0000 - val_fp: 124.0000 - val_tn: 653.0000 - val_fn: 177.0000 - val_accuracy: 0.7346 - val_precision: 0.5921 - val_recall: 0.5042 - val_auc: 0.7475 - val_prc: 0.5869\n",
      "Epoch 9/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.3980 - tp: 881.0000 - fp: 246.0000 - tn: 2861.0000 - fn: 548.0000 - accuracy: 0.8250 - precision: 0.7817 - recall: 0.6165 - auc: 0.8797 - prc: 0.7894 - val_loss: 0.5563 - val_tp: 170.0000 - val_fp: 97.0000 - val_tn: 680.0000 - val_fn: 187.0000 - val_accuracy: 0.7496 - val_precision: 0.6367 - val_recall: 0.4762 - val_auc: 0.7459 - val_prc: 0.5882\n",
      "Epoch 10/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.3908 - tp: 917.0000 - fp: 238.0000 - tn: 2869.0000 - fn: 512.0000 - accuracy: 0.8347 - precision: 0.7939 - recall: 0.6417 - auc: 0.8857 - prc: 0.7980 - val_loss: 0.5610 - val_tp: 157.0000 - val_fp: 87.0000 - val_tn: 690.0000 - val_fn: 200.0000 - val_accuracy: 0.7469 - val_precision: 0.6434 - val_recall: 0.4398 - val_auc: 0.7422 - val_prc: 0.5869\n",
      "Epoch 11/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.3736 - tp: 936.0000 - fp: 223.0000 - tn: 2884.0000 - fn: 493.0000 - accuracy: 0.8422 - precision: 0.8076 - recall: 0.6550 - auc: 0.8983 - prc: 0.8167 - val_loss: 0.5712 - val_tp: 149.0000 - val_fp: 71.0000 - val_tn: 706.0000 - val_fn: 208.0000 - val_accuracy: 0.7540 - val_precision: 0.6773 - val_recall: 0.4174 - val_auc: 0.7379 - val_prc: 0.5845\n",
      "Epoch 12/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.3484 - tp: 982.0000 - fp: 197.0000 - tn: 2910.0000 - fn: 447.0000 - accuracy: 0.8580 - precision: 0.8329 - recall: 0.6872 - auc: 0.9142 - prc: 0.8445 - val_loss: 0.5689 - val_tp: 174.0000 - val_fp: 109.0000 - val_tn: 668.0000 - val_fn: 183.0000 - val_accuracy: 0.7425 - val_precision: 0.6148 - val_recall: 0.4874 - val_auc: 0.7453 - val_prc: 0.5879\n",
      "Epoch 13/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.3394 - tp: 987.0000 - fp: 204.0000 - tn: 2903.0000 - fn: 442.0000 - accuracy: 0.8576 - precision: 0.8287 - recall: 0.6907 - auc: 0.9187 - prc: 0.8567 - val_loss: 0.5776 - val_tp: 158.0000 - val_fp: 80.0000 - val_tn: 697.0000 - val_fn: 199.0000 - val_accuracy: 0.7540 - val_precision: 0.6639 - val_recall: 0.4426 - val_auc: 0.7404 - val_prc: 0.5874\n",
      "Epoch 14/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.3222 - tp: 988.0000 - fp: 199.0000 - tn: 2908.0000 - fn: 441.0000 - accuracy: 0.8589 - precision: 0.8324 - recall: 0.6914 - auc: 0.9309 - prc: 0.8678 - val_loss: 0.5830 - val_tp: 176.0000 - val_fp: 114.0000 - val_tn: 663.0000 - val_fn: 181.0000 - val_accuracy: 0.7399 - val_precision: 0.6069 - val_recall: 0.4930 - val_auc: 0.7415 - val_prc: 0.5817\n",
      "Epoch 15/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.3104 - tp: 1027.0000 - fp: 183.0000 - tn: 2924.0000 - fn: 402.0000 - accuracy: 0.8710 - precision: 0.8488 - recall: 0.7187 - auc: 0.9376 - prc: 0.8817 - val_loss: 0.6048 - val_tp: 143.0000 - val_fp: 68.0000 - val_tn: 709.0000 - val_fn: 214.0000 - val_accuracy: 0.7513 - val_precision: 0.6777 - val_recall: 0.4006 - val_auc: 0.7345 - val_prc: 0.5845\n",
      "Epoch 16/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.2927 - tp: 1045.0000 - fp: 154.0000 - tn: 2953.0000 - fn: 384.0000 - accuracy: 0.8814 - precision: 0.8716 - recall: 0.7313 - auc: 0.9445 - prc: 0.8964 - val_loss: 0.6031 - val_tp: 186.0000 - val_fp: 139.0000 - val_tn: 638.0000 - val_fn: 171.0000 - val_accuracy: 0.7266 - val_precision: 0.5723 - val_recall: 0.5210 - val_auc: 0.7418 - val_prc: 0.5760\n",
      "Epoch 17/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.2834 - tp: 1066.0000 - fp: 159.0000 - tn: 2948.0000 - fn: 363.0000 - accuracy: 0.8849 - precision: 0.8702 - recall: 0.7460 - auc: 0.9495 - prc: 0.9035 - val_loss: 0.5998 - val_tp: 171.0000 - val_fp: 106.0000 - val_tn: 671.0000 - val_fn: 186.0000 - val_accuracy: 0.7425 - val_precision: 0.6173 - val_recall: 0.4790 - val_auc: 0.7406 - val_prc: 0.5838\n",
      "Epoch 18/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.2705 - tp: 1086.0000 - fp: 154.0000 - tn: 2953.0000 - fn: 343.0000 - accuracy: 0.8904 - precision: 0.8758 - recall: 0.7600 - auc: 0.9556 - prc: 0.9146 - val_loss: 0.6112 - val_tp: 180.0000 - val_fp: 127.0000 - val_tn: 650.0000 - val_fn: 177.0000 - val_accuracy: 0.7319 - val_precision: 0.5863 - val_recall: 0.5042 - val_auc: 0.7407 - val_prc: 0.5787\n",
      "Epoch 19/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.2589 - tp: 1110.0000 - fp: 148.0000 - tn: 2959.0000 - fn: 319.0000 - accuracy: 0.8970 - precision: 0.8824 - recall: 0.7768 - auc: 0.9594 - prc: 0.9229 - val_loss: 0.6172 - val_tp: 163.0000 - val_fp: 101.0000 - val_tn: 676.0000 - val_fn: 194.0000 - val_accuracy: 0.7399 - val_precision: 0.6174 - val_recall: 0.4566 - val_auc: 0.7373 - val_prc: 0.5808\n",
      "Epoch 20/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.2435 - tp: 1129.0000 - fp: 114.0000 - tn: 2993.0000 - fn: 300.0000 - accuracy: 0.9087 - precision: 0.9083 - recall: 0.7901 - auc: 0.9657 - prc: 0.9354 - val_loss: 0.6272 - val_tp: 163.0000 - val_fp: 104.0000 - val_tn: 673.0000 - val_fn: 194.0000 - val_accuracy: 0.7372 - val_precision: 0.6105 - val_recall: 0.4566 - val_auc: 0.7349 - val_prc: 0.5777\n",
      "Epoch 21/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.2378 - tp: 1136.0000 - fp: 133.0000 - tn: 2974.0000 - fn: 293.0000 - accuracy: 0.9061 - precision: 0.8952 - recall: 0.7950 - auc: 0.9673 - prc: 0.9354 - val_loss: 0.6340 - val_tp: 182.0000 - val_fp: 127.0000 - val_tn: 650.0000 - val_fn: 175.0000 - val_accuracy: 0.7337 - val_precision: 0.5890 - val_recall: 0.5098 - val_auc: 0.7376 - val_prc: 0.5728\n",
      "Epoch 22/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.2253 - tp: 1151.0000 - fp: 117.0000 - tn: 2990.0000 - fn: 278.0000 - accuracy: 0.9129 - precision: 0.9077 - recall: 0.8055 - auc: 0.9719 - prc: 0.9454 - val_loss: 0.6412 - val_tp: 169.0000 - val_fp: 108.0000 - val_tn: 669.0000 - val_fn: 188.0000 - val_accuracy: 0.7390 - val_precision: 0.6101 - val_recall: 0.4734 - val_auc: 0.7348 - val_prc: 0.5744\n",
      "Epoch 23/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.2171 - tp: 1170.0000 - fp: 111.0000 - tn: 2996.0000 - fn: 259.0000 - accuracy: 0.9184 - precision: 0.9133 - recall: 0.8188 - auc: 0.9741 - prc: 0.9472 - val_loss: 0.6471 - val_tp: 169.0000 - val_fp: 113.0000 - val_tn: 664.0000 - val_fn: 188.0000 - val_accuracy: 0.7346 - val_precision: 0.5993 - val_recall: 0.4734 - val_auc: 0.7353 - val_prc: 0.5758\n",
      "Epoch 24/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.2070 - tp: 1190.0000 - fp: 109.0000 - tn: 2998.0000 - fn: 239.0000 - accuracy: 0.9233 - precision: 0.9161 - recall: 0.8328 - auc: 0.9772 - prc: 0.9549 - val_loss: 0.6587 - val_tp: 171.0000 - val_fp: 112.0000 - val_tn: 665.0000 - val_fn: 186.0000 - val_accuracy: 0.7372 - val_precision: 0.6042 - val_recall: 0.4790 - val_auc: 0.7336 - val_prc: 0.5756\n",
      "Epoch 25/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.2002 - tp: 1202.0000 - fp: 100.0000 - tn: 3007.0000 - fn: 227.0000 - accuracy: 0.9279 - precision: 0.9232 - recall: 0.8411 - auc: 0.9783 - prc: 0.9574 - val_loss: 0.6762 - val_tp: 153.0000 - val_fp: 83.0000 - val_tn: 694.0000 - val_fn: 204.0000 - val_accuracy: 0.7469 - val_precision: 0.6483 - val_recall: 0.4286 - val_auc: 0.7322 - val_prc: 0.5801\n",
      "Epoch 26/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.1874 - tp: 1207.0000 - fp: 90.0000 - tn: 3017.0000 - fn: 222.0000 - accuracy: 0.9312 - precision: 0.9306 - recall: 0.8446 - auc: 0.9825 - prc: 0.9654 - val_loss: 0.6804 - val_tp: 160.0000 - val_fp: 94.0000 - val_tn: 683.0000 - val_fn: 197.0000 - val_accuracy: 0.7434 - val_precision: 0.6299 - val_recall: 0.4482 - val_auc: 0.7314 - val_prc: 0.5742\n",
      "Epoch 27/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.1760 - tp: 1242.0000 - fp: 86.0000 - tn: 3021.0000 - fn: 187.0000 - accuracy: 0.9398 - precision: 0.9352 - recall: 0.8691 - auc: 0.9848 - prc: 0.9702 - val_loss: 0.6865 - val_tp: 176.0000 - val_fp: 127.0000 - val_tn: 650.0000 - val_fn: 181.0000 - val_accuracy: 0.7284 - val_precision: 0.5809 - val_recall: 0.4930 - val_auc: 0.7321 - val_prc: 0.5708\n",
      "Epoch 28/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.1718 - tp: 1238.0000 - fp: 79.0000 - tn: 3028.0000 - fn: 191.0000 - accuracy: 0.9405 - precision: 0.9400 - recall: 0.8663 - auc: 0.9853 - prc: 0.9709 - val_loss: 0.6982 - val_tp: 189.0000 - val_fp: 148.0000 - val_tn: 629.0000 - val_fn: 168.0000 - val_accuracy: 0.7213 - val_precision: 0.5608 - val_recall: 0.5294 - val_auc: 0.7346 - val_prc: 0.5694\n",
      "Epoch 29/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.1688 - tp: 1244.0000 - fp: 93.0000 - tn: 3014.0000 - fn: 185.0000 - accuracy: 0.9387 - precision: 0.9304 - recall: 0.8705 - auc: 0.9852 - prc: 0.9704 - val_loss: 0.7052 - val_tp: 167.0000 - val_fp: 111.0000 - val_tn: 666.0000 - val_fn: 190.0000 - val_accuracy: 0.7346 - val_precision: 0.6007 - val_recall: 0.4678 - val_auc: 0.7309 - val_prc: 0.5700\n",
      "Epoch 30/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.1580 - tp: 1256.0000 - fp: 72.0000 - tn: 3035.0000 - fn: 173.0000 - accuracy: 0.9460 - precision: 0.9458 - recall: 0.8789 - auc: 0.9879 - prc: 0.9759 - val_loss: 0.7096 - val_tp: 180.0000 - val_fp: 134.0000 - val_tn: 643.0000 - val_fn: 177.0000 - val_accuracy: 0.7257 - val_precision: 0.5732 - val_recall: 0.5042 - val_auc: 0.7332 - val_prc: 0.5691\n",
      "Epoch 31/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.1504 - tp: 1272.0000 - fp: 76.0000 - tn: 3031.0000 - fn: 157.0000 - accuracy: 0.9486 - precision: 0.9436 - recall: 0.8901 - auc: 0.9893 - prc: 0.9781 - val_loss: 0.7239 - val_tp: 171.0000 - val_fp: 114.0000 - val_tn: 663.0000 - val_fn: 186.0000 - val_accuracy: 0.7354 - val_precision: 0.6000 - val_recall: 0.4790 - val_auc: 0.7327 - val_prc: 0.5692\n",
      "Epoch 32/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.1431 - tp: 1291.0000 - fp: 71.0000 - tn: 3036.0000 - fn: 138.0000 - accuracy: 0.9539 - precision: 0.9479 - recall: 0.9034 - auc: 0.9906 - prc: 0.9812 - val_loss: 0.7350 - val_tp: 181.0000 - val_fp: 126.0000 - val_tn: 651.0000 - val_fn: 176.0000 - val_accuracy: 0.7337 - val_precision: 0.5896 - val_recall: 0.5070 - val_auc: 0.7300 - val_prc: 0.5689\n",
      "Epoch 33/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.1375 - tp: 1290.0000 - fp: 66.0000 - tn: 3041.0000 - fn: 139.0000 - accuracy: 0.9548 - precision: 0.9513 - recall: 0.9027 - auc: 0.9914 - prc: 0.9824 - val_loss: 0.7467 - val_tp: 175.0000 - val_fp: 125.0000 - val_tn: 652.0000 - val_fn: 182.0000 - val_accuracy: 0.7293 - val_precision: 0.5833 - val_recall: 0.4902 - val_auc: 0.7301 - val_prc: 0.5683\n",
      "Epoch 34/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.1330 - tp: 1303.0000 - fp: 65.0000 - tn: 3042.0000 - fn: 126.0000 - accuracy: 0.9579 - precision: 0.9525 - recall: 0.9118 - auc: 0.9916 - prc: 0.9831 - val_loss: 0.7570 - val_tp: 173.0000 - val_fp: 123.0000 - val_tn: 654.0000 - val_fn: 184.0000 - val_accuracy: 0.7293 - val_precision: 0.5845 - val_recall: 0.4846 - val_auc: 0.7296 - val_prc: 0.5643\n",
      "Epoch 35/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.1276 - tp: 1299.0000 - fp: 63.0000 - tn: 3044.0000 - fn: 130.0000 - accuracy: 0.9575 - precision: 0.9537 - recall: 0.9090 - auc: 0.9925 - prc: 0.9847 - val_loss: 0.7681 - val_tp: 166.0000 - val_fp: 117.0000 - val_tn: 660.0000 - val_fn: 191.0000 - val_accuracy: 0.7284 - val_precision: 0.5866 - val_recall: 0.4650 - val_auc: 0.7284 - val_prc: 0.5695\n",
      "Epoch 36/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.1210 - tp: 1315.0000 - fp: 51.0000 - tn: 3056.0000 - fn: 114.0000 - accuracy: 0.9636 - precision: 0.9627 - recall: 0.9202 - auc: 0.9934 - prc: 0.9864 - val_loss: 0.7896 - val_tp: 158.0000 - val_fp: 105.0000 - val_tn: 672.0000 - val_fn: 199.0000 - val_accuracy: 0.7319 - val_precision: 0.6008 - val_recall: 0.4426 - val_auc: 0.7255 - val_prc: 0.5687\n",
      "Epoch 37/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.1139 - tp: 1326.0000 - fp: 57.0000 - tn: 3050.0000 - fn: 103.0000 - accuracy: 0.9647 - precision: 0.9588 - recall: 0.9279 - auc: 0.9948 - prc: 0.9893 - val_loss: 0.8104 - val_tp: 155.0000 - val_fp: 99.0000 - val_tn: 678.0000 - val_fn: 202.0000 - val_accuracy: 0.7346 - val_precision: 0.6102 - val_recall: 0.4342 - val_auc: 0.7242 - val_prc: 0.5672\n",
      "Epoch 38/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.1146 - tp: 1317.0000 - fp: 49.0000 - tn: 3058.0000 - fn: 112.0000 - accuracy: 0.9645 - precision: 0.9641 - recall: 0.9216 - auc: 0.9943 - prc: 0.9883 - val_loss: 0.7998 - val_tp: 175.0000 - val_fp: 131.0000 - val_tn: 646.0000 - val_fn: 182.0000 - val_accuracy: 0.7240 - val_precision: 0.5719 - val_recall: 0.4902 - val_auc: 0.7257 - val_prc: 0.5623\n",
      "Epoch 39/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.1079 - tp: 1331.0000 - fp: 52.0000 - tn: 3055.0000 - fn: 98.0000 - accuracy: 0.9669 - precision: 0.9624 - recall: 0.9314 - auc: 0.9946 - prc: 0.9893 - val_loss: 0.8139 - val_tp: 168.0000 - val_fp: 117.0000 - val_tn: 660.0000 - val_fn: 189.0000 - val_accuracy: 0.7302 - val_precision: 0.5895 - val_recall: 0.4706 - val_auc: 0.7260 - val_prc: 0.5658\n",
      "Epoch 40/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.1029 - tp: 1339.0000 - fp: 56.0000 - tn: 3051.0000 - fn: 90.0000 - accuracy: 0.9678 - precision: 0.9599 - recall: 0.9370 - auc: 0.9954 - prc: 0.9908 - val_loss: 0.8207 - val_tp: 175.0000 - val_fp: 132.0000 - val_tn: 645.0000 - val_fn: 182.0000 - val_accuracy: 0.7231 - val_precision: 0.5700 - val_recall: 0.4902 - val_auc: 0.7244 - val_prc: 0.5580\n",
      "Epoch 41/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0979 - tp: 1340.0000 - fp: 48.0000 - tn: 3059.0000 - fn: 89.0000 - accuracy: 0.9698 - precision: 0.9654 - recall: 0.9377 - auc: 0.9959 - prc: 0.9916 - val_loss: 0.8343 - val_tp: 179.0000 - val_fp: 136.0000 - val_tn: 641.0000 - val_fn: 178.0000 - val_accuracy: 0.7231 - val_precision: 0.5683 - val_recall: 0.5014 - val_auc: 0.7251 - val_prc: 0.5600\n",
      "Epoch 42/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0991 - tp: 1326.0000 - fp: 43.0000 - tn: 3064.0000 - fn: 103.0000 - accuracy: 0.9678 - precision: 0.9686 - recall: 0.9279 - auc: 0.9955 - prc: 0.9909 - val_loss: 0.8486 - val_tp: 176.0000 - val_fp: 127.0000 - val_tn: 650.0000 - val_fn: 181.0000 - val_accuracy: 0.7284 - val_precision: 0.5809 - val_recall: 0.4930 - val_auc: 0.7259 - val_prc: 0.5593\n",
      "Epoch 43/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0917 - tp: 1349.0000 - fp: 39.0000 - tn: 3068.0000 - fn: 80.0000 - accuracy: 0.9738 - precision: 0.9719 - recall: 0.9440 - auc: 0.9964 - prc: 0.9927 - val_loss: 0.8655 - val_tp: 166.0000 - val_fp: 112.0000 - val_tn: 665.0000 - val_fn: 191.0000 - val_accuracy: 0.7328 - val_precision: 0.5971 - val_recall: 0.4650 - val_auc: 0.7225 - val_prc: 0.5565\n",
      "Epoch 44/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0882 - tp: 1353.0000 - fp: 35.0000 - tn: 3072.0000 - fn: 76.0000 - accuracy: 0.9755 - precision: 0.9748 - recall: 0.9468 - auc: 0.9968 - prc: 0.9933 - val_loss: 0.8790 - val_tp: 171.0000 - val_fp: 121.0000 - val_tn: 656.0000 - val_fn: 186.0000 - val_accuracy: 0.7293 - val_precision: 0.5856 - val_recall: 0.4790 - val_auc: 0.7224 - val_prc: 0.5561\n",
      "Epoch 45/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0848 - tp: 1354.0000 - fp: 48.0000 - tn: 3059.0000 - fn: 75.0000 - accuracy: 0.9729 - precision: 0.9658 - recall: 0.9475 - auc: 0.9969 - prc: 0.9934 - val_loss: 0.9002 - val_tp: 158.0000 - val_fp: 103.0000 - val_tn: 674.0000 - val_fn: 199.0000 - val_accuracy: 0.7337 - val_precision: 0.6054 - val_recall: 0.4426 - val_auc: 0.7205 - val_prc: 0.5563\n",
      "Epoch 46/200\n",
      "71/71 [==============================] - 1s 7ms/step - loss: 0.0849 - tp: 1347.0000 - fp: 40.0000 - tn: 3067.0000 - fn: 82.0000 - accuracy: 0.9731 - precision: 0.9712 - recall: 0.9426 - auc: 0.9968 - prc: 0.9935 - val_loss: 0.8917 - val_tp: 181.0000 - val_fp: 150.0000 - val_tn: 627.0000 - val_fn: 176.0000 - val_accuracy: 0.7125 - val_precision: 0.5468 - val_recall: 0.5070 - val_auc: 0.7217 - val_prc: 0.5481\n",
      "Epoch 47/200\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.0825 - tp: 1351.0000 - fp: 41.0000 - tn: 3066.0000 - fn: 78.0000 - accuracy: 0.9738 - precision: 0.9705 - recall: 0.9454 - auc: 0.9970 - prc: 0.9938 - val_loss: 0.9042 - val_tp: 173.0000 - val_fp: 133.0000 - val_tn: 644.0000 - val_fn: 184.0000 - val_accuracy: 0.7205 - val_precision: 0.5654 - val_recall: 0.4846 - val_auc: 0.7206 - val_prc: 0.5513\n",
      "Epoch 48/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0774 - tp: 1359.0000 - fp: 42.0000 - tn: 3065.0000 - fn: 70.0000 - accuracy: 0.9753 - precision: 0.9700 - recall: 0.9510 - auc: 0.9975 - prc: 0.9947 - val_loss: 0.9143 - val_tp: 175.0000 - val_fp: 143.0000 - val_tn: 634.0000 - val_fn: 182.0000 - val_accuracy: 0.7134 - val_precision: 0.5503 - val_recall: 0.4902 - val_auc: 0.7210 - val_prc: 0.5530\n",
      "Epoch 49/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0785 - tp: 1357.0000 - fp: 46.0000 - tn: 3061.0000 - fn: 72.0000 - accuracy: 0.9740 - precision: 0.9672 - recall: 0.9496 - auc: 0.9972 - prc: 0.9941 - val_loss: 0.9287 - val_tp: 171.0000 - val_fp: 126.0000 - val_tn: 651.0000 - val_fn: 186.0000 - val_accuracy: 0.7249 - val_precision: 0.5758 - val_recall: 0.4790 - val_auc: 0.7218 - val_prc: 0.5537\n",
      "Epoch 50/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0715 - tp: 1365.0000 - fp: 29.0000 - tn: 3078.0000 - fn: 64.0000 - accuracy: 0.9795 - precision: 0.9792 - recall: 0.9552 - auc: 0.9979 - prc: 0.9955 - val_loss: 0.9359 - val_tp: 178.0000 - val_fp: 145.0000 - val_tn: 632.0000 - val_fn: 179.0000 - val_accuracy: 0.7143 - val_precision: 0.5511 - val_recall: 0.4986 - val_auc: 0.7210 - val_prc: 0.5528\n",
      "Epoch 51/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0728 - tp: 1366.0000 - fp: 37.0000 - tn: 3070.0000 - fn: 63.0000 - accuracy: 0.9780 - precision: 0.9736 - recall: 0.9559 - auc: 0.9976 - prc: 0.9951 - val_loss: 0.9429 - val_tp: 170.0000 - val_fp: 134.0000 - val_tn: 643.0000 - val_fn: 187.0000 - val_accuracy: 0.7169 - val_precision: 0.5592 - val_recall: 0.4762 - val_auc: 0.7208 - val_prc: 0.5494\n",
      "Epoch 52/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0678 - tp: 1366.0000 - fp: 32.0000 - tn: 3075.0000 - fn: 63.0000 - accuracy: 0.9791 - precision: 0.9771 - recall: 0.9559 - auc: 0.9981 - prc: 0.9961 - val_loss: 0.9574 - val_tp: 175.0000 - val_fp: 136.0000 - val_tn: 641.0000 - val_fn: 182.0000 - val_accuracy: 0.7196 - val_precision: 0.5627 - val_recall: 0.4902 - val_auc: 0.7212 - val_prc: 0.5512\n",
      "Epoch 53/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0702 - tp: 1369.0000 - fp: 43.0000 - tn: 3064.0000 - fn: 60.0000 - accuracy: 0.9773 - precision: 0.9695 - recall: 0.9580 - auc: 0.9977 - prc: 0.9953 - val_loss: 0.9748 - val_tp: 162.0000 - val_fp: 118.0000 - val_tn: 659.0000 - val_fn: 195.0000 - val_accuracy: 0.7240 - val_precision: 0.5786 - val_recall: 0.4538 - val_auc: 0.7188 - val_prc: 0.5503\n",
      "Epoch 54/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0670 - tp: 1368.0000 - fp: 37.0000 - tn: 3070.0000 - fn: 61.0000 - accuracy: 0.9784 - precision: 0.9737 - recall: 0.9573 - auc: 0.9980 - prc: 0.9958 - val_loss: 0.9931 - val_tp: 163.0000 - val_fp: 115.0000 - val_tn: 662.0000 - val_fn: 194.0000 - val_accuracy: 0.7275 - val_precision: 0.5863 - val_recall: 0.4566 - val_auc: 0.7178 - val_prc: 0.5536\n",
      "Epoch 55/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0631 - tp: 1366.0000 - fp: 27.0000 - tn: 3080.0000 - fn: 63.0000 - accuracy: 0.9802 - precision: 0.9806 - recall: 0.9559 - auc: 0.9983 - prc: 0.9965 - val_loss: 0.9850 - val_tp: 184.0000 - val_fp: 153.0000 - val_tn: 624.0000 - val_fn: 173.0000 - val_accuracy: 0.7125 - val_precision: 0.5460 - val_recall: 0.5154 - val_auc: 0.7208 - val_prc: 0.5476\n",
      "Epoch 56/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0632 - tp: 1373.0000 - fp: 37.0000 - tn: 3070.0000 - fn: 56.0000 - accuracy: 0.9795 - precision: 0.9738 - recall: 0.9608 - auc: 0.9982 - prc: 0.9962 - val_loss: 1.0031 - val_tp: 169.0000 - val_fp: 131.0000 - val_tn: 646.0000 - val_fn: 188.0000 - val_accuracy: 0.7187 - val_precision: 0.5633 - val_recall: 0.4734 - val_auc: 0.7172 - val_prc: 0.5476\n",
      "Epoch 57/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0632 - tp: 1365.0000 - fp: 30.0000 - tn: 3077.0000 - fn: 64.0000 - accuracy: 0.9793 - precision: 0.9785 - recall: 0.9552 - auc: 0.9982 - prc: 0.9962 - val_loss: 1.0103 - val_tp: 172.0000 - val_fp: 133.0000 - val_tn: 644.0000 - val_fn: 185.0000 - val_accuracy: 0.7196 - val_precision: 0.5639 - val_recall: 0.4818 - val_auc: 0.7192 - val_prc: 0.5460\n",
      "Epoch 58/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0601 - tp: 1375.0000 - fp: 36.0000 - tn: 3071.0000 - fn: 54.0000 - accuracy: 0.9802 - precision: 0.9745 - recall: 0.9622 - auc: 0.9984 - prc: 0.9967 - val_loss: 1.0225 - val_tp: 178.0000 - val_fp: 154.0000 - val_tn: 623.0000 - val_fn: 179.0000 - val_accuracy: 0.7063 - val_precision: 0.5361 - val_recall: 0.4986 - val_auc: 0.7152 - val_prc: 0.5404\n",
      "Epoch 59/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0600 - tp: 1373.0000 - fp: 37.0000 - tn: 3070.0000 - fn: 56.0000 - accuracy: 0.9795 - precision: 0.9738 - recall: 0.9608 - auc: 0.9981 - prc: 0.9962 - val_loss: 1.0447 - val_tp: 166.0000 - val_fp: 125.0000 - val_tn: 652.0000 - val_fn: 191.0000 - val_accuracy: 0.7213 - val_precision: 0.5704 - val_recall: 0.4650 - val_auc: 0.7153 - val_prc: 0.5449\n",
      "Epoch 60/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0539 - tp: 1375.0000 - fp: 22.0000 - tn: 3085.0000 - fn: 54.0000 - accuracy: 0.9832 - precision: 0.9843 - recall: 0.9622 - auc: 0.9988 - prc: 0.9975 - val_loss: 1.0474 - val_tp: 182.0000 - val_fp: 157.0000 - val_tn: 620.0000 - val_fn: 175.0000 - val_accuracy: 0.7072 - val_precision: 0.5369 - val_recall: 0.5098 - val_auc: 0.7163 - val_prc: 0.5399\n",
      "Epoch 61/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0560 - tp: 1367.0000 - fp: 32.0000 - tn: 3075.0000 - fn: 62.0000 - accuracy: 0.9793 - precision: 0.9771 - recall: 0.9566 - auc: 0.9986 - prc: 0.9972 - val_loss: 1.0537 - val_tp: 174.0000 - val_fp: 142.0000 - val_tn: 635.0000 - val_fn: 183.0000 - val_accuracy: 0.7134 - val_precision: 0.5506 - val_recall: 0.4874 - val_auc: 0.7151 - val_prc: 0.5393\n",
      "Epoch 62/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0551 - tp: 1374.0000 - fp: 32.0000 - tn: 3075.0000 - fn: 55.0000 - accuracy: 0.9808 - precision: 0.9772 - recall: 0.9615 - auc: 0.9984 - prc: 0.9968 - val_loss: 1.0705 - val_tp: 178.0000 - val_fp: 148.0000 - val_tn: 629.0000 - val_fn: 179.0000 - val_accuracy: 0.7116 - val_precision: 0.5460 - val_recall: 0.4986 - val_auc: 0.7152 - val_prc: 0.5395\n",
      "Epoch 63/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0558 - tp: 1371.0000 - fp: 33.0000 - tn: 3074.0000 - fn: 58.0000 - accuracy: 0.9799 - precision: 0.9765 - recall: 0.9594 - auc: 0.9986 - prc: 0.9970 - val_loss: 1.0723 - val_tp: 172.0000 - val_fp: 143.0000 - val_tn: 634.0000 - val_fn: 185.0000 - val_accuracy: 0.7108 - val_precision: 0.5460 - val_recall: 0.4818 - val_auc: 0.7138 - val_prc: 0.5391\n",
      "Epoch 64/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0525 - tp: 1378.0000 - fp: 30.0000 - tn: 3077.0000 - fn: 51.0000 - accuracy: 0.9821 - precision: 0.9787 - recall: 0.9643 - auc: 0.9988 - prc: 0.9975 - val_loss: 1.0994 - val_tp: 166.0000 - val_fp: 134.0000 - val_tn: 643.0000 - val_fn: 191.0000 - val_accuracy: 0.7134 - val_precision: 0.5533 - val_recall: 0.4650 - val_auc: 0.7114 - val_prc: 0.5364\n",
      "Epoch 65/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0517 - tp: 1379.0000 - fp: 24.0000 - tn: 3083.0000 - fn: 50.0000 - accuracy: 0.9837 - precision: 0.9829 - recall: 0.9650 - auc: 0.9987 - prc: 0.9974 - val_loss: 1.1194 - val_tp: 156.0000 - val_fp: 114.0000 - val_tn: 663.0000 - val_fn: 201.0000 - val_accuracy: 0.7222 - val_precision: 0.5778 - val_recall: 0.4370 - val_auc: 0.7124 - val_prc: 0.5444\n",
      "Epoch 66/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0513 - tp: 1377.0000 - fp: 27.0000 - tn: 3080.0000 - fn: 52.0000 - accuracy: 0.9826 - precision: 0.9808 - recall: 0.9636 - auc: 0.9987 - prc: 0.9974 - val_loss: 1.1086 - val_tp: 175.0000 - val_fp: 157.0000 - val_tn: 620.0000 - val_fn: 182.0000 - val_accuracy: 0.7011 - val_precision: 0.5271 - val_recall: 0.4902 - val_auc: 0.7132 - val_prc: 0.5353\n",
      "Epoch 67/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0496 - tp: 1375.0000 - fp: 25.0000 - tn: 3082.0000 - fn: 54.0000 - accuracy: 0.9826 - precision: 0.9821 - recall: 0.9622 - auc: 0.9989 - prc: 0.9977 - val_loss: 1.1242 - val_tp: 172.0000 - val_fp: 148.0000 - val_tn: 629.0000 - val_fn: 185.0000 - val_accuracy: 0.7063 - val_precision: 0.5375 - val_recall: 0.4818 - val_auc: 0.7110 - val_prc: 0.5356\n",
      "Epoch 68/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0490 - tp: 1376.0000 - fp: 27.0000 - tn: 3080.0000 - fn: 53.0000 - accuracy: 0.9824 - precision: 0.9808 - recall: 0.9629 - auc: 0.9988 - prc: 0.9976 - val_loss: 1.1280 - val_tp: 171.0000 - val_fp: 146.0000 - val_tn: 631.0000 - val_fn: 186.0000 - val_accuracy: 0.7072 - val_precision: 0.5394 - val_recall: 0.4790 - val_auc: 0.7106 - val_prc: 0.5343\n",
      "Epoch 69/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0487 - tp: 1378.0000 - fp: 26.0000 - tn: 3081.0000 - fn: 51.0000 - accuracy: 0.9830 - precision: 0.9815 - recall: 0.9643 - auc: 0.9988 - prc: 0.9974 - val_loss: 1.1433 - val_tp: 164.0000 - val_fp: 125.0000 - val_tn: 652.0000 - val_fn: 193.0000 - val_accuracy: 0.7196 - val_precision: 0.5675 - val_recall: 0.4594 - val_auc: 0.7119 - val_prc: 0.5356\n",
      "Epoch 70/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0473 - tp: 1381.0000 - fp: 28.0000 - tn: 3079.0000 - fn: 48.0000 - accuracy: 0.9832 - precision: 0.9801 - recall: 0.9664 - auc: 0.9990 - prc: 0.9979 - val_loss: 1.1461 - val_tp: 176.0000 - val_fp: 148.0000 - val_tn: 629.0000 - val_fn: 181.0000 - val_accuracy: 0.7099 - val_precision: 0.5432 - val_recall: 0.4930 - val_auc: 0.7121 - val_prc: 0.5369\n",
      "Epoch 71/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0480 - tp: 1377.0000 - fp: 27.0000 - tn: 3080.0000 - fn: 52.0000 - accuracy: 0.9826 - precision: 0.9808 - recall: 0.9636 - auc: 0.9988 - prc: 0.9976 - val_loss: 1.1496 - val_tp: 178.0000 - val_fp: 153.0000 - val_tn: 624.0000 - val_fn: 179.0000 - val_accuracy: 0.7072 - val_precision: 0.5378 - val_recall: 0.4986 - val_auc: 0.7112 - val_prc: 0.5324\n",
      "Epoch 72/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0478 - tp: 1382.0000 - fp: 27.0000 - tn: 3080.0000 - fn: 47.0000 - accuracy: 0.9837 - precision: 0.9808 - recall: 0.9671 - auc: 0.9989 - prc: 0.9976 - val_loss: 1.1564 - val_tp: 168.0000 - val_fp: 141.0000 - val_tn: 636.0000 - val_fn: 189.0000 - val_accuracy: 0.7090 - val_precision: 0.5437 - val_recall: 0.4706 - val_auc: 0.7099 - val_prc: 0.5337\n",
      "Epoch 73/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0439 - tp: 1388.0000 - fp: 22.0000 - tn: 3085.0000 - fn: 41.0000 - accuracy: 0.9861 - precision: 0.9844 - recall: 0.9713 - auc: 0.9991 - prc: 0.9981 - val_loss: 1.1774 - val_tp: 166.0000 - val_fp: 132.0000 - val_tn: 645.0000 - val_fn: 191.0000 - val_accuracy: 0.7152 - val_precision: 0.5570 - val_recall: 0.4650 - val_auc: 0.7084 - val_prc: 0.5309\n",
      "Epoch 74/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0447 - tp: 1382.0000 - fp: 33.0000 - tn: 3074.0000 - fn: 47.0000 - accuracy: 0.9824 - precision: 0.9767 - recall: 0.9671 - auc: 0.9990 - prc: 0.9979 - val_loss: 1.1990 - val_tp: 161.0000 - val_fp: 129.0000 - val_tn: 648.0000 - val_fn: 196.0000 - val_accuracy: 0.7134 - val_precision: 0.5552 - val_recall: 0.4510 - val_auc: 0.7101 - val_prc: 0.5329\n",
      "Epoch 75/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0456 - tp: 1381.0000 - fp: 24.0000 - tn: 3083.0000 - fn: 48.0000 - accuracy: 0.9841 - precision: 0.9829 - recall: 0.9664 - auc: 0.9989 - prc: 0.9978 - val_loss: 1.1972 - val_tp: 166.0000 - val_fp: 134.0000 - val_tn: 643.0000 - val_fn: 191.0000 - val_accuracy: 0.7134 - val_precision: 0.5533 - val_recall: 0.4650 - val_auc: 0.7098 - val_prc: 0.5316\n",
      "Epoch 76/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0436 - tp: 1385.0000 - fp: 28.0000 - tn: 3079.0000 - fn: 44.0000 - accuracy: 0.9841 - precision: 0.9802 - recall: 0.9692 - auc: 0.9991 - prc: 0.9982 - val_loss: 1.2088 - val_tp: 169.0000 - val_fp: 149.0000 - val_tn: 628.0000 - val_fn: 188.0000 - val_accuracy: 0.7028 - val_precision: 0.5314 - val_recall: 0.4734 - val_auc: 0.7089 - val_prc: 0.5311\n",
      "Epoch 77/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0435 - tp: 1385.0000 - fp: 26.0000 - tn: 3081.0000 - fn: 44.0000 - accuracy: 0.9846 - precision: 0.9816 - recall: 0.9692 - auc: 0.9990 - prc: 0.9979 - val_loss: 1.2068 - val_tp: 166.0000 - val_fp: 131.0000 - val_tn: 646.0000 - val_fn: 191.0000 - val_accuracy: 0.7160 - val_precision: 0.5589 - val_recall: 0.4650 - val_auc: 0.7077 - val_prc: 0.5282\n",
      "Epoch 78/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0433 - tp: 1387.0000 - fp: 27.0000 - tn: 3080.0000 - fn: 42.0000 - accuracy: 0.9848 - precision: 0.9809 - recall: 0.9706 - auc: 0.9990 - prc: 0.9979 - val_loss: 1.2272 - val_tp: 161.0000 - val_fp: 129.0000 - val_tn: 648.0000 - val_fn: 196.0000 - val_accuracy: 0.7134 - val_precision: 0.5552 - val_recall: 0.4510 - val_auc: 0.7081 - val_prc: 0.5330\n",
      "Epoch 79/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0426 - tp: 1384.0000 - fp: 22.0000 - tn: 3085.0000 - fn: 45.0000 - accuracy: 0.9852 - precision: 0.9844 - recall: 0.9685 - auc: 0.9990 - prc: 0.9979 - val_loss: 1.2339 - val_tp: 163.0000 - val_fp: 129.0000 - val_tn: 648.0000 - val_fn: 194.0000 - val_accuracy: 0.7152 - val_precision: 0.5582 - val_recall: 0.4566 - val_auc: 0.7075 - val_prc: 0.5338\n",
      "Epoch 80/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0400 - tp: 1387.0000 - fp: 19.0000 - tn: 3088.0000 - fn: 42.0000 - accuracy: 0.9866 - precision: 0.9865 - recall: 0.9706 - auc: 0.9992 - prc: 0.9984 - val_loss: 1.2345 - val_tp: 168.0000 - val_fp: 144.0000 - val_tn: 633.0000 - val_fn: 189.0000 - val_accuracy: 0.7063 - val_precision: 0.5385 - val_recall: 0.4706 - val_auc: 0.7092 - val_prc: 0.5295\n",
      "Epoch 81/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0401 - tp: 1386.0000 - fp: 23.0000 - tn: 3084.0000 - fn: 43.0000 - accuracy: 0.9854 - precision: 0.9837 - recall: 0.9699 - auc: 0.9992 - prc: 0.9983 - val_loss: 1.2476 - val_tp: 184.0000 - val_fp: 169.0000 - val_tn: 608.0000 - val_fn: 173.0000 - val_accuracy: 0.6984 - val_precision: 0.5212 - val_recall: 0.5154 - val_auc: 0.7080 - val_prc: 0.5290\n",
      "Epoch 82/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0405 - tp: 1379.0000 - fp: 23.0000 - tn: 3084.0000 - fn: 50.0000 - accuracy: 0.9839 - precision: 0.9836 - recall: 0.9650 - auc: 0.9991 - prc: 0.9982 - val_loss: 1.2562 - val_tp: 163.0000 - val_fp: 132.0000 - val_tn: 645.0000 - val_fn: 194.0000 - val_accuracy: 0.7125 - val_precision: 0.5525 - val_recall: 0.4566 - val_auc: 0.7085 - val_prc: 0.5343\n",
      "Epoch 83/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0422 - tp: 1382.0000 - fp: 31.0000 - tn: 3076.0000 - fn: 47.0000 - accuracy: 0.9828 - precision: 0.9781 - recall: 0.9671 - auc: 0.9990 - prc: 0.9980 - val_loss: 1.2577 - val_tp: 166.0000 - val_fp: 142.0000 - val_tn: 635.0000 - val_fn: 191.0000 - val_accuracy: 0.7063 - val_precision: 0.5390 - val_recall: 0.4650 - val_auc: 0.7078 - val_prc: 0.5341\n",
      "Epoch 84/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0404 - tp: 1387.0000 - fp: 29.0000 - tn: 3078.0000 - fn: 42.0000 - accuracy: 0.9843 - precision: 0.9795 - recall: 0.9706 - auc: 0.9992 - prc: 0.9983 - val_loss: 1.2720 - val_tp: 163.0000 - val_fp: 135.0000 - val_tn: 642.0000 - val_fn: 194.0000 - val_accuracy: 0.7099 - val_precision: 0.5470 - val_recall: 0.4566 - val_auc: 0.7054 - val_prc: 0.5309\n",
      "Epoch 85/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0417 - tp: 1383.0000 - fp: 30.0000 - tn: 3077.0000 - fn: 46.0000 - accuracy: 0.9832 - precision: 0.9788 - recall: 0.9678 - auc: 0.9990 - prc: 0.9980 - val_loss: 1.2692 - val_tp: 174.0000 - val_fp: 152.0000 - val_tn: 625.0000 - val_fn: 183.0000 - val_accuracy: 0.7046 - val_precision: 0.5337 - val_recall: 0.4874 - val_auc: 0.7054 - val_prc: 0.5279\n",
      "Epoch 86/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0400 - tp: 1385.0000 - fp: 31.0000 - tn: 3076.0000 - fn: 44.0000 - accuracy: 0.9835 - precision: 0.9781 - recall: 0.9692 - auc: 0.9991 - prc: 0.9982 - val_loss: 1.2639 - val_tp: 176.0000 - val_fp: 156.0000 - val_tn: 621.0000 - val_fn: 181.0000 - val_accuracy: 0.7028 - val_precision: 0.5301 - val_recall: 0.4930 - val_auc: 0.7084 - val_prc: 0.5308\n",
      "Epoch 87/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0390 - tp: 1386.0000 - fp: 24.0000 - tn: 3083.0000 - fn: 43.0000 - accuracy: 0.9852 - precision: 0.9830 - recall: 0.9699 - auc: 0.9992 - prc: 0.9983 - val_loss: 1.2840 - val_tp: 167.0000 - val_fp: 141.0000 - val_tn: 636.0000 - val_fn: 190.0000 - val_accuracy: 0.7081 - val_precision: 0.5422 - val_recall: 0.4678 - val_auc: 0.7031 - val_prc: 0.5285\n",
      "Epoch 88/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0389 - tp: 1382.0000 - fp: 24.0000 - tn: 3083.0000 - fn: 47.0000 - accuracy: 0.9843 - precision: 0.9829 - recall: 0.9671 - auc: 0.9991 - prc: 0.9981 - val_loss: 1.2969 - val_tp: 172.0000 - val_fp: 147.0000 - val_tn: 630.0000 - val_fn: 185.0000 - val_accuracy: 0.7072 - val_precision: 0.5392 - val_recall: 0.4818 - val_auc: 0.7043 - val_prc: 0.5306\n",
      "Epoch 89/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0379 - tp: 1390.0000 - fp: 18.0000 - tn: 3089.0000 - fn: 39.0000 - accuracy: 0.9874 - precision: 0.9872 - recall: 0.9727 - auc: 0.9992 - prc: 0.9982 - val_loss: 1.3007 - val_tp: 172.0000 - val_fp: 146.0000 - val_tn: 631.0000 - val_fn: 185.0000 - val_accuracy: 0.7081 - val_precision: 0.5409 - val_recall: 0.4818 - val_auc: 0.7053 - val_prc: 0.5279\n",
      "Epoch 90/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0379 - tp: 1390.0000 - fp: 27.0000 - tn: 3080.0000 - fn: 39.0000 - accuracy: 0.9854 - precision: 0.9809 - recall: 0.9727 - auc: 0.9992 - prc: 0.9984 - val_loss: 1.3053 - val_tp: 172.0000 - val_fp: 143.0000 - val_tn: 634.0000 - val_fn: 185.0000 - val_accuracy: 0.7108 - val_precision: 0.5460 - val_recall: 0.4818 - val_auc: 0.7036 - val_prc: 0.5277\n",
      "Epoch 91/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0390 - tp: 1385.0000 - fp: 23.0000 - tn: 3084.0000 - fn: 44.0000 - accuracy: 0.9852 - precision: 0.9837 - recall: 0.9692 - auc: 0.9991 - prc: 0.9982 - val_loss: 1.3124 - val_tp: 176.0000 - val_fp: 163.0000 - val_tn: 614.0000 - val_fn: 181.0000 - val_accuracy: 0.6966 - val_precision: 0.5192 - val_recall: 0.4930 - val_auc: 0.7028 - val_prc: 0.5256\n",
      "Epoch 92/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0343 - tp: 1395.0000 - fp: 25.0000 - tn: 3082.0000 - fn: 34.0000 - accuracy: 0.9870 - precision: 0.9824 - recall: 0.9762 - auc: 0.9994 - prc: 0.9988 - val_loss: 1.3632 - val_tp: 155.0000 - val_fp: 121.0000 - val_tn: 656.0000 - val_fn: 202.0000 - val_accuracy: 0.7152 - val_precision: 0.5616 - val_recall: 0.4342 - val_auc: 0.7010 - val_prc: 0.5281\n",
      "Epoch 93/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0351 - tp: 1384.0000 - fp: 16.0000 - tn: 3091.0000 - fn: 45.0000 - accuracy: 0.9866 - precision: 0.9886 - recall: 0.9685 - auc: 0.9993 - prc: 0.9986 - val_loss: 1.3470 - val_tp: 188.0000 - val_fp: 187.0000 - val_tn: 590.0000 - val_fn: 169.0000 - val_accuracy: 0.6861 - val_precision: 0.5013 - val_recall: 0.5266 - val_auc: 0.7075 - val_prc: 0.5302\n",
      "Epoch 94/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0360 - tp: 1390.0000 - fp: 24.0000 - tn: 3083.0000 - fn: 39.0000 - accuracy: 0.9861 - precision: 0.9830 - recall: 0.9727 - auc: 0.9993 - prc: 0.9985 - val_loss: 1.3508 - val_tp: 171.0000 - val_fp: 146.0000 - val_tn: 631.0000 - val_fn: 186.0000 - val_accuracy: 0.7072 - val_precision: 0.5394 - val_recall: 0.4790 - val_auc: 0.7042 - val_prc: 0.5302\n",
      "Epoch 95/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0356 - tp: 1389.0000 - fp: 28.0000 - tn: 3079.0000 - fn: 40.0000 - accuracy: 0.9850 - precision: 0.9802 - recall: 0.9720 - auc: 0.9993 - prc: 0.9986 - val_loss: 1.3580 - val_tp: 182.0000 - val_fp: 170.0000 - val_tn: 607.0000 - val_fn: 175.0000 - val_accuracy: 0.6958 - val_precision: 0.5170 - val_recall: 0.5098 - val_auc: 0.7052 - val_prc: 0.5287\n",
      "Epoch 96/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0356 - tp: 1392.0000 - fp: 25.0000 - tn: 3082.0000 - fn: 37.0000 - accuracy: 0.9863 - precision: 0.9824 - recall: 0.9741 - auc: 0.9993 - prc: 0.9985 - val_loss: 1.3680 - val_tp: 164.0000 - val_fp: 135.0000 - val_tn: 642.0000 - val_fn: 193.0000 - val_accuracy: 0.7108 - val_precision: 0.5485 - val_recall: 0.4594 - val_auc: 0.7036 - val_prc: 0.5295\n",
      "Epoch 97/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0350 - tp: 1387.0000 - fp: 18.0000 - tn: 3089.0000 - fn: 42.0000 - accuracy: 0.9868 - precision: 0.9872 - recall: 0.9706 - auc: 0.9993 - prc: 0.9985 - val_loss: 1.3782 - val_tp: 171.0000 - val_fp: 146.0000 - val_tn: 631.0000 - val_fn: 186.0000 - val_accuracy: 0.7072 - val_precision: 0.5394 - val_recall: 0.4790 - val_auc: 0.7025 - val_prc: 0.5286\n",
      "Epoch 98/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0324 - tp: 1395.0000 - fp: 22.0000 - tn: 3085.0000 - fn: 34.0000 - accuracy: 0.9877 - precision: 0.9845 - recall: 0.9762 - auc: 0.9995 - prc: 0.9989 - val_loss: 1.3987 - val_tp: 188.0000 - val_fp: 179.0000 - val_tn: 598.0000 - val_fn: 169.0000 - val_accuracy: 0.6931 - val_precision: 0.5123 - val_recall: 0.5266 - val_auc: 0.7074 - val_prc: 0.5295\n",
      "Epoch 99/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0355 - tp: 1390.0000 - fp: 22.0000 - tn: 3085.0000 - fn: 39.0000 - accuracy: 0.9866 - precision: 0.9844 - recall: 0.9727 - auc: 0.9993 - prc: 0.9985 - val_loss: 1.3830 - val_tp: 173.0000 - val_fp: 147.0000 - val_tn: 630.0000 - val_fn: 184.0000 - val_accuracy: 0.7081 - val_precision: 0.5406 - val_recall: 0.4846 - val_auc: 0.6988 - val_prc: 0.5261\n",
      "Epoch 100/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0336 - tp: 1392.0000 - fp: 23.0000 - tn: 3084.0000 - fn: 37.0000 - accuracy: 0.9868 - precision: 0.9837 - recall: 0.9741 - auc: 0.9994 - prc: 0.9987 - val_loss: 1.3949 - val_tp: 177.0000 - val_fp: 153.0000 - val_tn: 624.0000 - val_fn: 180.0000 - val_accuracy: 0.7063 - val_precision: 0.5364 - val_recall: 0.4958 - val_auc: 0.7004 - val_prc: 0.5280\n",
      "Epoch 101/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0356 - tp: 1389.0000 - fp: 24.0000 - tn: 3083.0000 - fn: 40.0000 - accuracy: 0.9859 - precision: 0.9830 - recall: 0.9720 - auc: 0.9992 - prc: 0.9984 - val_loss: 1.3908 - val_tp: 179.0000 - val_fp: 162.0000 - val_tn: 615.0000 - val_fn: 178.0000 - val_accuracy: 0.7002 - val_precision: 0.5249 - val_recall: 0.5014 - val_auc: 0.7015 - val_prc: 0.5284\n",
      "Epoch 102/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0335 - tp: 1391.0000 - fp: 24.0000 - tn: 3083.0000 - fn: 38.0000 - accuracy: 0.9863 - precision: 0.9830 - recall: 0.9734 - auc: 0.9993 - prc: 0.9986 - val_loss: 1.4110 - val_tp: 162.0000 - val_fp: 131.0000 - val_tn: 646.0000 - val_fn: 195.0000 - val_accuracy: 0.7125 - val_precision: 0.5529 - val_recall: 0.4538 - val_auc: 0.7017 - val_prc: 0.5274\n",
      "Epoch 103/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0314 - tp: 1395.0000 - fp: 22.0000 - tn: 3085.0000 - fn: 34.0000 - accuracy: 0.9877 - precision: 0.9845 - recall: 0.9762 - auc: 0.9994 - prc: 0.9988 - val_loss: 1.4408 - val_tp: 160.0000 - val_fp: 123.0000 - val_tn: 654.0000 - val_fn: 197.0000 - val_accuracy: 0.7178 - val_precision: 0.5654 - val_recall: 0.4482 - val_auc: 0.7004 - val_prc: 0.5244\n",
      "Epoch 104/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0337 - tp: 1392.0000 - fp: 27.0000 - tn: 3080.0000 - fn: 37.0000 - accuracy: 0.9859 - precision: 0.9810 - recall: 0.9741 - auc: 0.9993 - prc: 0.9986 - val_loss: 1.4301 - val_tp: 172.0000 - val_fp: 143.0000 - val_tn: 634.0000 - val_fn: 185.0000 - val_accuracy: 0.7108 - val_precision: 0.5460 - val_recall: 0.4818 - val_auc: 0.7009 - val_prc: 0.5250\n",
      "Epoch 105/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0315 - tp: 1392.0000 - fp: 22.0000 - tn: 3085.0000 - fn: 37.0000 - accuracy: 0.9870 - precision: 0.9844 - recall: 0.9741 - auc: 0.9994 - prc: 0.9988 - val_loss: 1.4622 - val_tp: 157.0000 - val_fp: 121.0000 - val_tn: 656.0000 - val_fn: 200.0000 - val_accuracy: 0.7169 - val_precision: 0.5647 - val_recall: 0.4398 - val_auc: 0.6988 - val_prc: 0.5238\n",
      "Epoch 106/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0339 - tp: 1389.0000 - fp: 30.0000 - tn: 3077.0000 - fn: 40.0000 - accuracy: 0.9846 - precision: 0.9789 - recall: 0.9720 - auc: 0.9994 - prc: 0.9986 - val_loss: 1.4774 - val_tp: 156.0000 - val_fp: 114.0000 - val_tn: 663.0000 - val_fn: 201.0000 - val_accuracy: 0.7222 - val_precision: 0.5778 - val_recall: 0.4370 - val_auc: 0.7012 - val_prc: 0.5255\n",
      "Epoch 107/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0316 - tp: 1390.0000 - fp: 20.0000 - tn: 3087.0000 - fn: 39.0000 - accuracy: 0.9870 - precision: 0.9858 - recall: 0.9727 - auc: 0.9994 - prc: 0.9988 - val_loss: 1.4605 - val_tp: 164.0000 - val_fp: 132.0000 - val_tn: 645.0000 - val_fn: 193.0000 - val_accuracy: 0.7134 - val_precision: 0.5541 - val_recall: 0.4594 - val_auc: 0.7014 - val_prc: 0.5256\n",
      "Epoch 108/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0354 - tp: 1388.0000 - fp: 30.0000 - tn: 3077.0000 - fn: 41.0000 - accuracy: 0.9843 - precision: 0.9788 - recall: 0.9713 - auc: 0.9989 - prc: 0.9981 - val_loss: 1.4548 - val_tp: 162.0000 - val_fp: 130.0000 - val_tn: 647.0000 - val_fn: 195.0000 - val_accuracy: 0.7134 - val_precision: 0.5548 - val_recall: 0.4538 - val_auc: 0.7002 - val_prc: 0.5263\n",
      "Epoch 109/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0323 - tp: 1393.0000 - fp: 23.0000 - tn: 3084.0000 - fn: 36.0000 - accuracy: 0.9870 - precision: 0.9838 - recall: 0.9748 - auc: 0.9994 - prc: 0.9987 - val_loss: 1.4436 - val_tp: 181.0000 - val_fp: 153.0000 - val_tn: 624.0000 - val_fn: 176.0000 - val_accuracy: 0.7099 - val_precision: 0.5419 - val_recall: 0.5070 - val_auc: 0.7021 - val_prc: 0.5282\n",
      "Epoch 110/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0326 - tp: 1393.0000 - fp: 26.0000 - tn: 3081.0000 - fn: 36.0000 - accuracy: 0.9863 - precision: 0.9817 - recall: 0.9748 - auc: 0.9993 - prc: 0.9985 - val_loss: 1.4568 - val_tp: 176.0000 - val_fp: 151.0000 - val_tn: 626.0000 - val_fn: 181.0000 - val_accuracy: 0.7072 - val_precision: 0.5382 - val_recall: 0.4930 - val_auc: 0.7018 - val_prc: 0.5261\n",
      "Epoch 111/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0308 - tp: 1391.0000 - fp: 24.0000 - tn: 3083.0000 - fn: 38.0000 - accuracy: 0.9863 - precision: 0.9830 - recall: 0.9734 - auc: 0.9994 - prc: 0.9988 - val_loss: 1.4730 - val_tp: 180.0000 - val_fp: 159.0000 - val_tn: 618.0000 - val_fn: 177.0000 - val_accuracy: 0.7037 - val_precision: 0.5310 - val_recall: 0.5042 - val_auc: 0.7021 - val_prc: 0.5252\n",
      "Epoch 112/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0318 - tp: 1396.0000 - fp: 22.0000 - tn: 3085.0000 - fn: 33.0000 - accuracy: 0.9879 - precision: 0.9845 - recall: 0.9769 - auc: 0.9994 - prc: 0.9987 - val_loss: 1.4783 - val_tp: 166.0000 - val_fp: 134.0000 - val_tn: 643.0000 - val_fn: 191.0000 - val_accuracy: 0.7134 - val_precision: 0.5533 - val_recall: 0.4650 - val_auc: 0.6982 - val_prc: 0.5239\n",
      "Epoch 113/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0303 - tp: 1395.0000 - fp: 17.0000 - tn: 3090.0000 - fn: 34.0000 - accuracy: 0.9888 - precision: 0.9880 - recall: 0.9762 - auc: 0.9995 - prc: 0.9989 - val_loss: 1.5112 - val_tp: 160.0000 - val_fp: 128.0000 - val_tn: 649.0000 - val_fn: 197.0000 - val_accuracy: 0.7134 - val_precision: 0.5556 - val_recall: 0.4482 - val_auc: 0.6967 - val_prc: 0.5252\n",
      "Epoch 114/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0328 - tp: 1389.0000 - fp: 22.0000 - tn: 3085.0000 - fn: 40.0000 - accuracy: 0.9863 - precision: 0.9844 - recall: 0.9720 - auc: 0.9994 - prc: 0.9986 - val_loss: 1.5060 - val_tp: 161.0000 - val_fp: 133.0000 - val_tn: 644.0000 - val_fn: 196.0000 - val_accuracy: 0.7099 - val_precision: 0.5476 - val_recall: 0.4510 - val_auc: 0.6982 - val_prc: 0.5260\n",
      "Epoch 115/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0327 - tp: 1392.0000 - fp: 26.0000 - tn: 3081.0000 - fn: 37.0000 - accuracy: 0.9861 - precision: 0.9817 - recall: 0.9741 - auc: 0.9993 - prc: 0.9986 - val_loss: 1.4976 - val_tp: 159.0000 - val_fp: 123.0000 - val_tn: 654.0000 - val_fn: 198.0000 - val_accuracy: 0.7169 - val_precision: 0.5638 - val_recall: 0.4454 - val_auc: 0.6972 - val_prc: 0.5237\n",
      "Epoch 116/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0305 - tp: 1396.0000 - fp: 24.0000 - tn: 3083.0000 - fn: 33.0000 - accuracy: 0.9874 - precision: 0.9831 - recall: 0.9769 - auc: 0.9994 - prc: 0.9988 - val_loss: 1.5447 - val_tp: 151.0000 - val_fp: 117.0000 - val_tn: 660.0000 - val_fn: 206.0000 - val_accuracy: 0.7152 - val_precision: 0.5634 - val_recall: 0.4230 - val_auc: 0.6943 - val_prc: 0.5217\n",
      "Epoch 117/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0314 - tp: 1395.0000 - fp: 24.0000 - tn: 3083.0000 - fn: 34.0000 - accuracy: 0.9872 - precision: 0.9831 - recall: 0.9762 - auc: 0.9994 - prc: 0.9987 - val_loss: 1.5258 - val_tp: 160.0000 - val_fp: 130.0000 - val_tn: 647.0000 - val_fn: 197.0000 - val_accuracy: 0.7116 - val_precision: 0.5517 - val_recall: 0.4482 - val_auc: 0.6967 - val_prc: 0.5249\n",
      "Epoch 118/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0311 - tp: 1394.0000 - fp: 21.0000 - tn: 3086.0000 - fn: 35.0000 - accuracy: 0.9877 - precision: 0.9852 - recall: 0.9755 - auc: 0.9994 - prc: 0.9987 - val_loss: 1.5231 - val_tp: 167.0000 - val_fp: 142.0000 - val_tn: 635.0000 - val_fn: 190.0000 - val_accuracy: 0.7072 - val_precision: 0.5405 - val_recall: 0.4678 - val_auc: 0.6975 - val_prc: 0.5226\n",
      "Epoch 119/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0317 - tp: 1389.0000 - fp: 24.0000 - tn: 3083.0000 - fn: 40.0000 - accuracy: 0.9859 - precision: 0.9830 - recall: 0.9720 - auc: 0.9993 - prc: 0.9987 - val_loss: 1.5191 - val_tp: 176.0000 - val_fp: 157.0000 - val_tn: 620.0000 - val_fn: 181.0000 - val_accuracy: 0.7019 - val_precision: 0.5285 - val_recall: 0.4930 - val_auc: 0.6958 - val_prc: 0.5198\n",
      "Epoch 120/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0284 - tp: 1401.0000 - fp: 18.0000 - tn: 3089.0000 - fn: 28.0000 - accuracy: 0.9899 - precision: 0.9873 - recall: 0.9804 - auc: 0.9995 - prc: 0.9989 - val_loss: 1.5285 - val_tp: 186.0000 - val_fp: 171.0000 - val_tn: 606.0000 - val_fn: 171.0000 - val_accuracy: 0.6984 - val_precision: 0.5210 - val_recall: 0.5210 - val_auc: 0.6975 - val_prc: 0.5194\n",
      "Epoch 121/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0283 - tp: 1397.0000 - fp: 23.0000 - tn: 3084.0000 - fn: 32.0000 - accuracy: 0.9879 - precision: 0.9838 - recall: 0.9776 - auc: 0.9995 - prc: 0.9990 - val_loss: 1.5312 - val_tp: 168.0000 - val_fp: 141.0000 - val_tn: 636.0000 - val_fn: 189.0000 - val_accuracy: 0.7090 - val_precision: 0.5437 - val_recall: 0.4706 - val_auc: 0.6973 - val_prc: 0.5218\n",
      "Epoch 122/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0316 - tp: 1389.0000 - fp: 23.0000 - tn: 3084.0000 - fn: 40.0000 - accuracy: 0.9861 - precision: 0.9837 - recall: 0.9720 - auc: 0.9994 - prc: 0.9987 - val_loss: 1.5422 - val_tp: 185.0000 - val_fp: 176.0000 - val_tn: 601.0000 - val_fn: 172.0000 - val_accuracy: 0.6931 - val_precision: 0.5125 - val_recall: 0.5182 - val_auc: 0.7002 - val_prc: 0.5203\n",
      "Epoch 123/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0291 - tp: 1395.0000 - fp: 21.0000 - tn: 3086.0000 - fn: 34.0000 - accuracy: 0.9879 - precision: 0.9852 - recall: 0.9762 - auc: 0.9995 - prc: 0.9989 - val_loss: 1.5720 - val_tp: 155.0000 - val_fp: 125.0000 - val_tn: 652.0000 - val_fn: 202.0000 - val_accuracy: 0.7116 - val_precision: 0.5536 - val_recall: 0.4342 - val_auc: 0.6934 - val_prc: 0.5199\n",
      "Epoch 124/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0318 - tp: 1391.0000 - fp: 23.0000 - tn: 3084.0000 - fn: 38.0000 - accuracy: 0.9866 - precision: 0.9837 - recall: 0.9734 - auc: 0.9993 - prc: 0.9985 - val_loss: 1.5561 - val_tp: 188.0000 - val_fp: 193.0000 - val_tn: 584.0000 - val_fn: 169.0000 - val_accuracy: 0.6808 - val_precision: 0.4934 - val_recall: 0.5266 - val_auc: 0.6998 - val_prc: 0.5114\n",
      "Epoch 125/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0280 - tp: 1394.0000 - fp: 22.0000 - tn: 3085.0000 - fn: 35.0000 - accuracy: 0.9874 - precision: 0.9845 - recall: 0.9755 - auc: 0.9995 - prc: 0.9990 - val_loss: 1.5598 - val_tp: 173.0000 - val_fp: 154.0000 - val_tn: 623.0000 - val_fn: 184.0000 - val_accuracy: 0.7019 - val_precision: 0.5291 - val_recall: 0.4846 - val_auc: 0.6953 - val_prc: 0.5203\n",
      "Epoch 126/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0297 - tp: 1389.0000 - fp: 21.0000 - tn: 3086.0000 - fn: 40.0000 - accuracy: 0.9866 - precision: 0.9851 - recall: 0.9720 - auc: 0.9995 - prc: 0.9989 - val_loss: 1.5716 - val_tp: 165.0000 - val_fp: 139.0000 - val_tn: 638.0000 - val_fn: 192.0000 - val_accuracy: 0.7081 - val_precision: 0.5428 - val_recall: 0.4622 - val_auc: 0.6951 - val_prc: 0.5227\n",
      "Epoch 127/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0290 - tp: 1392.0000 - fp: 18.0000 - tn: 3089.0000 - fn: 37.0000 - accuracy: 0.9879 - precision: 0.9872 - recall: 0.9741 - auc: 0.9995 - prc: 0.9989 - val_loss: 1.5759 - val_tp: 170.0000 - val_fp: 146.0000 - val_tn: 631.0000 - val_fn: 187.0000 - val_accuracy: 0.7063 - val_precision: 0.5380 - val_recall: 0.4762 - val_auc: 0.6950 - val_prc: 0.5203\n",
      "Epoch 128/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0292 - tp: 1393.0000 - fp: 22.0000 - tn: 3085.0000 - fn: 36.0000 - accuracy: 0.9872 - precision: 0.9845 - recall: 0.9748 - auc: 0.9995 - prc: 0.9989 - val_loss: 1.5861 - val_tp: 163.0000 - val_fp: 136.0000 - val_tn: 641.0000 - val_fn: 194.0000 - val_accuracy: 0.7090 - val_precision: 0.5452 - val_recall: 0.4566 - val_auc: 0.6945 - val_prc: 0.5192\n",
      "Epoch 129/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0289 - tp: 1394.0000 - fp: 20.0000 - tn: 3087.0000 - fn: 35.0000 - accuracy: 0.9879 - precision: 0.9859 - recall: 0.9755 - auc: 0.9995 - prc: 0.9989 - val_loss: 1.5994 - val_tp: 163.0000 - val_fp: 138.0000 - val_tn: 639.0000 - val_fn: 194.0000 - val_accuracy: 0.7072 - val_precision: 0.5415 - val_recall: 0.4566 - val_auc: 0.6956 - val_prc: 0.5195\n",
      "Epoch 130/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0277 - tp: 1391.0000 - fp: 18.0000 - tn: 3089.0000 - fn: 38.0000 - accuracy: 0.9877 - precision: 0.9872 - recall: 0.9734 - auc: 0.9995 - prc: 0.9990 - val_loss: 1.5840 - val_tp: 183.0000 - val_fp: 171.0000 - val_tn: 606.0000 - val_fn: 174.0000 - val_accuracy: 0.6958 - val_precision: 0.5169 - val_recall: 0.5126 - val_auc: 0.6975 - val_prc: 0.5197\n",
      "Epoch 131/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0293 - tp: 1393.0000 - fp: 22.0000 - tn: 3085.0000 - fn: 36.0000 - accuracy: 0.9872 - precision: 0.9845 - recall: 0.9748 - auc: 0.9995 - prc: 0.9989 - val_loss: 1.6072 - val_tp: 185.0000 - val_fp: 178.0000 - val_tn: 599.0000 - val_fn: 172.0000 - val_accuracy: 0.6914 - val_precision: 0.5096 - val_recall: 0.5182 - val_auc: 0.6949 - val_prc: 0.5104\n",
      "Epoch 132/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0295 - tp: 1393.0000 - fp: 23.0000 - tn: 3084.0000 - fn: 36.0000 - accuracy: 0.9870 - precision: 0.9838 - recall: 0.9748 - auc: 0.9995 - prc: 0.9989 - val_loss: 1.6037 - val_tp: 185.0000 - val_fp: 174.0000 - val_tn: 603.0000 - val_fn: 172.0000 - val_accuracy: 0.6949 - val_precision: 0.5153 - val_recall: 0.5182 - val_auc: 0.6953 - val_prc: 0.5103\n",
      "Epoch 133/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0301 - tp: 1386.0000 - fp: 23.0000 - tn: 3084.0000 - fn: 43.0000 - accuracy: 0.9854 - precision: 0.9837 - recall: 0.9699 - auc: 0.9994 - prc: 0.9988 - val_loss: 1.6178 - val_tp: 184.0000 - val_fp: 173.0000 - val_tn: 604.0000 - val_fn: 173.0000 - val_accuracy: 0.6949 - val_precision: 0.5154 - val_recall: 0.5154 - val_auc: 0.6973 - val_prc: 0.5146\n",
      "Epoch 134/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0281 - tp: 1395.0000 - fp: 25.0000 - tn: 3082.0000 - fn: 34.0000 - accuracy: 0.9870 - precision: 0.9824 - recall: 0.9762 - auc: 0.9995 - prc: 0.9990 - val_loss: 1.6223 - val_tp: 174.0000 - val_fp: 150.0000 - val_tn: 627.0000 - val_fn: 183.0000 - val_accuracy: 0.7063 - val_precision: 0.5370 - val_recall: 0.4874 - val_auc: 0.6934 - val_prc: 0.5175\n",
      "Epoch 135/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0283 - tp: 1395.0000 - fp: 23.0000 - tn: 3084.0000 - fn: 34.0000 - accuracy: 0.9874 - precision: 0.9838 - recall: 0.9762 - auc: 0.9995 - prc: 0.9989 - val_loss: 1.6489 - val_tp: 162.0000 - val_fp: 135.0000 - val_tn: 642.0000 - val_fn: 195.0000 - val_accuracy: 0.7090 - val_precision: 0.5455 - val_recall: 0.4538 - val_auc: 0.6955 - val_prc: 0.5187\n",
      "Epoch 136/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0290 - tp: 1390.0000 - fp: 23.0000 - tn: 3084.0000 - fn: 39.0000 - accuracy: 0.9863 - precision: 0.9837 - recall: 0.9727 - auc: 0.9995 - prc: 0.9988 - val_loss: 1.6138 - val_tp: 180.0000 - val_fp: 168.0000 - val_tn: 609.0000 - val_fn: 177.0000 - val_accuracy: 0.6958 - val_precision: 0.5172 - val_recall: 0.5042 - val_auc: 0.6941 - val_prc: 0.5171\n",
      "Epoch 137/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0295 - tp: 1392.0000 - fp: 23.0000 - tn: 3084.0000 - fn: 37.0000 - accuracy: 0.9868 - precision: 0.9837 - recall: 0.9741 - auc: 0.9994 - prc: 0.9988 - val_loss: 1.6299 - val_tp: 162.0000 - val_fp: 139.0000 - val_tn: 638.0000 - val_fn: 195.0000 - val_accuracy: 0.7055 - val_precision: 0.5382 - val_recall: 0.4538 - val_auc: 0.6962 - val_prc: 0.5203\n",
      "Epoch 138/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0275 - tp: 1393.0000 - fp: 18.0000 - tn: 3089.0000 - fn: 36.0000 - accuracy: 0.9881 - precision: 0.9872 - recall: 0.9748 - auc: 0.9995 - prc: 0.9990 - val_loss: 1.6215 - val_tp: 179.0000 - val_fp: 160.0000 - val_tn: 617.0000 - val_fn: 178.0000 - val_accuracy: 0.7019 - val_precision: 0.5280 - val_recall: 0.5014 - val_auc: 0.6951 - val_prc: 0.5165\n",
      "Epoch 139/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0278 - tp: 1394.0000 - fp: 22.0000 - tn: 3085.0000 - fn: 35.0000 - accuracy: 0.9874 - precision: 0.9845 - recall: 0.9755 - auc: 0.9995 - prc: 0.9990 - val_loss: 1.6653 - val_tp: 160.0000 - val_fp: 130.0000 - val_tn: 647.0000 - val_fn: 197.0000 - val_accuracy: 0.7116 - val_precision: 0.5517 - val_recall: 0.4482 - val_auc: 0.6957 - val_prc: 0.5203\n",
      "Epoch 140/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0295 - tp: 1392.0000 - fp: 21.0000 - tn: 3086.0000 - fn: 37.0000 - accuracy: 0.9872 - precision: 0.9851 - recall: 0.9741 - auc: 0.9994 - prc: 0.9988 - val_loss: 1.6355 - val_tp: 177.0000 - val_fp: 160.0000 - val_tn: 617.0000 - val_fn: 180.0000 - val_accuracy: 0.7002 - val_precision: 0.5252 - val_recall: 0.4958 - val_auc: 0.6956 - val_prc: 0.5159\n",
      "Epoch 141/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0303 - tp: 1391.0000 - fp: 21.0000 - tn: 3086.0000 - fn: 38.0000 - accuracy: 0.9870 - precision: 0.9851 - recall: 0.9734 - auc: 0.9994 - prc: 0.9987 - val_loss: 1.6470 - val_tp: 176.0000 - val_fp: 156.0000 - val_tn: 621.0000 - val_fn: 181.0000 - val_accuracy: 0.7028 - val_precision: 0.5301 - val_recall: 0.4930 - val_auc: 0.6938 - val_prc: 0.5163\n",
      "Epoch 142/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0257 - tp: 1396.0000 - fp: 18.0000 - tn: 3089.0000 - fn: 33.0000 - accuracy: 0.9888 - precision: 0.9873 - recall: 0.9769 - auc: 0.9996 - prc: 0.9991 - val_loss: 1.6736 - val_tp: 164.0000 - val_fp: 141.0000 - val_tn: 636.0000 - val_fn: 193.0000 - val_accuracy: 0.7055 - val_precision: 0.5377 - val_recall: 0.4594 - val_auc: 0.6934 - val_prc: 0.5197\n",
      "Epoch 143/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0284 - tp: 1394.0000 - fp: 22.0000 - tn: 3085.0000 - fn: 35.0000 - accuracy: 0.9874 - precision: 0.9845 - recall: 0.9755 - auc: 0.9995 - prc: 0.9989 - val_loss: 1.6855 - val_tp: 163.0000 - val_fp: 135.0000 - val_tn: 642.0000 - val_fn: 194.0000 - val_accuracy: 0.7099 - val_precision: 0.5470 - val_recall: 0.4566 - val_auc: 0.6930 - val_prc: 0.5207\n",
      "Epoch 144/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0281 - tp: 1395.0000 - fp: 19.0000 - tn: 3088.0000 - fn: 34.0000 - accuracy: 0.9883 - precision: 0.9866 - recall: 0.9762 - auc: 0.9995 - prc: 0.9989 - val_loss: 1.6936 - val_tp: 160.0000 - val_fp: 133.0000 - val_tn: 644.0000 - val_fn: 197.0000 - val_accuracy: 0.7090 - val_precision: 0.5461 - val_recall: 0.4482 - val_auc: 0.6948 - val_prc: 0.5219\n",
      "Epoch 145/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0269 - tp: 1398.0000 - fp: 21.0000 - tn: 3086.0000 - fn: 31.0000 - accuracy: 0.9885 - precision: 0.9852 - recall: 0.9783 - auc: 0.9995 - prc: 0.9990 - val_loss: 1.6789 - val_tp: 167.0000 - val_fp: 139.0000 - val_tn: 638.0000 - val_fn: 190.0000 - val_accuracy: 0.7099 - val_precision: 0.5458 - val_recall: 0.4678 - val_auc: 0.6961 - val_prc: 0.5229\n",
      "Epoch 146/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0263 - tp: 1391.0000 - fp: 25.0000 - tn: 3082.0000 - fn: 38.0000 - accuracy: 0.9861 - precision: 0.9823 - recall: 0.9734 - auc: 0.9996 - prc: 0.9991 - val_loss: 1.6955 - val_tp: 182.0000 - val_fp: 171.0000 - val_tn: 606.0000 - val_fn: 175.0000 - val_accuracy: 0.6949 - val_precision: 0.5156 - val_recall: 0.5098 - val_auc: 0.6912 - val_prc: 0.5079\n",
      "Epoch 147/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0261 - tp: 1397.0000 - fp: 21.0000 - tn: 3086.0000 - fn: 32.0000 - accuracy: 0.9883 - precision: 0.9852 - recall: 0.9776 - auc: 0.9995 - prc: 0.9990 - val_loss: 1.6896 - val_tp: 167.0000 - val_fp: 143.0000 - val_tn: 634.0000 - val_fn: 190.0000 - val_accuracy: 0.7063 - val_precision: 0.5387 - val_recall: 0.4678 - val_auc: 0.6960 - val_prc: 0.5190\n",
      "Epoch 148/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0260 - tp: 1393.0000 - fp: 18.0000 - tn: 3089.0000 - fn: 36.0000 - accuracy: 0.9881 - precision: 0.9872 - recall: 0.9748 - auc: 0.9996 - prc: 0.9991 - val_loss: 1.6998 - val_tp: 177.0000 - val_fp: 159.0000 - val_tn: 618.0000 - val_fn: 180.0000 - val_accuracy: 0.7011 - val_precision: 0.5268 - val_recall: 0.4958 - val_auc: 0.6926 - val_prc: 0.5081\n",
      "Epoch 149/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0294 - tp: 1391.0000 - fp: 27.0000 - tn: 3080.0000 - fn: 38.0000 - accuracy: 0.9857 - precision: 0.9810 - recall: 0.9734 - auc: 0.9995 - prc: 0.9988 - val_loss: 1.7049 - val_tp: 174.0000 - val_fp: 158.0000 - val_tn: 619.0000 - val_fn: 183.0000 - val_accuracy: 0.6993 - val_precision: 0.5241 - val_recall: 0.4874 - val_auc: 0.6933 - val_prc: 0.5104\n",
      "Epoch 150/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0263 - tp: 1389.0000 - fp: 17.0000 - tn: 3090.0000 - fn: 40.0000 - accuracy: 0.9874 - precision: 0.9879 - recall: 0.9720 - auc: 0.9995 - prc: 0.9990 - val_loss: 1.6958 - val_tp: 175.0000 - val_fp: 158.0000 - val_tn: 619.0000 - val_fn: 182.0000 - val_accuracy: 0.7002 - val_precision: 0.5255 - val_recall: 0.4902 - val_auc: 0.6951 - val_prc: 0.5142\n",
      "Epoch 151/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0271 - tp: 1393.0000 - fp: 22.0000 - tn: 3085.0000 - fn: 36.0000 - accuracy: 0.9872 - precision: 0.9845 - recall: 0.9748 - auc: 0.9995 - prc: 0.9990 - val_loss: 1.7167 - val_tp: 167.0000 - val_fp: 144.0000 - val_tn: 633.0000 - val_fn: 190.0000 - val_accuracy: 0.7055 - val_precision: 0.5370 - val_recall: 0.4678 - val_auc: 0.6977 - val_prc: 0.5202\n",
      "Epoch 152/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0298 - tp: 1393.0000 - fp: 28.0000 - tn: 3079.0000 - fn: 36.0000 - accuracy: 0.9859 - precision: 0.9803 - recall: 0.9748 - auc: 0.9994 - prc: 0.9987 - val_loss: 1.7135 - val_tp: 168.0000 - val_fp: 147.0000 - val_tn: 630.0000 - val_fn: 189.0000 - val_accuracy: 0.7037 - val_precision: 0.5333 - val_recall: 0.4706 - val_auc: 0.6973 - val_prc: 0.5217\n"
     ]
    }
   ],
   "source": [
    "# Simple Model\n",
    "def nn_builder(text_vectorizer):\n",
    "    nn = Sequential()\n",
    "    nn.add(Input(shape=(1,), dtype=\"string\"))\n",
    "    nn.add(text_vectorizer)\n",
    "    nn.add(Dense(500, activation=\"relu\"))\n",
    "    nn.add(Dropout(0.4))\n",
    "    nn.add(Dense(1, activation=\"sigmoid\"))\n",
    "    nn.compile(loss=experiment_parameters['loss'],\n",
    "               optimizer=experiment_parameters['optimizer'],\n",
    "               metrics=METRICS)\n",
    "    return nn\n",
    "\n",
    "\n",
    "nn_model = nn_builder(tfidf_vectorizer)\n",
    "\n",
    "history = nn_model.fit(X_train, y_train,\n",
    "                       experiment_parameters['batch_size'],\n",
    "                       experiment_parameters['epochs'],\n",
    "                       validation_data=(X_test, y_test),\n",
    "                       callbacks=[EarlyStopping(monitor=\"loss\",\n",
    "                                                patience=10,\n",
    "                                                restore_best_weights=True)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.767189</td>\n",
       "      <td>0.537705</td>\n",
       "      <td>0.705467</td>\n",
       "      <td>0.652447</td>\n",
       "      <td>0.694944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.818533</td>\n",
       "      <td>0.459384</td>\n",
       "      <td>0.705467</td>\n",
       "      <td>0.638958</td>\n",
       "      <td>0.705467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.792030</td>\n",
       "      <td>0.495468</td>\n",
       "      <td>0.705467</td>\n",
       "      <td>0.643749</td>\n",
       "      <td>0.698668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>777.000000</td>\n",
       "      <td>357.000000</td>\n",
       "      <td>0.705467</td>\n",
       "      <td>1134.000000</td>\n",
       "      <td>1134.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0           1  accuracy    macro avg  weighted avg\n",
       "precision    0.767189    0.537705  0.705467     0.652447      0.694944\n",
       "recall       0.818533    0.459384  0.705467     0.638958      0.705467\n",
       "f1-score     0.792030    0.495468  0.705467     0.643749      0.698668\n",
       "support    777.000000  357.000000  0.705467  1134.000000   1134.000000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds = nn_model.predict(X_test)\n",
    "pd.DataFrame(classification_report(\n",
    "    y_test, np.where(test_preds >= 0.5, 1, 0), output_dict=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "71/71 [==============================] - 2s 18ms/step - loss: 0.8792 - tp: 563.0000 - fp: 735.0000 - tn: 3149.0000 - fn: 1223.0000 - accuracy: 0.6547 - precision: 0.4337 - recall: 0.3152 - auc: 0.5824 - prc: 0.4022 - val_loss: 0.5867 - val_tp: 50.0000 - val_fp: 11.0000 - val_tn: 766.0000 - val_fn: 307.0000 - val_accuracy: 0.7196 - val_precision: 0.8197 - val_recall: 0.1401 - val_auc: 0.6608 - val_prc: 0.5103\n",
      "Epoch 2/200\n",
      "71/71 [==============================] - 1s 12ms/step - loss: 0.5494 - tp: 487.0000 - fp: 227.0000 - tn: 2880.0000 - fn: 942.0000 - accuracy: 0.7423 - precision: 0.6821 - recall: 0.3408 - auc: 0.7321 - prc: 0.5801 - val_loss: 0.5560 - val_tp: 120.0000 - val_fp: 47.0000 - val_tn: 730.0000 - val_fn: 237.0000 - val_accuracy: 0.7496 - val_precision: 0.7186 - val_recall: 0.3361 - val_auc: 0.7208 - val_prc: 0.5676\n",
      "Epoch 3/200\n",
      "71/71 [==============================] - 1s 13ms/step - loss: 0.4964 - tp: 672.0000 - fp: 258.0000 - tn: 2849.0000 - fn: 757.0000 - accuracy: 0.7762 - precision: 0.7226 - recall: 0.4703 - auc: 0.7992 - prc: 0.6550 - val_loss: 0.5560 - val_tp: 123.0000 - val_fp: 51.0000 - val_tn: 726.0000 - val_fn: 234.0000 - val_accuracy: 0.7487 - val_precision: 0.7069 - val_recall: 0.3445 - val_auc: 0.7252 - val_prc: 0.5752\n",
      "Epoch 4/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.4325 - tp: 806.0000 - fp: 250.0000 - tn: 2857.0000 - fn: 623.0000 - accuracy: 0.8075 - precision: 0.7633 - recall: 0.5640 - auc: 0.8561 - prc: 0.7468 - val_loss: 0.5862 - val_tp: 112.0000 - val_fp: 42.0000 - val_tn: 735.0000 - val_fn: 245.0000 - val_accuracy: 0.7469 - val_precision: 0.7273 - val_recall: 0.3137 - val_auc: 0.7253 - val_prc: 0.5770\n",
      "Epoch 5/200\n",
      "71/71 [==============================] - 1s 13ms/step - loss: 0.3845 - tp: 892.0000 - fp: 238.0000 - tn: 2869.0000 - fn: 537.0000 - accuracy: 0.8291 - precision: 0.7894 - recall: 0.6242 - auc: 0.8926 - prc: 0.7975 - val_loss: 0.5829 - val_tp: 193.0000 - val_fp: 140.0000 - val_tn: 637.0000 - val_fn: 164.0000 - val_accuracy: 0.7319 - val_precision: 0.5796 - val_recall: 0.5406 - val_auc: 0.7399 - val_prc: 0.5728\n",
      "Epoch 6/200\n",
      "71/71 [==============================] - 1s 13ms/step - loss: 0.3360 - tp: 986.0000 - fp: 238.0000 - tn: 2869.0000 - fn: 443.0000 - accuracy: 0.8499 - precision: 0.8056 - recall: 0.6900 - auc: 0.9211 - prc: 0.8486 - val_loss: 0.6025 - val_tp: 161.0000 - val_fp: 85.0000 - val_tn: 692.0000 - val_fn: 196.0000 - val_accuracy: 0.7522 - val_precision: 0.6545 - val_recall: 0.4510 - val_auc: 0.7368 - val_prc: 0.5784\n",
      "Epoch 7/200\n",
      "71/71 [==============================] - 1s 13ms/step - loss: 0.3124 - tp: 1034.0000 - fp: 215.0000 - tn: 2892.0000 - fn: 395.0000 - accuracy: 0.8655 - precision: 0.8279 - recall: 0.7236 - auc: 0.9305 - prc: 0.8677 - val_loss: 0.6373 - val_tp: 155.0000 - val_fp: 82.0000 - val_tn: 695.0000 - val_fn: 202.0000 - val_accuracy: 0.7496 - val_precision: 0.6540 - val_recall: 0.4342 - val_auc: 0.7322 - val_prc: 0.5786\n",
      "Epoch 8/200\n",
      "71/71 [==============================] - 1s 13ms/step - loss: 0.2711 - tp: 1107.0000 - fp: 195.0000 - tn: 2912.0000 - fn: 322.0000 - accuracy: 0.8860 - precision: 0.8502 - recall: 0.7747 - auc: 0.9502 - prc: 0.9004 - val_loss: 0.6378 - val_tp: 173.0000 - val_fp: 109.0000 - val_tn: 668.0000 - val_fn: 184.0000 - val_accuracy: 0.7416 - val_precision: 0.6135 - val_recall: 0.4846 - val_auc: 0.7354 - val_prc: 0.5790\n",
      "Epoch 9/200\n",
      "71/71 [==============================] - 1s 13ms/step - loss: 0.2330 - tp: 1139.0000 - fp: 161.0000 - tn: 2946.0000 - fn: 290.0000 - accuracy: 0.9006 - precision: 0.8762 - recall: 0.7971 - auc: 0.9642 - prc: 0.9292 - val_loss: 0.7024 - val_tp: 206.0000 - val_fp: 178.0000 - val_tn: 599.0000 - val_fn: 151.0000 - val_accuracy: 0.7099 - val_precision: 0.5365 - val_recall: 0.5770 - val_auc: 0.7302 - val_prc: 0.5591\n",
      "Epoch 10/200\n",
      "71/71 [==============================] - 1s 12ms/step - loss: 0.2083 - tp: 1203.0000 - fp: 157.0000 - tn: 2950.0000 - fn: 226.0000 - accuracy: 0.9156 - precision: 0.8846 - recall: 0.8418 - auc: 0.9713 - prc: 0.9416 - val_loss: 0.7598 - val_tp: 141.0000 - val_fp: 72.0000 - val_tn: 705.0000 - val_fn: 216.0000 - val_accuracy: 0.7460 - val_precision: 0.6620 - val_recall: 0.3950 - val_auc: 0.7266 - val_prc: 0.5777\n",
      "Epoch 11/200\n",
      "71/71 [==============================] - 1s 13ms/step - loss: 0.1722 - tp: 1239.0000 - fp: 120.0000 - tn: 2987.0000 - fn: 190.0000 - accuracy: 0.9317 - precision: 0.9117 - recall: 0.8670 - auc: 0.9818 - prc: 0.9634 - val_loss: 0.8552 - val_tp: 130.0000 - val_fp: 65.0000 - val_tn: 712.0000 - val_fn: 227.0000 - val_accuracy: 0.7425 - val_precision: 0.6667 - val_recall: 0.3641 - val_auc: 0.7219 - val_prc: 0.5730\n",
      "Epoch 12/200\n",
      "71/71 [==============================] - 1s 12ms/step - loss: 0.1453 - tp: 1283.0000 - fp: 100.0000 - tn: 3007.0000 - fn: 146.0000 - accuracy: 0.9458 - precision: 0.9277 - recall: 0.8978 - auc: 0.9868 - prc: 0.9735 - val_loss: 0.8551 - val_tp: 149.0000 - val_fp: 90.0000 - val_tn: 687.0000 - val_fn: 208.0000 - val_accuracy: 0.7372 - val_precision: 0.6234 - val_recall: 0.4174 - val_auc: 0.7258 - val_prc: 0.5692\n",
      "Epoch 13/200\n",
      "71/71 [==============================] - 1s 13ms/step - loss: 0.1294 - tp: 1297.0000 - fp: 100.0000 - tn: 3007.0000 - fn: 132.0000 - accuracy: 0.9489 - precision: 0.9284 - recall: 0.9076 - auc: 0.9895 - prc: 0.9790 - val_loss: 0.8540 - val_tp: 181.0000 - val_fp: 131.0000 - val_tn: 646.0000 - val_fn: 176.0000 - val_accuracy: 0.7293 - val_precision: 0.5801 - val_recall: 0.5070 - val_auc: 0.7242 - val_prc: 0.5608\n",
      "Epoch 14/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.1144 - tp: 1318.0000 - fp: 74.0000 - tn: 3033.0000 - fn: 111.0000 - accuracy: 0.9592 - precision: 0.9468 - recall: 0.9223 - auc: 0.9921 - prc: 0.9839 - val_loss: 0.9024 - val_tp: 189.0000 - val_fp: 150.0000 - val_tn: 627.0000 - val_fn: 168.0000 - val_accuracy: 0.7196 - val_precision: 0.5575 - val_recall: 0.5294 - val_auc: 0.7202 - val_prc: 0.5547\n",
      "Epoch 15/200\n",
      "71/71 [==============================] - 1s 16ms/step - loss: 0.0922 - tp: 1345.0000 - fp: 67.0000 - tn: 3040.0000 - fn: 84.0000 - accuracy: 0.9667 - precision: 0.9525 - recall: 0.9412 - auc: 0.9952 - prc: 0.9900 - val_loss: 0.9589 - val_tp: 164.0000 - val_fp: 114.0000 - val_tn: 663.0000 - val_fn: 193.0000 - val_accuracy: 0.7293 - val_precision: 0.5899 - val_recall: 0.4594 - val_auc: 0.7215 - val_prc: 0.5591\n",
      "Epoch 16/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0772 - tp: 1362.0000 - fp: 48.0000 - tn: 3059.0000 - fn: 67.0000 - accuracy: 0.9746 - precision: 0.9660 - recall: 0.9531 - auc: 0.9967 - prc: 0.9931 - val_loss: 0.9979 - val_tp: 165.0000 - val_fp: 109.0000 - val_tn: 668.0000 - val_fn: 192.0000 - val_accuracy: 0.7346 - val_precision: 0.6022 - val_recall: 0.4622 - val_auc: 0.7196 - val_prc: 0.5612\n",
      "Epoch 17/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0825 - tp: 1346.0000 - fp: 48.0000 - tn: 3059.0000 - fn: 83.0000 - accuracy: 0.9711 - precision: 0.9656 - recall: 0.9419 - auc: 0.9955 - prc: 0.9912 - val_loss: 0.9979 - val_tp: 198.0000 - val_fp: 162.0000 - val_tn: 615.0000 - val_fn: 159.0000 - val_accuracy: 0.7169 - val_precision: 0.5500 - val_recall: 0.5546 - val_auc: 0.7192 - val_prc: 0.5534\n",
      "Epoch 18/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0773 - tp: 1357.0000 - fp: 50.0000 - tn: 3057.0000 - fn: 72.0000 - accuracy: 0.9731 - precision: 0.9645 - recall: 0.9496 - auc: 0.9958 - prc: 0.9918 - val_loss: 0.9999 - val_tp: 197.0000 - val_fp: 171.0000 - val_tn: 606.0000 - val_fn: 160.0000 - val_accuracy: 0.7081 - val_precision: 0.5353 - val_recall: 0.5518 - val_auc: 0.7166 - val_prc: 0.5460\n",
      "Epoch 19/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0657 - tp: 1370.0000 - fp: 47.0000 - tn: 3060.0000 - fn: 59.0000 - accuracy: 0.9766 - precision: 0.9668 - recall: 0.9587 - auc: 0.9973 - prc: 0.9945 - val_loss: 1.2039 - val_tp: 134.0000 - val_fp: 78.0000 - val_tn: 699.0000 - val_fn: 223.0000 - val_accuracy: 0.7346 - val_precision: 0.6321 - val_recall: 0.3754 - val_auc: 0.7089 - val_prc: 0.5542\n",
      "Epoch 20/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0598 - tp: 1371.0000 - fp: 41.0000 - tn: 3066.0000 - fn: 58.0000 - accuracy: 0.9782 - precision: 0.9710 - recall: 0.9594 - auc: 0.9977 - prc: 0.9953 - val_loss: 1.1174 - val_tp: 184.0000 - val_fp: 161.0000 - val_tn: 616.0000 - val_fn: 173.0000 - val_accuracy: 0.7055 - val_precision: 0.5333 - val_recall: 0.5154 - val_auc: 0.7089 - val_prc: 0.5390\n",
      "Epoch 21/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0555 - tp: 1373.0000 - fp: 34.0000 - tn: 3073.0000 - fn: 56.0000 - accuracy: 0.9802 - precision: 0.9758 - recall: 0.9608 - auc: 0.9981 - prc: 0.9960 - val_loss: 1.1572 - val_tp: 194.0000 - val_fp: 177.0000 - val_tn: 600.0000 - val_fn: 163.0000 - val_accuracy: 0.7002 - val_precision: 0.5229 - val_recall: 0.5434 - val_auc: 0.7095 - val_prc: 0.5408\n",
      "Epoch 22/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0563 - tp: 1368.0000 - fp: 43.0000 - tn: 3064.0000 - fn: 61.0000 - accuracy: 0.9771 - precision: 0.9695 - recall: 0.9573 - auc: 0.9980 - prc: 0.9959 - val_loss: 1.1733 - val_tp: 181.0000 - val_fp: 147.0000 - val_tn: 630.0000 - val_fn: 176.0000 - val_accuracy: 0.7152 - val_precision: 0.5518 - val_recall: 0.5070 - val_auc: 0.7086 - val_prc: 0.5422\n",
      "Epoch 23/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0477 - tp: 1376.0000 - fp: 37.0000 - tn: 3070.0000 - fn: 53.0000 - accuracy: 0.9802 - precision: 0.9738 - recall: 0.9629 - auc: 0.9986 - prc: 0.9971 - val_loss: 1.2149 - val_tp: 203.0000 - val_fp: 188.0000 - val_tn: 589.0000 - val_fn: 154.0000 - val_accuracy: 0.6984 - val_precision: 0.5192 - val_recall: 0.5686 - val_auc: 0.7122 - val_prc: 0.5429\n",
      "Epoch 24/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0470 - tp: 1378.0000 - fp: 33.0000 - tn: 3074.0000 - fn: 51.0000 - accuracy: 0.9815 - precision: 0.9766 - recall: 0.9643 - auc: 0.9985 - prc: 0.9970 - val_loss: 1.2288 - val_tp: 196.0000 - val_fp: 182.0000 - val_tn: 595.0000 - val_fn: 161.0000 - val_accuracy: 0.6975 - val_precision: 0.5185 - val_recall: 0.5490 - val_auc: 0.7116 - val_prc: 0.5390\n",
      "Epoch 25/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0468 - tp: 1380.0000 - fp: 37.0000 - tn: 3070.0000 - fn: 49.0000 - accuracy: 0.9810 - precision: 0.9739 - recall: 0.9657 - auc: 0.9986 - prc: 0.9970 - val_loss: 1.3050 - val_tp: 157.0000 - val_fp: 107.0000 - val_tn: 670.0000 - val_fn: 200.0000 - val_accuracy: 0.7293 - val_precision: 0.5947 - val_recall: 0.4398 - val_auc: 0.7085 - val_prc: 0.5461\n",
      "Epoch 26/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0411 - tp: 1392.0000 - fp: 35.0000 - tn: 3072.0000 - fn: 37.0000 - accuracy: 0.9841 - precision: 0.9755 - recall: 0.9741 - auc: 0.9989 - prc: 0.9977 - val_loss: 1.3407 - val_tp: 151.0000 - val_fp: 107.0000 - val_tn: 670.0000 - val_fn: 206.0000 - val_accuracy: 0.7240 - val_precision: 0.5853 - val_recall: 0.4230 - val_auc: 0.7008 - val_prc: 0.5396\n",
      "Epoch 27/200\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 0.0491 - tp: 1383.0000 - fp: 41.0000 - tn: 3066.0000 - fn: 46.0000 - accuracy: 0.9808 - precision: 0.9712 - recall: 0.9678 - auc: 0.9981 - prc: 0.9966 - val_loss: 1.2886 - val_tp: 172.0000 - val_fp: 128.0000 - val_tn: 649.0000 - val_fn: 185.0000 - val_accuracy: 0.7240 - val_precision: 0.5733 - val_recall: 0.4818 - val_auc: 0.7092 - val_prc: 0.5432\n",
      "Epoch 28/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0408 - tp: 1385.0000 - fp: 30.0000 - tn: 3077.0000 - fn: 44.0000 - accuracy: 0.9837 - precision: 0.9788 - recall: 0.9692 - auc: 0.9989 - prc: 0.9977 - val_loss: 1.4858 - val_tp: 134.0000 - val_fp: 81.0000 - val_tn: 696.0000 - val_fn: 223.0000 - val_accuracy: 0.7319 - val_precision: 0.6233 - val_recall: 0.3754 - val_auc: 0.6977 - val_prc: 0.5445\n",
      "Epoch 29/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0430 - tp: 1387.0000 - fp: 29.0000 - tn: 3078.0000 - fn: 42.0000 - accuracy: 0.9843 - precision: 0.9795 - recall: 0.9706 - auc: 0.9987 - prc: 0.9974 - val_loss: 1.3767 - val_tp: 154.0000 - val_fp: 107.0000 - val_tn: 670.0000 - val_fn: 203.0000 - val_accuracy: 0.7266 - val_precision: 0.5900 - val_recall: 0.4314 - val_auc: 0.7059 - val_prc: 0.5428\n",
      "Epoch 30/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0396 - tp: 1384.0000 - fp: 27.0000 - tn: 3080.0000 - fn: 45.0000 - accuracy: 0.9841 - precision: 0.9809 - recall: 0.9685 - auc: 0.9989 - prc: 0.9978 - val_loss: 1.4097 - val_tp: 160.0000 - val_fp: 120.0000 - val_tn: 657.0000 - val_fn: 197.0000 - val_accuracy: 0.7205 - val_precision: 0.5714 - val_recall: 0.4482 - val_auc: 0.7073 - val_prc: 0.5437\n",
      "Epoch 31/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0465 - tp: 1378.0000 - fp: 30.0000 - tn: 3077.0000 - fn: 51.0000 - accuracy: 0.9821 - precision: 0.9787 - recall: 0.9643 - auc: 0.9984 - prc: 0.9969 - val_loss: 1.5422 - val_tp: 242.0000 - val_fp: 300.0000 - val_tn: 477.0000 - val_fn: 115.0000 - val_accuracy: 0.6340 - val_precision: 0.4465 - val_recall: 0.6779 - val_auc: 0.7034 - val_prc: 0.5101\n",
      "Epoch 32/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0425 - tp: 1385.0000 - fp: 29.0000 - tn: 3078.0000 - fn: 44.0000 - accuracy: 0.9839 - precision: 0.9795 - recall: 0.9692 - auc: 0.9986 - prc: 0.9965 - val_loss: 1.3954 - val_tp: 202.0000 - val_fp: 183.0000 - val_tn: 594.0000 - val_fn: 155.0000 - val_accuracy: 0.7019 - val_precision: 0.5247 - val_recall: 0.5658 - val_auc: 0.7075 - val_prc: 0.5393\n",
      "Epoch 33/200\n",
      "71/71 [==============================] - 1s 16ms/step - loss: 0.0382 - tp: 1387.0000 - fp: 29.0000 - tn: 3078.0000 - fn: 42.0000 - accuracy: 0.9843 - precision: 0.9795 - recall: 0.9706 - auc: 0.9990 - prc: 0.9979 - val_loss: 1.3921 - val_tp: 182.0000 - val_fp: 149.0000 - val_tn: 628.0000 - val_fn: 175.0000 - val_accuracy: 0.7143 - val_precision: 0.5498 - val_recall: 0.5098 - val_auc: 0.7091 - val_prc: 0.5452\n",
      "Epoch 34/200\n",
      "71/71 [==============================] - 1s 16ms/step - loss: 0.0363 - tp: 1390.0000 - fp: 32.0000 - tn: 3075.0000 - fn: 39.0000 - accuracy: 0.9843 - precision: 0.9775 - recall: 0.9727 - auc: 0.9991 - prc: 0.9982 - val_loss: 1.4030 - val_tp: 169.0000 - val_fp: 129.0000 - val_tn: 648.0000 - val_fn: 188.0000 - val_accuracy: 0.7205 - val_precision: 0.5671 - val_recall: 0.4734 - val_auc: 0.7057 - val_prc: 0.5405\n",
      "Epoch 35/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0363 - tp: 1391.0000 - fp: 33.0000 - tn: 3074.0000 - fn: 38.0000 - accuracy: 0.9843 - precision: 0.9768 - recall: 0.9734 - auc: 0.9991 - prc: 0.9982 - val_loss: 1.4605 - val_tp: 149.0000 - val_fp: 101.0000 - val_tn: 676.0000 - val_fn: 208.0000 - val_accuracy: 0.7275 - val_precision: 0.5960 - val_recall: 0.4174 - val_auc: 0.6971 - val_prc: 0.5421\n",
      "Epoch 36/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0419 - tp: 1389.0000 - fp: 25.0000 - tn: 3082.0000 - fn: 40.0000 - accuracy: 0.9857 - precision: 0.9823 - recall: 0.9720 - auc: 0.9987 - prc: 0.9972 - val_loss: 1.4389 - val_tp: 180.0000 - val_fp: 147.0000 - val_tn: 630.0000 - val_fn: 177.0000 - val_accuracy: 0.7143 - val_precision: 0.5505 - val_recall: 0.5042 - val_auc: 0.7075 - val_prc: 0.5441\n",
      "Epoch 37/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0393 - tp: 1385.0000 - fp: 34.0000 - tn: 3073.0000 - fn: 44.0000 - accuracy: 0.9828 - precision: 0.9760 - recall: 0.9692 - auc: 0.9989 - prc: 0.9978 - val_loss: 1.4294 - val_tp: 182.0000 - val_fp: 143.0000 - val_tn: 634.0000 - val_fn: 175.0000 - val_accuracy: 0.7196 - val_precision: 0.5600 - val_recall: 0.5098 - val_auc: 0.7052 - val_prc: 0.5417\n",
      "Epoch 38/200\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 0.0323 - tp: 1392.0000 - fp: 27.0000 - tn: 3080.0000 - fn: 37.0000 - accuracy: 0.9859 - precision: 0.9810 - recall: 0.9741 - auc: 0.9992 - prc: 0.9978 - val_loss: 1.5126 - val_tp: 151.0000 - val_fp: 110.0000 - val_tn: 667.0000 - val_fn: 206.0000 - val_accuracy: 0.7213 - val_precision: 0.5785 - val_recall: 0.4230 - val_auc: 0.7016 - val_prc: 0.5434\n",
      "Epoch 39/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0353 - tp: 1392.0000 - fp: 35.0000 - tn: 3072.0000 - fn: 37.0000 - accuracy: 0.9841 - precision: 0.9755 - recall: 0.9741 - auc: 0.9992 - prc: 0.9983 - val_loss: 1.5504 - val_tp: 172.0000 - val_fp: 132.0000 - val_tn: 645.0000 - val_fn: 185.0000 - val_accuracy: 0.7205 - val_precision: 0.5658 - val_recall: 0.4818 - val_auc: 0.7009 - val_prc: 0.5394\n",
      "Epoch 40/200\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 0.0384 - tp: 1388.0000 - fp: 28.0000 - tn: 3079.0000 - fn: 41.0000 - accuracy: 0.9848 - precision: 0.9802 - recall: 0.9713 - auc: 0.9989 - prc: 0.9971 - val_loss: 1.5292 - val_tp: 166.0000 - val_fp: 121.0000 - val_tn: 656.0000 - val_fn: 191.0000 - val_accuracy: 0.7249 - val_precision: 0.5784 - val_recall: 0.4650 - val_auc: 0.6974 - val_prc: 0.5360\n",
      "Epoch 41/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0340 - tp: 1395.0000 - fp: 28.0000 - tn: 3079.0000 - fn: 34.0000 - accuracy: 0.9863 - precision: 0.9803 - recall: 0.9762 - auc: 0.9992 - prc: 0.9983 - val_loss: 1.5603 - val_tp: 178.0000 - val_fp: 142.0000 - val_tn: 635.0000 - val_fn: 179.0000 - val_accuracy: 0.7169 - val_precision: 0.5562 - val_recall: 0.4986 - val_auc: 0.7034 - val_prc: 0.5412\n",
      "Epoch 42/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0357 - tp: 1387.0000 - fp: 28.0000 - tn: 3079.0000 - fn: 42.0000 - accuracy: 0.9846 - precision: 0.9802 - recall: 0.9706 - auc: 0.9988 - prc: 0.9980 - val_loss: 1.4799 - val_tp: 199.0000 - val_fp: 189.0000 - val_tn: 588.0000 - val_fn: 158.0000 - val_accuracy: 0.6940 - val_precision: 0.5129 - val_recall: 0.5574 - val_auc: 0.7044 - val_prc: 0.5333\n",
      "Epoch 43/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0333 - tp: 1393.0000 - fp: 29.0000 - tn: 3078.0000 - fn: 36.0000 - accuracy: 0.9857 - precision: 0.9796 - recall: 0.9748 - auc: 0.9992 - prc: 0.9984 - val_loss: 1.5457 - val_tp: 199.0000 - val_fp: 191.0000 - val_tn: 586.0000 - val_fn: 158.0000 - val_accuracy: 0.6922 - val_precision: 0.5103 - val_recall: 0.5574 - val_auc: 0.7054 - val_prc: 0.5246\n",
      "Epoch 44/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0337 - tp: 1394.0000 - fp: 35.0000 - tn: 3072.0000 - fn: 35.0000 - accuracy: 0.9846 - precision: 0.9755 - recall: 0.9755 - auc: 0.9992 - prc: 0.9984 - val_loss: 1.7105 - val_tp: 126.0000 - val_fp: 86.0000 - val_tn: 691.0000 - val_fn: 231.0000 - val_accuracy: 0.7205 - val_precision: 0.5943 - val_recall: 0.3529 - val_auc: 0.6922 - val_prc: 0.5384\n",
      "Epoch 45/200\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 0.0360 - tp: 1386.0000 - fp: 28.0000 - tn: 3079.0000 - fn: 43.0000 - accuracy: 0.9843 - precision: 0.9802 - recall: 0.9699 - auc: 0.9991 - prc: 0.9982 - val_loss: 1.4728 - val_tp: 181.0000 - val_fp: 149.0000 - val_tn: 628.0000 - val_fn: 176.0000 - val_accuracy: 0.7134 - val_precision: 0.5485 - val_recall: 0.5070 - val_auc: 0.7041 - val_prc: 0.5404\n",
      "Epoch 46/200\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 0.0327 - tp: 1387.0000 - fp: 30.0000 - tn: 3077.0000 - fn: 42.0000 - accuracy: 0.9841 - precision: 0.9788 - recall: 0.9706 - auc: 0.9993 - prc: 0.9985 - val_loss: 1.5767 - val_tp: 212.0000 - val_fp: 214.0000 - val_tn: 563.0000 - val_fn: 145.0000 - val_accuracy: 0.6834 - val_precision: 0.4977 - val_recall: 0.5938 - val_auc: 0.7039 - val_prc: 0.5211\n",
      "Epoch 47/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0323 - tp: 1394.0000 - fp: 33.0000 - tn: 3074.0000 - fn: 35.0000 - accuracy: 0.9850 - precision: 0.9769 - recall: 0.9755 - auc: 0.9993 - prc: 0.9985 - val_loss: 1.6389 - val_tp: 151.0000 - val_fp: 105.0000 - val_tn: 672.0000 - val_fn: 206.0000 - val_accuracy: 0.7257 - val_precision: 0.5898 - val_recall: 0.4230 - val_auc: 0.6920 - val_prc: 0.5359\n",
      "Epoch 48/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0309 - tp: 1391.0000 - fp: 29.0000 - tn: 3078.0000 - fn: 38.0000 - accuracy: 0.9852 - precision: 0.9796 - recall: 0.9734 - auc: 0.9994 - prc: 0.9987 - val_loss: 1.5951 - val_tp: 171.0000 - val_fp: 133.0000 - val_tn: 644.0000 - val_fn: 186.0000 - val_accuracy: 0.7187 - val_precision: 0.5625 - val_recall: 0.4790 - val_auc: 0.6964 - val_prc: 0.5299\n",
      "Epoch 49/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0342 - tp: 1385.0000 - fp: 31.0000 - tn: 3076.0000 - fn: 44.0000 - accuracy: 0.9835 - precision: 0.9781 - recall: 0.9692 - auc: 0.9992 - prc: 0.9984 - val_loss: 1.6746 - val_tp: 142.0000 - val_fp: 96.0000 - val_tn: 681.0000 - val_fn: 215.0000 - val_accuracy: 0.7257 - val_precision: 0.5966 - val_recall: 0.3978 - val_auc: 0.6926 - val_prc: 0.5310\n",
      "Epoch 50/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0318 - tp: 1395.0000 - fp: 34.0000 - tn: 3073.0000 - fn: 34.0000 - accuracy: 0.9850 - precision: 0.9762 - recall: 0.9762 - auc: 0.9993 - prc: 0.9986 - val_loss: 1.7134 - val_tp: 146.0000 - val_fp: 100.0000 - val_tn: 677.0000 - val_fn: 211.0000 - val_accuracy: 0.7257 - val_precision: 0.5935 - val_recall: 0.4090 - val_auc: 0.6910 - val_prc: 0.5327\n",
      "Epoch 51/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0320 - tp: 1391.0000 - fp: 30.0000 - tn: 3077.0000 - fn: 38.0000 - accuracy: 0.9850 - precision: 0.9789 - recall: 0.9734 - auc: 0.9993 - prc: 0.9985 - val_loss: 1.6865 - val_tp: 149.0000 - val_fp: 103.0000 - val_tn: 674.0000 - val_fn: 208.0000 - val_accuracy: 0.7257 - val_precision: 0.5913 - val_recall: 0.4174 - val_auc: 0.6943 - val_prc: 0.5264\n",
      "Epoch 52/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0302 - tp: 1394.0000 - fp: 26.0000 - tn: 3081.0000 - fn: 35.0000 - accuracy: 0.9866 - precision: 0.9817 - recall: 0.9755 - auc: 0.9994 - prc: 0.9987 - val_loss: 1.5924 - val_tp: 173.0000 - val_fp: 132.0000 - val_tn: 645.0000 - val_fn: 184.0000 - val_accuracy: 0.7213 - val_precision: 0.5672 - val_recall: 0.4846 - val_auc: 0.6985 - val_prc: 0.5315\n",
      "Epoch 53/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0312 - tp: 1395.0000 - fp: 28.0000 - tn: 3079.0000 - fn: 34.0000 - accuracy: 0.9863 - precision: 0.9803 - recall: 0.9762 - auc: 0.9993 - prc: 0.9986 - val_loss: 1.6031 - val_tp: 158.0000 - val_fp: 124.0000 - val_tn: 653.0000 - val_fn: 199.0000 - val_accuracy: 0.7152 - val_precision: 0.5603 - val_recall: 0.4426 - val_auc: 0.6942 - val_prc: 0.5309\n",
      "Epoch 54/200\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 0.0296 - tp: 1393.0000 - fp: 28.0000 - tn: 3079.0000 - fn: 36.0000 - accuracy: 0.9859 - precision: 0.9803 - recall: 0.9748 - auc: 0.9994 - prc: 0.9988 - val_loss: 1.5992 - val_tp: 176.0000 - val_fp: 137.0000 - val_tn: 640.0000 - val_fn: 181.0000 - val_accuracy: 0.7196 - val_precision: 0.5623 - val_recall: 0.4930 - val_auc: 0.7034 - val_prc: 0.5281\n",
      "Epoch 55/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0299 - tp: 1392.0000 - fp: 28.0000 - tn: 3079.0000 - fn: 37.0000 - accuracy: 0.9857 - precision: 0.9803 - recall: 0.9741 - auc: 0.9994 - prc: 0.9987 - val_loss: 1.6325 - val_tp: 185.0000 - val_fp: 151.0000 - val_tn: 626.0000 - val_fn: 172.0000 - val_accuracy: 0.7152 - val_precision: 0.5506 - val_recall: 0.5182 - val_auc: 0.6989 - val_prc: 0.5226\n",
      "Epoch 56/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0283 - tp: 1398.0000 - fp: 28.0000 - tn: 3079.0000 - fn: 31.0000 - accuracy: 0.9870 - precision: 0.9804 - recall: 0.9783 - auc: 0.9995 - prc: 0.9989 - val_loss: 1.6229 - val_tp: 184.0000 - val_fp: 155.0000 - val_tn: 622.0000 - val_fn: 173.0000 - val_accuracy: 0.7108 - val_precision: 0.5428 - val_recall: 0.5154 - val_auc: 0.6988 - val_prc: 0.5275\n",
      "Epoch 57/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0287 - tp: 1395.0000 - fp: 30.0000 - tn: 3077.0000 - fn: 34.0000 - accuracy: 0.9859 - precision: 0.9789 - recall: 0.9762 - auc: 0.9995 - prc: 0.9988 - val_loss: 1.6172 - val_tp: 187.0000 - val_fp: 158.0000 - val_tn: 619.0000 - val_fn: 170.0000 - val_accuracy: 0.7108 - val_precision: 0.5420 - val_recall: 0.5238 - val_auc: 0.7013 - val_prc: 0.5282\n",
      "Epoch 58/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0284 - tp: 1396.0000 - fp: 27.0000 - tn: 3080.0000 - fn: 33.0000 - accuracy: 0.9868 - precision: 0.9810 - recall: 0.9769 - auc: 0.9994 - prc: 0.9988 - val_loss: 1.8023 - val_tp: 146.0000 - val_fp: 102.0000 - val_tn: 675.0000 - val_fn: 211.0000 - val_accuracy: 0.7240 - val_precision: 0.5887 - val_recall: 0.4090 - val_auc: 0.6860 - val_prc: 0.5202\n",
      "Epoch 59/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0283 - tp: 1395.0000 - fp: 26.0000 - tn: 3081.0000 - fn: 34.0000 - accuracy: 0.9868 - precision: 0.9817 - recall: 0.9762 - auc: 0.9994 - prc: 0.9988 - val_loss: 1.6660 - val_tp: 148.0000 - val_fp: 106.0000 - val_tn: 671.0000 - val_fn: 209.0000 - val_accuracy: 0.7222 - val_precision: 0.5827 - val_recall: 0.4146 - val_auc: 0.6927 - val_prc: 0.5262\n",
      "Epoch 60/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0272 - tp: 1393.0000 - fp: 24.0000 - tn: 3083.0000 - fn: 36.0000 - accuracy: 0.9868 - precision: 0.9831 - recall: 0.9748 - auc: 0.9995 - prc: 0.9989 - val_loss: 1.6549 - val_tp: 188.0000 - val_fp: 161.0000 - val_tn: 616.0000 - val_fn: 169.0000 - val_accuracy: 0.7090 - val_precision: 0.5387 - val_recall: 0.5266 - val_auc: 0.6956 - val_prc: 0.5170\n",
      "Epoch 61/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0277 - tp: 1392.0000 - fp: 26.0000 - tn: 3081.0000 - fn: 37.0000 - accuracy: 0.9861 - precision: 0.9817 - recall: 0.9741 - auc: 0.9995 - prc: 0.9989 - val_loss: 1.7371 - val_tp: 154.0000 - val_fp: 120.0000 - val_tn: 657.0000 - val_fn: 203.0000 - val_accuracy: 0.7152 - val_precision: 0.5620 - val_recall: 0.4314 - val_auc: 0.6911 - val_prc: 0.5254\n",
      "Epoch 62/200\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 0.0279 - tp: 1391.0000 - fp: 27.0000 - tn: 3080.0000 - fn: 38.0000 - accuracy: 0.9857 - precision: 0.9810 - recall: 0.9734 - auc: 0.9995 - prc: 0.9989 - val_loss: 1.7322 - val_tp: 207.0000 - val_fp: 212.0000 - val_tn: 565.0000 - val_fn: 150.0000 - val_accuracy: 0.6808 - val_precision: 0.4940 - val_recall: 0.5798 - val_auc: 0.6981 - val_prc: 0.5079\n",
      "Epoch 63/200\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 0.0290 - tp: 1399.0000 - fp: 33.0000 - tn: 3074.0000 - fn: 30.0000 - accuracy: 0.9861 - precision: 0.9770 - recall: 0.9790 - auc: 0.9994 - prc: 0.9988 - val_loss: 1.6275 - val_tp: 210.0000 - val_fp: 200.0000 - val_tn: 577.0000 - val_fn: 147.0000 - val_accuracy: 0.6940 - val_precision: 0.5122 - val_recall: 0.5882 - val_auc: 0.6961 - val_prc: 0.5140\n",
      "Epoch 64/200\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 0.0295 - tp: 1393.0000 - fp: 31.0000 - tn: 3076.0000 - fn: 36.0000 - accuracy: 0.9852 - precision: 0.9782 - recall: 0.9748 - auc: 0.9994 - prc: 0.9987 - val_loss: 2.0122 - val_tp: 125.0000 - val_fp: 82.0000 - val_tn: 695.0000 - val_fn: 232.0000 - val_accuracy: 0.7231 - val_precision: 0.6039 - val_recall: 0.3501 - val_auc: 0.6791 - val_prc: 0.5220\n",
      "Epoch 65/200\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 0.0267 - tp: 1396.0000 - fp: 25.0000 - tn: 3082.0000 - fn: 33.0000 - accuracy: 0.9872 - precision: 0.9824 - recall: 0.9769 - auc: 0.9995 - prc: 0.9989 - val_loss: 1.7278 - val_tp: 195.0000 - val_fp: 167.0000 - val_tn: 610.0000 - val_fn: 162.0000 - val_accuracy: 0.7099 - val_precision: 0.5387 - val_recall: 0.5462 - val_auc: 0.6950 - val_prc: 0.5194\n",
      "Epoch 66/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0265 - tp: 1396.0000 - fp: 30.0000 - tn: 3077.0000 - fn: 33.0000 - accuracy: 0.9861 - precision: 0.9790 - recall: 0.9769 - auc: 0.9995 - prc: 0.9989 - val_loss: 1.7684 - val_tp: 148.0000 - val_fp: 106.0000 - val_tn: 671.0000 - val_fn: 209.0000 - val_accuracy: 0.7222 - val_precision: 0.5827 - val_recall: 0.4146 - val_auc: 0.6912 - val_prc: 0.5246\n",
      "Epoch 67/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0245 - tp: 1397.0000 - fp: 26.0000 - tn: 3081.0000 - fn: 32.0000 - accuracy: 0.9872 - precision: 0.9817 - recall: 0.9776 - auc: 0.9996 - prc: 0.9991 - val_loss: 1.7530 - val_tp: 180.0000 - val_fp: 142.0000 - val_tn: 635.0000 - val_fn: 177.0000 - val_accuracy: 0.7187 - val_precision: 0.5590 - val_recall: 0.5042 - val_auc: 0.6927 - val_prc: 0.5181\n",
      "Epoch 68/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0251 - tp: 1393.0000 - fp: 24.0000 - tn: 3083.0000 - fn: 36.0000 - accuracy: 0.9868 - precision: 0.9831 - recall: 0.9748 - auc: 0.9995 - prc: 0.9990 - val_loss: 1.7758 - val_tp: 201.0000 - val_fp: 191.0000 - val_tn: 586.0000 - val_fn: 156.0000 - val_accuracy: 0.6940 - val_precision: 0.5128 - val_recall: 0.5630 - val_auc: 0.6953 - val_prc: 0.5061\n",
      "Epoch 69/200\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 0.0234 - tp: 1400.0000 - fp: 27.0000 - tn: 3080.0000 - fn: 29.0000 - accuracy: 0.9877 - precision: 0.9811 - recall: 0.9797 - auc: 0.9996 - prc: 0.9991 - val_loss: 1.8645 - val_tp: 150.0000 - val_fp: 97.0000 - val_tn: 680.0000 - val_fn: 207.0000 - val_accuracy: 0.7319 - val_precision: 0.6073 - val_recall: 0.4202 - val_auc: 0.6881 - val_prc: 0.5252\n",
      "Epoch 70/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0259 - tp: 1391.0000 - fp: 29.0000 - tn: 3078.0000 - fn: 38.0000 - accuracy: 0.9852 - precision: 0.9796 - recall: 0.9734 - auc: 0.9995 - prc: 0.9990 - val_loss: 1.7437 - val_tp: 195.0000 - val_fp: 185.0000 - val_tn: 592.0000 - val_fn: 162.0000 - val_accuracy: 0.6940 - val_precision: 0.5132 - val_recall: 0.5462 - val_auc: 0.6982 - val_prc: 0.5197\n",
      "Epoch 71/200\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 0.0266 - tp: 1396.0000 - fp: 27.0000 - tn: 3080.0000 - fn: 33.0000 - accuracy: 0.9868 - precision: 0.9810 - recall: 0.9769 - auc: 0.9995 - prc: 0.9989 - val_loss: 1.7532 - val_tp: 208.0000 - val_fp: 225.0000 - val_tn: 552.0000 - val_fn: 149.0000 - val_accuracy: 0.6702 - val_precision: 0.4804 - val_recall: 0.5826 - val_auc: 0.6940 - val_prc: 0.5030\n",
      "Epoch 72/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0254 - tp: 1394.0000 - fp: 25.0000 - tn: 3082.0000 - fn: 35.0000 - accuracy: 0.9868 - precision: 0.9824 - recall: 0.9755 - auc: 0.9995 - prc: 0.9990 - val_loss: 1.8413 - val_tp: 211.0000 - val_fp: 214.0000 - val_tn: 563.0000 - val_fn: 146.0000 - val_accuracy: 0.6825 - val_precision: 0.4965 - val_recall: 0.5910 - val_auc: 0.6980 - val_prc: 0.5082\n",
      "Epoch 73/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0232 - tp: 1398.0000 - fp: 30.0000 - tn: 3077.0000 - fn: 31.0000 - accuracy: 0.9866 - precision: 0.9790 - recall: 0.9783 - auc: 0.9996 - prc: 0.9991 - val_loss: 1.8884 - val_tp: 201.0000 - val_fp: 192.0000 - val_tn: 585.0000 - val_fn: 156.0000 - val_accuracy: 0.6931 - val_precision: 0.5115 - val_recall: 0.5630 - val_auc: 0.6953 - val_prc: 0.5036\n",
      "Epoch 74/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0220 - tp: 1397.0000 - fp: 26.0000 - tn: 3081.0000 - fn: 32.0000 - accuracy: 0.9872 - precision: 0.9817 - recall: 0.9776 - auc: 0.9996 - prc: 0.9992 - val_loss: 1.8648 - val_tp: 187.0000 - val_fp: 161.0000 - val_tn: 616.0000 - val_fn: 170.0000 - val_accuracy: 0.7081 - val_precision: 0.5374 - val_recall: 0.5238 - val_auc: 0.6940 - val_prc: 0.5189\n",
      "Epoch 75/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0238 - tp: 1393.0000 - fp: 25.0000 - tn: 3082.0000 - fn: 36.0000 - accuracy: 0.9866 - precision: 0.9824 - recall: 0.9748 - auc: 0.9996 - prc: 0.9991 - val_loss: 1.7906 - val_tp: 197.0000 - val_fp: 181.0000 - val_tn: 596.0000 - val_fn: 160.0000 - val_accuracy: 0.6993 - val_precision: 0.5212 - val_recall: 0.5518 - val_auc: 0.7009 - val_prc: 0.5179\n",
      "Epoch 76/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0218 - tp: 1399.0000 - fp: 26.0000 - tn: 3081.0000 - fn: 30.0000 - accuracy: 0.9877 - precision: 0.9818 - recall: 0.9790 - auc: 0.9996 - prc: 0.9992 - val_loss: 2.0038 - val_tp: 156.0000 - val_fp: 119.0000 - val_tn: 658.0000 - val_fn: 201.0000 - val_accuracy: 0.7178 - val_precision: 0.5673 - val_recall: 0.4370 - val_auc: 0.6889 - val_prc: 0.5136\n",
      "Epoch 77/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0237 - tp: 1397.0000 - fp: 27.0000 - tn: 3080.0000 - fn: 32.0000 - accuracy: 0.9870 - precision: 0.9810 - recall: 0.9776 - auc: 0.9996 - prc: 0.9991 - val_loss: 1.8328 - val_tp: 206.0000 - val_fp: 192.0000 - val_tn: 585.0000 - val_fn: 151.0000 - val_accuracy: 0.6975 - val_precision: 0.5176 - val_recall: 0.5770 - val_auc: 0.6969 - val_prc: 0.5096\n",
      "Epoch 78/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0237 - tp: 1396.0000 - fp: 24.0000 - tn: 3083.0000 - fn: 33.0000 - accuracy: 0.9874 - precision: 0.9831 - recall: 0.9769 - auc: 0.9996 - prc: 0.9991 - val_loss: 1.9198 - val_tp: 168.0000 - val_fp: 136.0000 - val_tn: 641.0000 - val_fn: 189.0000 - val_accuracy: 0.7134 - val_precision: 0.5526 - val_recall: 0.4706 - val_auc: 0.6866 - val_prc: 0.5114\n",
      "Epoch 79/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0229 - tp: 1396.0000 - fp: 27.0000 - tn: 3080.0000 - fn: 33.0000 - accuracy: 0.9868 - precision: 0.9810 - recall: 0.9769 - auc: 0.9996 - prc: 0.9991 - val_loss: 1.8348 - val_tp: 203.0000 - val_fp: 185.0000 - val_tn: 592.0000 - val_fn: 154.0000 - val_accuracy: 0.7011 - val_precision: 0.5232 - val_recall: 0.5686 - val_auc: 0.6993 - val_prc: 0.5139\n",
      "Epoch 80/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0221 - tp: 1398.0000 - fp: 27.0000 - tn: 3080.0000 - fn: 31.0000 - accuracy: 0.9872 - precision: 0.9811 - recall: 0.9783 - auc: 0.9996 - prc: 0.9992 - val_loss: 2.1515 - val_tp: 145.0000 - val_fp: 101.0000 - val_tn: 676.0000 - val_fn: 212.0000 - val_accuracy: 0.7240 - val_precision: 0.5894 - val_recall: 0.4062 - val_auc: 0.6833 - val_prc: 0.5104\n",
      "Epoch 81/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0221 - tp: 1397.0000 - fp: 25.0000 - tn: 3082.0000 - fn: 32.0000 - accuracy: 0.9874 - precision: 0.9824 - recall: 0.9776 - auc: 0.9996 - prc: 0.9992 - val_loss: 1.9322 - val_tp: 188.0000 - val_fp: 169.0000 - val_tn: 608.0000 - val_fn: 169.0000 - val_accuracy: 0.7019 - val_precision: 0.5266 - val_recall: 0.5266 - val_auc: 0.6916 - val_prc: 0.5087\n",
      "Epoch 82/200\n",
      "71/71 [==============================] - 1s 16ms/step - loss: 0.0214 - tp: 1394.0000 - fp: 21.0000 - tn: 3086.0000 - fn: 35.0000 - accuracy: 0.9877 - precision: 0.9852 - recall: 0.9755 - auc: 0.9996 - prc: 0.9992 - val_loss: 2.0034 - val_tp: 179.0000 - val_fp: 146.0000 - val_tn: 631.0000 - val_fn: 178.0000 - val_accuracy: 0.7143 - val_precision: 0.5508 - val_recall: 0.5014 - val_auc: 0.6955 - val_prc: 0.5154\n",
      "Epoch 83/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0240 - tp: 1398.0000 - fp: 25.0000 - tn: 3082.0000 - fn: 31.0000 - accuracy: 0.9877 - precision: 0.9824 - recall: 0.9783 - auc: 0.9996 - prc: 0.9991 - val_loss: 1.9077 - val_tp: 190.0000 - val_fp: 171.0000 - val_tn: 606.0000 - val_fn: 167.0000 - val_accuracy: 0.7019 - val_precision: 0.5263 - val_recall: 0.5322 - val_auc: 0.6932 - val_prc: 0.5048\n",
      "Epoch 84/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0216 - tp: 1395.0000 - fp: 22.0000 - tn: 3085.0000 - fn: 34.0000 - accuracy: 0.9877 - precision: 0.9845 - recall: 0.9762 - auc: 0.9996 - prc: 0.9992 - val_loss: 2.0587 - val_tp: 201.0000 - val_fp: 187.0000 - val_tn: 590.0000 - val_fn: 156.0000 - val_accuracy: 0.6975 - val_precision: 0.5180 - val_recall: 0.5630 - val_auc: 0.6933 - val_prc: 0.4995\n",
      "Epoch 85/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0226 - tp: 1399.0000 - fp: 29.0000 - tn: 3078.0000 - fn: 30.0000 - accuracy: 0.9870 - precision: 0.9797 - recall: 0.9790 - auc: 0.9996 - prc: 0.9991 - val_loss: 2.0327 - val_tp: 180.0000 - val_fp: 152.0000 - val_tn: 625.0000 - val_fn: 177.0000 - val_accuracy: 0.7099 - val_precision: 0.5422 - val_recall: 0.5042 - val_auc: 0.6981 - val_prc: 0.5130\n",
      "Epoch 86/200\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 0.0226 - tp: 1395.0000 - fp: 26.0000 - tn: 3081.0000 - fn: 34.0000 - accuracy: 0.9868 - precision: 0.9817 - recall: 0.9762 - auc: 0.9996 - prc: 0.9991 - val_loss: 1.9948 - val_tp: 170.0000 - val_fp: 141.0000 - val_tn: 636.0000 - val_fn: 187.0000 - val_accuracy: 0.7108 - val_precision: 0.5466 - val_recall: 0.4762 - val_auc: 0.6867 - val_prc: 0.5078\n",
      "Epoch 87/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0217 - tp: 1394.0000 - fp: 22.0000 - tn: 3085.0000 - fn: 35.0000 - accuracy: 0.9874 - precision: 0.9845 - recall: 0.9755 - auc: 0.9996 - prc: 0.9992 - val_loss: 2.2644 - val_tp: 147.0000 - val_fp: 98.0000 - val_tn: 679.0000 - val_fn: 210.0000 - val_accuracy: 0.7284 - val_precision: 0.6000 - val_recall: 0.4118 - val_auc: 0.6832 - val_prc: 0.5142\n",
      "Epoch 88/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0220 - tp: 1393.0000 - fp: 24.0000 - tn: 3083.0000 - fn: 36.0000 - accuracy: 0.9868 - precision: 0.9831 - recall: 0.9748 - auc: 0.9996 - prc: 0.9991 - val_loss: 2.1062 - val_tp: 211.0000 - val_fp: 214.0000 - val_tn: 563.0000 - val_fn: 146.0000 - val_accuracy: 0.6825 - val_precision: 0.4965 - val_recall: 0.5910 - val_auc: 0.6917 - val_prc: 0.4937\n",
      "Epoch 89/200\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 0.0238 - tp: 1393.0000 - fp: 23.0000 - tn: 3084.0000 - fn: 36.0000 - accuracy: 0.9870 - precision: 0.9838 - recall: 0.9748 - auc: 0.9996 - prc: 0.9991 - val_loss: 2.0176 - val_tp: 170.0000 - val_fp: 135.0000 - val_tn: 642.0000 - val_fn: 187.0000 - val_accuracy: 0.7160 - val_precision: 0.5574 - val_recall: 0.4762 - val_auc: 0.6838 - val_prc: 0.5094\n",
      "Epoch 90/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0215 - tp: 1398.0000 - fp: 29.0000 - tn: 3078.0000 - fn: 31.0000 - accuracy: 0.9868 - precision: 0.9797 - recall: 0.9783 - auc: 0.9996 - prc: 0.9992 - val_loss: 2.0815 - val_tp: 197.0000 - val_fp: 186.0000 - val_tn: 591.0000 - val_fn: 160.0000 - val_accuracy: 0.6949 - val_precision: 0.5144 - val_recall: 0.5518 - val_auc: 0.6941 - val_prc: 0.5056\n",
      "Epoch 91/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0208 - tp: 1401.0000 - fp: 31.0000 - tn: 3076.0000 - fn: 28.0000 - accuracy: 0.9870 - precision: 0.9784 - recall: 0.9804 - auc: 0.9996 - prc: 0.9992 - val_loss: 2.1101 - val_tp: 183.0000 - val_fp: 149.0000 - val_tn: 628.0000 - val_fn: 174.0000 - val_accuracy: 0.7152 - val_precision: 0.5512 - val_recall: 0.5126 - val_auc: 0.6899 - val_prc: 0.5071\n",
      "Epoch 92/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0212 - tp: 1394.0000 - fp: 20.0000 - tn: 3087.0000 - fn: 35.0000 - accuracy: 0.9879 - precision: 0.9859 - recall: 0.9755 - auc: 0.9996 - prc: 0.9992 - val_loss: 2.1566 - val_tp: 189.0000 - val_fp: 163.0000 - val_tn: 614.0000 - val_fn: 168.0000 - val_accuracy: 0.7081 - val_precision: 0.5369 - val_recall: 0.5294 - val_auc: 0.6918 - val_prc: 0.5087\n",
      "Epoch 93/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0196 - tp: 1402.0000 - fp: 26.0000 - tn: 3081.0000 - fn: 27.0000 - accuracy: 0.9883 - precision: 0.9818 - recall: 0.9811 - auc: 0.9997 - prc: 0.9993 - val_loss: 2.3404 - val_tp: 158.0000 - val_fp: 119.0000 - val_tn: 658.0000 - val_fn: 199.0000 - val_accuracy: 0.7196 - val_precision: 0.5704 - val_recall: 0.4426 - val_auc: 0.6861 - val_prc: 0.5085\n",
      "Epoch 94/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0209 - tp: 1397.0000 - fp: 29.0000 - tn: 3078.0000 - fn: 32.0000 - accuracy: 0.9866 - precision: 0.9797 - recall: 0.9776 - auc: 0.9996 - prc: 0.9992 - val_loss: 2.3190 - val_tp: 152.0000 - val_fp: 110.0000 - val_tn: 667.0000 - val_fn: 205.0000 - val_accuracy: 0.7222 - val_precision: 0.5802 - val_recall: 0.4258 - val_auc: 0.6834 - val_prc: 0.5096\n",
      "Epoch 95/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0201 - tp: 1396.0000 - fp: 20.0000 - tn: 3087.0000 - fn: 33.0000 - accuracy: 0.9883 - precision: 0.9859 - recall: 0.9769 - auc: 0.9997 - prc: 0.9993 - val_loss: 2.1864 - val_tp: 175.0000 - val_fp: 138.0000 - val_tn: 639.0000 - val_fn: 182.0000 - val_accuracy: 0.7178 - val_precision: 0.5591 - val_recall: 0.4902 - val_auc: 0.6901 - val_prc: 0.5128\n",
      "Epoch 96/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0202 - tp: 1402.0000 - fp: 27.0000 - tn: 3080.0000 - fn: 27.0000 - accuracy: 0.9881 - precision: 0.9811 - recall: 0.9811 - auc: 0.9997 - prc: 0.9993 - val_loss: 2.2598 - val_tp: 204.0000 - val_fp: 192.0000 - val_tn: 585.0000 - val_fn: 153.0000 - val_accuracy: 0.6958 - val_precision: 0.5152 - val_recall: 0.5714 - val_auc: 0.6926 - val_prc: 0.5012\n",
      "Epoch 97/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0188 - tp: 1398.0000 - fp: 24.0000 - tn: 3083.0000 - fn: 31.0000 - accuracy: 0.9879 - precision: 0.9831 - recall: 0.9783 - auc: 0.9997 - prc: 0.9993 - val_loss: 2.3464 - val_tp: 186.0000 - val_fp: 157.0000 - val_tn: 620.0000 - val_fn: 171.0000 - val_accuracy: 0.7108 - val_precision: 0.5423 - val_recall: 0.5210 - val_auc: 0.6883 - val_prc: 0.5012\n",
      "Epoch 98/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0195 - tp: 1406.0000 - fp: 29.0000 - tn: 3078.0000 - fn: 23.0000 - accuracy: 0.9885 - precision: 0.9798 - recall: 0.9839 - auc: 0.9997 - prc: 0.9993 - val_loss: 2.4047 - val_tp: 152.0000 - val_fp: 114.0000 - val_tn: 663.0000 - val_fn: 205.0000 - val_accuracy: 0.7187 - val_precision: 0.5714 - val_recall: 0.4258 - val_auc: 0.6762 - val_prc: 0.5006\n",
      "Epoch 99/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0206 - tp: 1393.0000 - fp: 27.0000 - tn: 3080.0000 - fn: 36.0000 - accuracy: 0.9861 - precision: 0.9810 - recall: 0.9748 - auc: 0.9996 - prc: 0.9992 - val_loss: 2.1547 - val_tp: 191.0000 - val_fp: 172.0000 - val_tn: 605.0000 - val_fn: 166.0000 - val_accuracy: 0.7019 - val_precision: 0.5262 - val_recall: 0.5350 - val_auc: 0.6911 - val_prc: 0.5051\n",
      "Epoch 100/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0204 - tp: 1395.0000 - fp: 22.0000 - tn: 3085.0000 - fn: 34.0000 - accuracy: 0.9877 - precision: 0.9845 - recall: 0.9762 - auc: 0.9996 - prc: 0.9992 - val_loss: 2.2094 - val_tp: 206.0000 - val_fp: 199.0000 - val_tn: 578.0000 - val_fn: 151.0000 - val_accuracy: 0.6914 - val_precision: 0.5086 - val_recall: 0.5770 - val_auc: 0.6914 - val_prc: 0.4986\n",
      "Epoch 101/200\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 0.0202 - tp: 1391.0000 - fp: 20.0000 - tn: 3087.0000 - fn: 38.0000 - accuracy: 0.9872 - precision: 0.9858 - recall: 0.9734 - auc: 0.9996 - prc: 0.9992 - val_loss: 2.2141 - val_tp: 193.0000 - val_fp: 174.0000 - val_tn: 603.0000 - val_fn: 164.0000 - val_accuracy: 0.7019 - val_precision: 0.5259 - val_recall: 0.5406 - val_auc: 0.6905 - val_prc: 0.5045\n",
      "Epoch 102/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0190 - tp: 1403.0000 - fp: 20.0000 - tn: 3087.0000 - fn: 26.0000 - accuracy: 0.9899 - precision: 0.9859 - recall: 0.9818 - auc: 0.9997 - prc: 0.9993 - val_loss: 2.4948 - val_tp: 162.0000 - val_fp: 123.0000 - val_tn: 654.0000 - val_fn: 195.0000 - val_accuracy: 0.7196 - val_precision: 0.5684 - val_recall: 0.4538 - val_auc: 0.6810 - val_prc: 0.5014\n",
      "Epoch 103/200\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 0.0210 - tp: 1396.0000 - fp: 27.0000 - tn: 3080.0000 - fn: 33.0000 - accuracy: 0.9868 - precision: 0.9810 - recall: 0.9769 - auc: 0.9996 - prc: 0.9992 - val_loss: 2.3143 - val_tp: 173.0000 - val_fp: 134.0000 - val_tn: 643.0000 - val_fn: 184.0000 - val_accuracy: 0.7196 - val_precision: 0.5635 - val_recall: 0.4846 - val_auc: 0.6810 - val_prc: 0.5029\n",
      "Epoch 104/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0201 - tp: 1406.0000 - fp: 25.0000 - tn: 3082.0000 - fn: 23.0000 - accuracy: 0.9894 - precision: 0.9825 - recall: 0.9839 - auc: 0.9997 - prc: 0.9993 - val_loss: 2.2930 - val_tp: 178.0000 - val_fp: 141.0000 - val_tn: 636.0000 - val_fn: 179.0000 - val_accuracy: 0.7178 - val_precision: 0.5580 - val_recall: 0.4986 - val_auc: 0.6820 - val_prc: 0.5035\n",
      "Epoch 105/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0204 - tp: 1397.0000 - fp: 25.0000 - tn: 3082.0000 - fn: 32.0000 - accuracy: 0.9874 - precision: 0.9824 - recall: 0.9776 - auc: 0.9996 - prc: 0.9992 - val_loss: 2.3574 - val_tp: 185.0000 - val_fp: 155.0000 - val_tn: 622.0000 - val_fn: 172.0000 - val_accuracy: 0.7116 - val_precision: 0.5441 - val_recall: 0.5182 - val_auc: 0.6844 - val_prc: 0.4982\n",
      "Epoch 106/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0191 - tp: 1392.0000 - fp: 17.0000 - tn: 3090.0000 - fn: 37.0000 - accuracy: 0.9881 - precision: 0.9879 - recall: 0.9741 - auc: 0.9997 - prc: 0.9993 - val_loss: 2.5418 - val_tp: 167.0000 - val_fp: 125.0000 - val_tn: 652.0000 - val_fn: 190.0000 - val_accuracy: 0.7222 - val_precision: 0.5719 - val_recall: 0.4678 - val_auc: 0.6836 - val_prc: 0.5050\n",
      "Epoch 107/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0196 - tp: 1399.0000 - fp: 25.0000 - tn: 3082.0000 - fn: 30.0000 - accuracy: 0.9879 - precision: 0.9824 - recall: 0.9790 - auc: 0.9997 - prc: 0.9993 - val_loss: 2.5647 - val_tp: 163.0000 - val_fp: 131.0000 - val_tn: 646.0000 - val_fn: 194.0000 - val_accuracy: 0.7134 - val_precision: 0.5544 - val_recall: 0.4566 - val_auc: 0.6807 - val_prc: 0.5026\n",
      "Epoch 108/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0187 - tp: 1399.0000 - fp: 18.0000 - tn: 3089.0000 - fn: 30.0000 - accuracy: 0.9894 - precision: 0.9873 - recall: 0.9790 - auc: 0.9997 - prc: 0.9993 - val_loss: 2.4617 - val_tp: 179.0000 - val_fp: 145.0000 - val_tn: 632.0000 - val_fn: 178.0000 - val_accuracy: 0.7152 - val_precision: 0.5525 - val_recall: 0.5014 - val_auc: 0.6809 - val_prc: 0.4991\n",
      "Epoch 109/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0204 - tp: 1397.0000 - fp: 23.0000 - tn: 3084.0000 - fn: 32.0000 - accuracy: 0.9879 - precision: 0.9838 - recall: 0.9776 - auc: 0.9996 - prc: 0.9992 - val_loss: 2.4411 - val_tp: 180.0000 - val_fp: 142.0000 - val_tn: 635.0000 - val_fn: 177.0000 - val_accuracy: 0.7187 - val_precision: 0.5590 - val_recall: 0.5042 - val_auc: 0.6850 - val_prc: 0.5017\n",
      "Epoch 110/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0190 - tp: 1397.0000 - fp: 19.0000 - tn: 3088.0000 - fn: 32.0000 - accuracy: 0.9888 - precision: 0.9866 - recall: 0.9776 - auc: 0.9997 - prc: 0.9993 - val_loss: 2.4741 - val_tp: 186.0000 - val_fp: 156.0000 - val_tn: 621.0000 - val_fn: 171.0000 - val_accuracy: 0.7116 - val_precision: 0.5439 - val_recall: 0.5210 - val_auc: 0.6847 - val_prc: 0.4979\n",
      "Epoch 111/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0188 - tp: 1397.0000 - fp: 23.0000 - tn: 3084.0000 - fn: 32.0000 - accuracy: 0.9879 - precision: 0.9838 - recall: 0.9776 - auc: 0.9997 - prc: 0.9993 - val_loss: 2.5478 - val_tp: 160.0000 - val_fp: 128.0000 - val_tn: 649.0000 - val_fn: 197.0000 - val_accuracy: 0.7134 - val_precision: 0.5556 - val_recall: 0.4482 - val_auc: 0.6796 - val_prc: 0.5047\n",
      "Epoch 112/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0187 - tp: 1400.0000 - fp: 27.0000 - tn: 3080.0000 - fn: 29.0000 - accuracy: 0.9877 - precision: 0.9811 - recall: 0.9797 - auc: 0.9997 - prc: 0.9993 - val_loss: 2.6762 - val_tp: 166.0000 - val_fp: 128.0000 - val_tn: 649.0000 - val_fn: 191.0000 - val_accuracy: 0.7187 - val_precision: 0.5646 - val_recall: 0.4650 - val_auc: 0.6805 - val_prc: 0.5004\n",
      "Epoch 113/200\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 0.0214 - tp: 1401.0000 - fp: 21.0000 - tn: 3086.0000 - fn: 28.0000 - accuracy: 0.9892 - precision: 0.9852 - recall: 0.9804 - auc: 0.9996 - prc: 0.9992 - val_loss: 2.3608 - val_tp: 207.0000 - val_fp: 194.0000 - val_tn: 583.0000 - val_fn: 150.0000 - val_accuracy: 0.6966 - val_precision: 0.5162 - val_recall: 0.5798 - val_auc: 0.6929 - val_prc: 0.5010\n",
      "Epoch 114/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0196 - tp: 1393.0000 - fp: 25.0000 - tn: 3082.0000 - fn: 36.0000 - accuracy: 0.9866 - precision: 0.9824 - recall: 0.9748 - auc: 0.9996 - prc: 0.9992 - val_loss: 2.5226 - val_tp: 180.0000 - val_fp: 146.0000 - val_tn: 631.0000 - val_fn: 177.0000 - val_accuracy: 0.7152 - val_precision: 0.5521 - val_recall: 0.5042 - val_auc: 0.6841 - val_prc: 0.4991\n",
      "Epoch 115/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0182 - tp: 1401.0000 - fp: 24.0000 - tn: 3083.0000 - fn: 28.0000 - accuracy: 0.9885 - precision: 0.9832 - recall: 0.9804 - auc: 0.9997 - prc: 0.9994 - val_loss: 2.8184 - val_tp: 145.0000 - val_fp: 106.0000 - val_tn: 671.0000 - val_fn: 212.0000 - val_accuracy: 0.7196 - val_precision: 0.5777 - val_recall: 0.4062 - val_auc: 0.6788 - val_prc: 0.5063\n",
      "Epoch 116/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0184 - tp: 1396.0000 - fp: 21.0000 - tn: 3086.0000 - fn: 33.0000 - accuracy: 0.9881 - precision: 0.9852 - recall: 0.9769 - auc: 0.9997 - prc: 0.9993 - val_loss: 2.6504 - val_tp: 192.0000 - val_fp: 167.0000 - val_tn: 610.0000 - val_fn: 165.0000 - val_accuracy: 0.7072 - val_precision: 0.5348 - val_recall: 0.5378 - val_auc: 0.6878 - val_prc: 0.4967\n",
      "Epoch 117/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0180 - tp: 1396.0000 - fp: 19.0000 - tn: 3088.0000 - fn: 33.0000 - accuracy: 0.9885 - precision: 0.9866 - recall: 0.9769 - auc: 0.9997 - prc: 0.9994 - val_loss: 2.6696 - val_tp: 196.0000 - val_fp: 172.0000 - val_tn: 605.0000 - val_fn: 161.0000 - val_accuracy: 0.7063 - val_precision: 0.5326 - val_recall: 0.5490 - val_auc: 0.6919 - val_prc: 0.4992\n",
      "Epoch 118/200\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 0.0182 - tp: 1403.0000 - fp: 27.0000 - tn: 3080.0000 - fn: 26.0000 - accuracy: 0.9883 - precision: 0.9811 - recall: 0.9818 - auc: 0.9997 - prc: 0.9993 - val_loss: 2.7552 - val_tp: 156.0000 - val_fp: 118.0000 - val_tn: 659.0000 - val_fn: 201.0000 - val_accuracy: 0.7187 - val_precision: 0.5693 - val_recall: 0.4370 - val_auc: 0.6827 - val_prc: 0.5023\n",
      "Epoch 119/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0194 - tp: 1397.0000 - fp: 18.0000 - tn: 3089.0000 - fn: 32.0000 - accuracy: 0.9890 - precision: 0.9873 - recall: 0.9776 - auc: 0.9997 - prc: 0.9993 - val_loss: 2.6223 - val_tp: 153.0000 - val_fp: 117.0000 - val_tn: 660.0000 - val_fn: 204.0000 - val_accuracy: 0.7169 - val_precision: 0.5667 - val_recall: 0.4286 - val_auc: 0.6763 - val_prc: 0.5036\n",
      "Epoch 120/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0185 - tp: 1401.0000 - fp: 21.0000 - tn: 3086.0000 - fn: 28.0000 - accuracy: 0.9892 - precision: 0.9852 - recall: 0.9804 - auc: 0.9997 - prc: 0.9993 - val_loss: 2.6619 - val_tp: 185.0000 - val_fp: 159.0000 - val_tn: 618.0000 - val_fn: 172.0000 - val_accuracy: 0.7081 - val_precision: 0.5378 - val_recall: 0.5182 - val_auc: 0.6824 - val_prc: 0.4941\n",
      "Epoch 121/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0181 - tp: 1407.0000 - fp: 28.0000 - tn: 3079.0000 - fn: 22.0000 - accuracy: 0.9890 - precision: 0.9805 - recall: 0.9846 - auc: 0.9997 - prc: 0.9994 - val_loss: 2.7649 - val_tp: 168.0000 - val_fp: 134.0000 - val_tn: 643.0000 - val_fn: 189.0000 - val_accuracy: 0.7152 - val_precision: 0.5563 - val_recall: 0.4706 - val_auc: 0.6786 - val_prc: 0.4958\n",
      "Epoch 122/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0181 - tp: 1398.0000 - fp: 21.0000 - tn: 3086.0000 - fn: 31.0000 - accuracy: 0.9885 - precision: 0.9852 - recall: 0.9783 - auc: 0.9997 - prc: 0.9993 - val_loss: 2.7659 - val_tp: 163.0000 - val_fp: 132.0000 - val_tn: 645.0000 - val_fn: 194.0000 - val_accuracy: 0.7125 - val_precision: 0.5525 - val_recall: 0.4566 - val_auc: 0.6806 - val_prc: 0.4984\n",
      "Epoch 123/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0180 - tp: 1403.0000 - fp: 26.0000 - tn: 3081.0000 - fn: 26.0000 - accuracy: 0.9885 - precision: 0.9818 - recall: 0.9818 - auc: 0.9997 - prc: 0.9993 - val_loss: 2.7856 - val_tp: 184.0000 - val_fp: 157.0000 - val_tn: 620.0000 - val_fn: 173.0000 - val_accuracy: 0.7090 - val_precision: 0.5396 - val_recall: 0.5154 - val_auc: 0.6828 - val_prc: 0.4984\n",
      "Epoch 124/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0177 - tp: 1403.0000 - fp: 24.0000 - tn: 3083.0000 - fn: 26.0000 - accuracy: 0.9890 - precision: 0.9832 - recall: 0.9818 - auc: 0.9997 - prc: 0.9994 - val_loss: 2.8771 - val_tp: 147.0000 - val_fp: 116.0000 - val_tn: 661.0000 - val_fn: 210.0000 - val_accuracy: 0.7125 - val_precision: 0.5589 - val_recall: 0.4118 - val_auc: 0.6779 - val_prc: 0.4992\n",
      "Epoch 125/200\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 0.0186 - tp: 1394.0000 - fp: 16.0000 - tn: 3091.0000 - fn: 35.0000 - accuracy: 0.9888 - precision: 0.9887 - recall: 0.9755 - auc: 0.9997 - prc: 0.9993 - val_loss: 2.7389 - val_tp: 173.0000 - val_fp: 144.0000 - val_tn: 633.0000 - val_fn: 184.0000 - val_accuracy: 0.7108 - val_precision: 0.5457 - val_recall: 0.4846 - val_auc: 0.6801 - val_prc: 0.4965\n",
      "Epoch 126/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0186 - tp: 1405.0000 - fp: 26.0000 - tn: 3081.0000 - fn: 24.0000 - accuracy: 0.9890 - precision: 0.9818 - recall: 0.9832 - auc: 0.9997 - prc: 0.9993 - val_loss: 2.7894 - val_tp: 190.0000 - val_fp: 167.0000 - val_tn: 610.0000 - val_fn: 167.0000 - val_accuracy: 0.7055 - val_precision: 0.5322 - val_recall: 0.5322 - val_auc: 0.6878 - val_prc: 0.4993\n",
      "Epoch 127/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0180 - tp: 1403.0000 - fp: 26.0000 - tn: 3081.0000 - fn: 26.0000 - accuracy: 0.9885 - precision: 0.9818 - recall: 0.9818 - auc: 0.9997 - prc: 0.9993 - val_loss: 2.8392 - val_tp: 189.0000 - val_fp: 166.0000 - val_tn: 611.0000 - val_fn: 168.0000 - val_accuracy: 0.7055 - val_precision: 0.5324 - val_recall: 0.5294 - val_auc: 0.6833 - val_prc: 0.4923\n",
      "Epoch 128/200\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 0.0174 - tp: 1396.0000 - fp: 20.0000 - tn: 3087.0000 - fn: 33.0000 - accuracy: 0.9883 - precision: 0.9859 - recall: 0.9769 - auc: 0.9997 - prc: 0.9994 - val_loss: 2.8424 - val_tp: 185.0000 - val_fp: 162.0000 - val_tn: 615.0000 - val_fn: 172.0000 - val_accuracy: 0.7055 - val_precision: 0.5331 - val_recall: 0.5182 - val_auc: 0.6884 - val_prc: 0.4995\n",
      "Epoch 129/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0186 - tp: 1400.0000 - fp: 27.0000 - tn: 3080.0000 - fn: 29.0000 - accuracy: 0.9877 - precision: 0.9811 - recall: 0.9797 - auc: 0.9997 - prc: 0.9993 - val_loss: 2.9041 - val_tp: 154.0000 - val_fp: 117.0000 - val_tn: 660.0000 - val_fn: 203.0000 - val_accuracy: 0.7178 - val_precision: 0.5683 - val_recall: 0.4314 - val_auc: 0.6779 - val_prc: 0.4969\n",
      "Epoch 130/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0182 - tp: 1393.0000 - fp: 22.0000 - tn: 3085.0000 - fn: 36.0000 - accuracy: 0.9872 - precision: 0.9845 - recall: 0.9748 - auc: 0.9997 - prc: 0.9993 - val_loss: 2.9270 - val_tp: 202.0000 - val_fp: 187.0000 - val_tn: 590.0000 - val_fn: 155.0000 - val_accuracy: 0.6984 - val_precision: 0.5193 - val_recall: 0.5658 - val_auc: 0.6844 - val_prc: 0.4888\n",
      "Epoch 131/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0182 - tp: 1401.0000 - fp: 18.0000 - tn: 3089.0000 - fn: 28.0000 - accuracy: 0.9899 - precision: 0.9873 - recall: 0.9804 - auc: 0.9997 - prc: 0.9994 - val_loss: 2.8673 - val_tp: 163.0000 - val_fp: 133.0000 - val_tn: 644.0000 - val_fn: 194.0000 - val_accuracy: 0.7116 - val_precision: 0.5507 - val_recall: 0.4566 - val_auc: 0.6809 - val_prc: 0.4979\n",
      "Epoch 132/200\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 0.0182 - tp: 1396.0000 - fp: 22.0000 - tn: 3085.0000 - fn: 33.0000 - accuracy: 0.9879 - precision: 0.9845 - recall: 0.9769 - auc: 0.9997 - prc: 0.9993 - val_loss: 2.8350 - val_tp: 169.0000 - val_fp: 140.0000 - val_tn: 637.0000 - val_fn: 188.0000 - val_accuracy: 0.7108 - val_precision: 0.5469 - val_recall: 0.4734 - val_auc: 0.6803 - val_prc: 0.4943\n",
      "Epoch 133/200\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 0.0172 - tp: 1397.0000 - fp: 22.0000 - tn: 3085.0000 - fn: 32.0000 - accuracy: 0.9881 - precision: 0.9845 - recall: 0.9776 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.1075 - val_tp: 174.0000 - val_fp: 143.0000 - val_tn: 634.0000 - val_fn: 183.0000 - val_accuracy: 0.7125 - val_precision: 0.5489 - val_recall: 0.4874 - val_auc: 0.6810 - val_prc: 0.4959\n",
      "Epoch 134/200\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 0.0182 - tp: 1397.0000 - fp: 21.0000 - tn: 3086.0000 - fn: 32.0000 - accuracy: 0.9883 - precision: 0.9852 - recall: 0.9776 - auc: 0.9997 - prc: 0.9994 - val_loss: 2.8310 - val_tp: 196.0000 - val_fp: 175.0000 - val_tn: 602.0000 - val_fn: 161.0000 - val_accuracy: 0.7037 - val_precision: 0.5283 - val_recall: 0.5490 - val_auc: 0.6865 - val_prc: 0.4948\n",
      "Epoch 135/200\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 0.0177 - tp: 1406.0000 - fp: 25.0000 - tn: 3082.0000 - fn: 23.0000 - accuracy: 0.9894 - precision: 0.9825 - recall: 0.9839 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.0760 - val_tp: 164.0000 - val_fp: 131.0000 - val_tn: 646.0000 - val_fn: 193.0000 - val_accuracy: 0.7143 - val_precision: 0.5559 - val_recall: 0.4594 - val_auc: 0.6816 - val_prc: 0.4998\n",
      "Epoch 136/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0177 - tp: 1403.0000 - fp: 18.0000 - tn: 3089.0000 - fn: 26.0000 - accuracy: 0.9903 - precision: 0.9873 - recall: 0.9818 - auc: 0.9997 - prc: 0.9994 - val_loss: 2.9929 - val_tp: 191.0000 - val_fp: 166.0000 - val_tn: 611.0000 - val_fn: 166.0000 - val_accuracy: 0.7072 - val_precision: 0.5350 - val_recall: 0.5350 - val_auc: 0.6872 - val_prc: 0.4944\n",
      "Epoch 137/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0180 - tp: 1411.0000 - fp: 25.0000 - tn: 3082.0000 - fn: 18.0000 - accuracy: 0.9905 - precision: 0.9826 - recall: 0.9874 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.0102 - val_tp: 163.0000 - val_fp: 134.0000 - val_tn: 643.0000 - val_fn: 194.0000 - val_accuracy: 0.7108 - val_precision: 0.5488 - val_recall: 0.4566 - val_auc: 0.6796 - val_prc: 0.4969\n",
      "Epoch 138/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0172 - tp: 1403.0000 - fp: 25.0000 - tn: 3082.0000 - fn: 26.0000 - accuracy: 0.9888 - precision: 0.9825 - recall: 0.9818 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.0461 - val_tp: 170.0000 - val_fp: 142.0000 - val_tn: 635.0000 - val_fn: 187.0000 - val_accuracy: 0.7099 - val_precision: 0.5449 - val_recall: 0.4762 - val_auc: 0.6789 - val_prc: 0.4928\n",
      "Epoch 139/200\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 0.0174 - tp: 1406.0000 - fp: 24.0000 - tn: 3083.0000 - fn: 23.0000 - accuracy: 0.9896 - precision: 0.9832 - recall: 0.9839 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.0989 - val_tp: 158.0000 - val_fp: 121.0000 - val_tn: 656.0000 - val_fn: 199.0000 - val_accuracy: 0.7178 - val_precision: 0.5663 - val_recall: 0.4426 - val_auc: 0.6751 - val_prc: 0.4992\n",
      "Epoch 140/200\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 0.0176 - tp: 1403.0000 - fp: 26.0000 - tn: 3081.0000 - fn: 26.0000 - accuracy: 0.9885 - precision: 0.9818 - recall: 0.9818 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.0290 - val_tp: 212.0000 - val_fp: 212.0000 - val_tn: 565.0000 - val_fn: 145.0000 - val_accuracy: 0.6852 - val_precision: 0.5000 - val_recall: 0.5938 - val_auc: 0.6834 - val_prc: 0.4814\n",
      "Epoch 141/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0180 - tp: 1398.0000 - fp: 22.0000 - tn: 3085.0000 - fn: 31.0000 - accuracy: 0.9883 - precision: 0.9845 - recall: 0.9783 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.0769 - val_tp: 164.0000 - val_fp: 129.0000 - val_tn: 648.0000 - val_fn: 193.0000 - val_accuracy: 0.7160 - val_precision: 0.5597 - val_recall: 0.4594 - val_auc: 0.6776 - val_prc: 0.4959\n",
      "Epoch 142/200\n",
      "71/71 [==============================] - 1s 16ms/step - loss: 0.0183 - tp: 1398.0000 - fp: 20.0000 - tn: 3087.0000 - fn: 31.0000 - accuracy: 0.9888 - precision: 0.9859 - recall: 0.9783 - auc: 0.9997 - prc: 0.9993 - val_loss: 3.1181 - val_tp: 164.0000 - val_fp: 129.0000 - val_tn: 648.0000 - val_fn: 193.0000 - val_accuracy: 0.7160 - val_precision: 0.5597 - val_recall: 0.4594 - val_auc: 0.6801 - val_prc: 0.4996\n",
      "Epoch 143/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0180 - tp: 1400.0000 - fp: 13.0000 - tn: 3094.0000 - fn: 29.0000 - accuracy: 0.9907 - precision: 0.9908 - recall: 0.9797 - auc: 0.9997 - prc: 0.9994 - val_loss: 2.9933 - val_tp: 187.0000 - val_fp: 167.0000 - val_tn: 610.0000 - val_fn: 170.0000 - val_accuracy: 0.7028 - val_precision: 0.5282 - val_recall: 0.5238 - val_auc: 0.6849 - val_prc: 0.4940\n",
      "Epoch 144/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0172 - tp: 1404.0000 - fp: 24.0000 - tn: 3083.0000 - fn: 25.0000 - accuracy: 0.9892 - precision: 0.9832 - recall: 0.9825 - auc: 0.9997 - prc: 0.9994 - val_loss: 2.9507 - val_tp: 184.0000 - val_fp: 157.0000 - val_tn: 620.0000 - val_fn: 173.0000 - val_accuracy: 0.7090 - val_precision: 0.5396 - val_recall: 0.5154 - val_auc: 0.6846 - val_prc: 0.4960\n",
      "Epoch 145/200\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 0.0169 - tp: 1404.0000 - fp: 24.0000 - tn: 3083.0000 - fn: 25.0000 - accuracy: 0.9892 - precision: 0.9832 - recall: 0.9825 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.1933 - val_tp: 172.0000 - val_fp: 134.0000 - val_tn: 643.0000 - val_fn: 185.0000 - val_accuracy: 0.7187 - val_precision: 0.5621 - val_recall: 0.4818 - val_auc: 0.6795 - val_prc: 0.4939\n",
      "Epoch 146/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0175 - tp: 1403.0000 - fp: 23.0000 - tn: 3084.0000 - fn: 26.0000 - accuracy: 0.9892 - precision: 0.9839 - recall: 0.9818 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.0255 - val_tp: 190.0000 - val_fp: 172.0000 - val_tn: 605.0000 - val_fn: 167.0000 - val_accuracy: 0.7011 - val_precision: 0.5249 - val_recall: 0.5322 - val_auc: 0.6828 - val_prc: 0.4893\n",
      "Epoch 147/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0173 - tp: 1405.0000 - fp: 24.0000 - tn: 3083.0000 - fn: 24.0000 - accuracy: 0.9894 - precision: 0.9832 - recall: 0.9832 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.1165 - val_tp: 183.0000 - val_fp: 155.0000 - val_tn: 622.0000 - val_fn: 174.0000 - val_accuracy: 0.7099 - val_precision: 0.5414 - val_recall: 0.5126 - val_auc: 0.6812 - val_prc: 0.4942\n",
      "Epoch 148/200\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 0.0175 - tp: 1394.0000 - fp: 14.0000 - tn: 3093.0000 - fn: 35.0000 - accuracy: 0.9892 - precision: 0.9901 - recall: 0.9755 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.0511 - val_tp: 182.0000 - val_fp: 149.0000 - val_tn: 628.0000 - val_fn: 175.0000 - val_accuracy: 0.7143 - val_precision: 0.5498 - val_recall: 0.5098 - val_auc: 0.6827 - val_prc: 0.4948\n",
      "Epoch 149/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0174 - tp: 1399.0000 - fp: 19.0000 - tn: 3088.0000 - fn: 30.0000 - accuracy: 0.9892 - precision: 0.9866 - recall: 0.9790 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.1988 - val_tp: 192.0000 - val_fp: 171.0000 - val_tn: 606.0000 - val_fn: 165.0000 - val_accuracy: 0.7037 - val_precision: 0.5289 - val_recall: 0.5378 - val_auc: 0.6847 - val_prc: 0.4891\n",
      "Epoch 150/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0175 - tp: 1402.0000 - fp: 22.0000 - tn: 3085.0000 - fn: 27.0000 - accuracy: 0.9892 - precision: 0.9846 - recall: 0.9811 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.2148 - val_tp: 191.0000 - val_fp: 172.0000 - val_tn: 605.0000 - val_fn: 166.0000 - val_accuracy: 0.7019 - val_precision: 0.5262 - val_recall: 0.5350 - val_auc: 0.6874 - val_prc: 0.4927\n",
      "Epoch 151/200\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 0.0172 - tp: 1402.0000 - fp: 22.0000 - tn: 3085.0000 - fn: 27.0000 - accuracy: 0.9892 - precision: 0.9846 - recall: 0.9811 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.2699 - val_tp: 163.0000 - val_fp: 130.0000 - val_tn: 647.0000 - val_fn: 194.0000 - val_accuracy: 0.7143 - val_precision: 0.5563 - val_recall: 0.4566 - val_auc: 0.6749 - val_prc: 0.4951\n",
      "Epoch 152/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0178 - tp: 1397.0000 - fp: 18.0000 - tn: 3089.0000 - fn: 32.0000 - accuracy: 0.9890 - precision: 0.9873 - recall: 0.9776 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.2190 - val_tp: 193.0000 - val_fp: 174.0000 - val_tn: 603.0000 - val_fn: 164.0000 - val_accuracy: 0.7019 - val_precision: 0.5259 - val_recall: 0.5406 - val_auc: 0.6874 - val_prc: 0.4918\n",
      "Epoch 153/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0170 - tp: 1399.0000 - fp: 17.0000 - tn: 3090.0000 - fn: 30.0000 - accuracy: 0.9896 - precision: 0.9880 - recall: 0.9790 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.2844 - val_tp: 164.0000 - val_fp: 135.0000 - val_tn: 642.0000 - val_fn: 193.0000 - val_accuracy: 0.7108 - val_precision: 0.5485 - val_recall: 0.4594 - val_auc: 0.6769 - val_prc: 0.4922\n",
      "Epoch 154/200\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 0.0169 - tp: 1400.0000 - fp: 16.0000 - tn: 3091.0000 - fn: 29.0000 - accuracy: 0.9901 - precision: 0.9887 - recall: 0.9797 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.2906 - val_tp: 181.0000 - val_fp: 152.0000 - val_tn: 625.0000 - val_fn: 176.0000 - val_accuracy: 0.7108 - val_precision: 0.5435 - val_recall: 0.5070 - val_auc: 0.6850 - val_prc: 0.4958\n",
      "Epoch 155/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0168 - tp: 1399.0000 - fp: 17.0000 - tn: 3090.0000 - fn: 30.0000 - accuracy: 0.9896 - precision: 0.9880 - recall: 0.9790 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.3155 - val_tp: 165.0000 - val_fp: 135.0000 - val_tn: 642.0000 - val_fn: 192.0000 - val_accuracy: 0.7116 - val_precision: 0.5500 - val_recall: 0.4622 - val_auc: 0.6776 - val_prc: 0.4943\n",
      "Epoch 156/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0173 - tp: 1398.0000 - fp: 15.0000 - tn: 3092.0000 - fn: 31.0000 - accuracy: 0.9899 - precision: 0.9894 - recall: 0.9783 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.2936 - val_tp: 218.0000 - val_fp: 214.0000 - val_tn: 563.0000 - val_fn: 139.0000 - val_accuracy: 0.6887 - val_precision: 0.5046 - val_recall: 0.6106 - val_auc: 0.6852 - val_prc: 0.4842\n",
      "Epoch 157/200\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 0.0172 - tp: 1398.0000 - fp: 11.0000 - tn: 3096.0000 - fn: 31.0000 - accuracy: 0.9907 - precision: 0.9922 - recall: 0.9783 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.2975 - val_tp: 186.0000 - val_fp: 157.0000 - val_tn: 620.0000 - val_fn: 171.0000 - val_accuracy: 0.7108 - val_precision: 0.5423 - val_recall: 0.5210 - val_auc: 0.6851 - val_prc: 0.4942\n",
      "Epoch 158/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0172 - tp: 1398.0000 - fp: 18.0000 - tn: 3089.0000 - fn: 31.0000 - accuracy: 0.9892 - precision: 0.9873 - recall: 0.9783 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.3767 - val_tp: 181.0000 - val_fp: 153.0000 - val_tn: 624.0000 - val_fn: 176.0000 - val_accuracy: 0.7099 - val_precision: 0.5419 - val_recall: 0.5070 - val_auc: 0.6846 - val_prc: 0.4957\n",
      "Epoch 159/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0171 - tp: 1398.0000 - fp: 18.0000 - tn: 3089.0000 - fn: 31.0000 - accuracy: 0.9892 - precision: 0.9873 - recall: 0.9783 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.3161 - val_tp: 164.0000 - val_fp: 134.0000 - val_tn: 643.0000 - val_fn: 193.0000 - val_accuracy: 0.7116 - val_precision: 0.5503 - val_recall: 0.4594 - val_auc: 0.6766 - val_prc: 0.4912\n",
      "Epoch 160/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0168 - tp: 1398.0000 - fp: 22.0000 - tn: 3085.0000 - fn: 31.0000 - accuracy: 0.9883 - precision: 0.9845 - recall: 0.9783 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.3511 - val_tp: 181.0000 - val_fp: 155.0000 - val_tn: 622.0000 - val_fn: 176.0000 - val_accuracy: 0.7081 - val_precision: 0.5387 - val_recall: 0.5070 - val_auc: 0.6853 - val_prc: 0.4922\n",
      "Epoch 161/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0167 - tp: 1399.0000 - fp: 21.0000 - tn: 3086.0000 - fn: 30.0000 - accuracy: 0.9888 - precision: 0.9852 - recall: 0.9790 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.3615 - val_tp: 175.0000 - val_fp: 147.0000 - val_tn: 630.0000 - val_fn: 182.0000 - val_accuracy: 0.7099 - val_precision: 0.5435 - val_recall: 0.4902 - val_auc: 0.6847 - val_prc: 0.4986\n",
      "Epoch 162/200\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 0.0169 - tp: 1396.0000 - fp: 20.0000 - tn: 3087.0000 - fn: 33.0000 - accuracy: 0.9883 - precision: 0.9859 - recall: 0.9769 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.3656 - val_tp: 184.0000 - val_fp: 155.0000 - val_tn: 622.0000 - val_fn: 173.0000 - val_accuracy: 0.7108 - val_precision: 0.5428 - val_recall: 0.5154 - val_auc: 0.6846 - val_prc: 0.4936\n",
      "Epoch 163/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0169 - tp: 1397.0000 - fp: 16.0000 - tn: 3091.0000 - fn: 32.0000 - accuracy: 0.9894 - precision: 0.9887 - recall: 0.9776 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.4552 - val_tp: 194.0000 - val_fp: 169.0000 - val_tn: 608.0000 - val_fn: 163.0000 - val_accuracy: 0.7072 - val_precision: 0.5344 - val_recall: 0.5434 - val_auc: 0.6842 - val_prc: 0.4846\n",
      "Epoch 164/200\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 0.0169 - tp: 1396.0000 - fp: 16.0000 - tn: 3091.0000 - fn: 33.0000 - accuracy: 0.9892 - precision: 0.9887 - recall: 0.9769 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.5315 - val_tp: 156.0000 - val_fp: 118.0000 - val_tn: 659.0000 - val_fn: 201.0000 - val_accuracy: 0.7187 - val_precision: 0.5693 - val_recall: 0.4370 - val_auc: 0.6731 - val_prc: 0.4952\n",
      "Epoch 165/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0175 - tp: 1399.0000 - fp: 22.0000 - tn: 3085.0000 - fn: 30.0000 - accuracy: 0.9885 - precision: 0.9845 - recall: 0.9790 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.5359 - val_tp: 165.0000 - val_fp: 126.0000 - val_tn: 651.0000 - val_fn: 192.0000 - val_accuracy: 0.7196 - val_precision: 0.5670 - val_recall: 0.4622 - val_auc: 0.6764 - val_prc: 0.4923\n",
      "Epoch 166/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0170 - tp: 1399.0000 - fp: 16.0000 - tn: 3091.0000 - fn: 30.0000 - accuracy: 0.9899 - precision: 0.9887 - recall: 0.9790 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.3833 - val_tp: 184.0000 - val_fp: 157.0000 - val_tn: 620.0000 - val_fn: 173.0000 - val_accuracy: 0.7090 - val_precision: 0.5396 - val_recall: 0.5154 - val_auc: 0.6841 - val_prc: 0.4923\n",
      "Epoch 167/200\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 0.0166 - tp: 1399.0000 - fp: 20.0000 - tn: 3087.0000 - fn: 30.0000 - accuracy: 0.9890 - precision: 0.9859 - recall: 0.9790 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.4264 - val_tp: 180.0000 - val_fp: 152.0000 - val_tn: 625.0000 - val_fn: 177.0000 - val_accuracy: 0.7099 - val_precision: 0.5422 - val_recall: 0.5042 - val_auc: 0.6845 - val_prc: 0.4958\n",
      "Epoch 168/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0169 - tp: 1396.0000 - fp: 23.0000 - tn: 3084.0000 - fn: 33.0000 - accuracy: 0.9877 - precision: 0.9838 - recall: 0.9769 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.4499 - val_tp: 168.0000 - val_fp: 138.0000 - val_tn: 639.0000 - val_fn: 189.0000 - val_accuracy: 0.7116 - val_precision: 0.5490 - val_recall: 0.4706 - val_auc: 0.6765 - val_prc: 0.4922\n",
      "Epoch 169/200\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 0.0171 - tp: 1396.0000 - fp: 20.0000 - tn: 3087.0000 - fn: 33.0000 - accuracy: 0.9883 - precision: 0.9859 - recall: 0.9769 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.4908 - val_tp: 168.0000 - val_fp: 139.0000 - val_tn: 638.0000 - val_fn: 189.0000 - val_accuracy: 0.7108 - val_precision: 0.5472 - val_recall: 0.4706 - val_auc: 0.6762 - val_prc: 0.4901\n",
      "Epoch 170/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0168 - tp: 1399.0000 - fp: 19.0000 - tn: 3088.0000 - fn: 30.0000 - accuracy: 0.9892 - precision: 0.9866 - recall: 0.9790 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.5018 - val_tp: 189.0000 - val_fp: 165.0000 - val_tn: 612.0000 - val_fn: 168.0000 - val_accuracy: 0.7063 - val_precision: 0.5339 - val_recall: 0.5294 - val_auc: 0.6889 - val_prc: 0.4910\n",
      "Epoch 171/200\n",
      "71/71 [==============================] - 1s 16ms/step - loss: 0.0169 - tp: 1401.0000 - fp: 19.0000 - tn: 3088.0000 - fn: 28.0000 - accuracy: 0.9896 - precision: 0.9866 - recall: 0.9804 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.4396 - val_tp: 184.0000 - val_fp: 155.0000 - val_tn: 622.0000 - val_fn: 173.0000 - val_accuracy: 0.7108 - val_precision: 0.5428 - val_recall: 0.5154 - val_auc: 0.6846 - val_prc: 0.4889\n",
      "Epoch 172/200\n",
      "71/71 [==============================] - 1s 16ms/step - loss: 0.0169 - tp: 1399.0000 - fp: 14.0000 - tn: 3093.0000 - fn: 30.0000 - accuracy: 0.9903 - precision: 0.9901 - recall: 0.9790 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.4466 - val_tp: 192.0000 - val_fp: 171.0000 - val_tn: 606.0000 - val_fn: 165.0000 - val_accuracy: 0.7037 - val_precision: 0.5289 - val_recall: 0.5378 - val_auc: 0.6858 - val_prc: 0.4894\n",
      "Epoch 173/200\n",
      "71/71 [==============================] - 1s 16ms/step - loss: 0.0166 - tp: 1398.0000 - fp: 16.0000 - tn: 3091.0000 - fn: 31.0000 - accuracy: 0.9896 - precision: 0.9887 - recall: 0.9783 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.5397 - val_tp: 188.0000 - val_fp: 163.0000 - val_tn: 614.0000 - val_fn: 169.0000 - val_accuracy: 0.7072 - val_precision: 0.5356 - val_recall: 0.5266 - val_auc: 0.6857 - val_prc: 0.4858\n",
      "Epoch 174/200\n",
      "71/71 [==============================] - 1s 16ms/step - loss: 0.0168 - tp: 1392.0000 - fp: 12.0000 - tn: 3095.0000 - fn: 37.0000 - accuracy: 0.9892 - precision: 0.9915 - recall: 0.9741 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.5022 - val_tp: 167.0000 - val_fp: 141.0000 - val_tn: 636.0000 - val_fn: 190.0000 - val_accuracy: 0.7081 - val_precision: 0.5422 - val_recall: 0.4678 - val_auc: 0.6795 - val_prc: 0.4928\n",
      "Epoch 175/200\n",
      "71/71 [==============================] - 1s 17ms/step - loss: 0.0173 - tp: 1399.0000 - fp: 24.0000 - tn: 3083.0000 - fn: 30.0000 - accuracy: 0.9881 - precision: 0.9831 - recall: 0.9790 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.4951 - val_tp: 179.0000 - val_fp: 150.0000 - val_tn: 627.0000 - val_fn: 178.0000 - val_accuracy: 0.7108 - val_precision: 0.5441 - val_recall: 0.5014 - val_auc: 0.6873 - val_prc: 0.4930\n",
      "Epoch 176/200\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 0.0167 - tp: 1399.0000 - fp: 15.0000 - tn: 3092.0000 - fn: 30.0000 - accuracy: 0.9901 - precision: 0.9894 - recall: 0.9790 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.5633 - val_tp: 196.0000 - val_fp: 179.0000 - val_tn: 598.0000 - val_fn: 161.0000 - val_accuracy: 0.7002 - val_precision: 0.5227 - val_recall: 0.5490 - val_auc: 0.6835 - val_prc: 0.4834\n",
      "Epoch 177/200\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 0.0175 - tp: 1401.0000 - fp: 18.0000 - tn: 3089.0000 - fn: 28.0000 - accuracy: 0.9899 - precision: 0.9873 - recall: 0.9804 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.6872 - val_tp: 155.0000 - val_fp: 113.0000 - val_tn: 664.0000 - val_fn: 202.0000 - val_accuracy: 0.7222 - val_precision: 0.5784 - val_recall: 0.4342 - val_auc: 0.6683 - val_prc: 0.4894\n",
      "Epoch 178/200\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 0.0166 - tp: 1394.0000 - fp: 16.0000 - tn: 3091.0000 - fn: 35.0000 - accuracy: 0.9888 - precision: 0.9887 - recall: 0.9755 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.6059 - val_tp: 197.0000 - val_fp: 182.0000 - val_tn: 595.0000 - val_fn: 160.0000 - val_accuracy: 0.6984 - val_precision: 0.5198 - val_recall: 0.5518 - val_auc: 0.6842 - val_prc: 0.4809\n",
      "Epoch 179/200\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 0.0176 - tp: 1397.0000 - fp: 15.0000 - tn: 3092.0000 - fn: 32.0000 - accuracy: 0.9896 - precision: 0.9894 - recall: 0.9776 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.6175 - val_tp: 174.0000 - val_fp: 146.0000 - val_tn: 631.0000 - val_fn: 183.0000 - val_accuracy: 0.7099 - val_precision: 0.5437 - val_recall: 0.4874 - val_auc: 0.6779 - val_prc: 0.4911\n",
      "Epoch 180/200\n",
      "71/71 [==============================] - 1s 17ms/step - loss: 0.0167 - tp: 1395.0000 - fp: 14.0000 - tn: 3093.0000 - fn: 34.0000 - accuracy: 0.9894 - precision: 0.9901 - recall: 0.9762 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.6697 - val_tp: 174.0000 - val_fp: 143.0000 - val_tn: 634.0000 - val_fn: 183.0000 - val_accuracy: 0.7125 - val_precision: 0.5489 - val_recall: 0.4874 - val_auc: 0.6782 - val_prc: 0.4903\n",
      "Epoch 181/200\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0170 - tp: 1396.0000 - fp: 14.0000 - tn: 3093.0000 - fn: 33.0000 - accuracy: 0.9896 - precision: 0.9901 - recall: 0.9769 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.8623 - val_tp: 142.0000 - val_fp: 103.0000 - val_tn: 674.0000 - val_fn: 215.0000 - val_accuracy: 0.7196 - val_precision: 0.5796 - val_recall: 0.3978 - val_auc: 0.6612 - val_prc: 0.4908\n",
      "Epoch 182/200\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 0.0167 - tp: 1397.0000 - fp: 14.0000 - tn: 3093.0000 - fn: 32.0000 - accuracy: 0.9899 - precision: 0.9901 - recall: 0.9776 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.7527 - val_tp: 196.0000 - val_fp: 185.0000 - val_tn: 592.0000 - val_fn: 161.0000 - val_accuracy: 0.6949 - val_precision: 0.5144 - val_recall: 0.5490 - val_auc: 0.6839 - val_prc: 0.4816\n",
      "Epoch 183/200\n",
      "71/71 [==============================] - 1s 16ms/step - loss: 0.0170 - tp: 1396.0000 - fp: 13.0000 - tn: 3094.0000 - fn: 33.0000 - accuracy: 0.9899 - precision: 0.9908 - recall: 0.9769 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.6990 - val_tp: 183.0000 - val_fp: 155.0000 - val_tn: 622.0000 - val_fn: 174.0000 - val_accuracy: 0.7099 - val_precision: 0.5414 - val_recall: 0.5126 - val_auc: 0.6816 - val_prc: 0.4916\n",
      "Epoch 184/200\n",
      "71/71 [==============================] - 1s 17ms/step - loss: 0.0164 - tp: 1396.0000 - fp: 18.0000 - tn: 3089.0000 - fn: 33.0000 - accuracy: 0.9888 - precision: 0.9873 - recall: 0.9769 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.7647 - val_tp: 171.0000 - val_fp: 136.0000 - val_tn: 641.0000 - val_fn: 186.0000 - val_accuracy: 0.7160 - val_precision: 0.5570 - val_recall: 0.4790 - val_auc: 0.6752 - val_prc: 0.4909\n",
      "Epoch 185/200\n",
      "71/71 [==============================] - 1s 18ms/step - loss: 0.0164 - tp: 1401.0000 - fp: 16.0000 - tn: 3091.0000 - fn: 28.0000 - accuracy: 0.9903 - precision: 0.9887 - recall: 0.9804 - auc: 0.9997 - prc: 0.9995 - val_loss: 3.7928 - val_tp: 168.0000 - val_fp: 134.0000 - val_tn: 643.0000 - val_fn: 189.0000 - val_accuracy: 0.7152 - val_precision: 0.5563 - val_recall: 0.4706 - val_auc: 0.6765 - val_prc: 0.4928\n",
      "Epoch 186/200\n",
      "71/71 [==============================] - 1s 19ms/step - loss: 0.0164 - tp: 1398.0000 - fp: 13.0000 - tn: 3094.0000 - fn: 31.0000 - accuracy: 0.9903 - precision: 0.9908 - recall: 0.9783 - auc: 0.9998 - prc: 0.9995 - val_loss: 3.7886 - val_tp: 183.0000 - val_fp: 157.0000 - val_tn: 620.0000 - val_fn: 174.0000 - val_accuracy: 0.7081 - val_precision: 0.5382 - val_recall: 0.5126 - val_auc: 0.6823 - val_prc: 0.4856\n",
      "Epoch 187/200\n",
      "71/71 [==============================] - 1s 17ms/step - loss: 0.0164 - tp: 1398.0000 - fp: 15.0000 - tn: 3092.0000 - fn: 31.0000 - accuracy: 0.9899 - precision: 0.9894 - recall: 0.9783 - auc: 0.9997 - prc: 0.9995 - val_loss: 3.7367 - val_tp: 196.0000 - val_fp: 180.0000 - val_tn: 597.0000 - val_fn: 161.0000 - val_accuracy: 0.6993 - val_precision: 0.5213 - val_recall: 0.5490 - val_auc: 0.6834 - val_prc: 0.4821\n",
      "Epoch 188/200\n",
      "71/71 [==============================] - 1s 18ms/step - loss: 0.0172 - tp: 1397.0000 - fp: 14.0000 - tn: 3093.0000 - fn: 32.0000 - accuracy: 0.9899 - precision: 0.9901 - recall: 0.9776 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.6962 - val_tp: 169.0000 - val_fp: 138.0000 - val_tn: 639.0000 - val_fn: 188.0000 - val_accuracy: 0.7125 - val_precision: 0.5505 - val_recall: 0.4734 - val_auc: 0.6739 - val_prc: 0.4896\n",
      "Epoch 189/200\n",
      "71/71 [==============================] - 1s 17ms/step - loss: 0.0173 - tp: 1393.0000 - fp: 12.0000 - tn: 3095.0000 - fn: 36.0000 - accuracy: 0.9894 - precision: 0.9915 - recall: 0.9748 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.7657 - val_tp: 182.0000 - val_fp: 156.0000 - val_tn: 621.0000 - val_fn: 175.0000 - val_accuracy: 0.7081 - val_precision: 0.5385 - val_recall: 0.5098 - val_auc: 0.6776 - val_prc: 0.4816\n",
      "Epoch 190/200\n",
      "71/71 [==============================] - 1s 17ms/step - loss: 0.0158 - tp: 1399.0000 - fp: 13.0000 - tn: 3094.0000 - fn: 30.0000 - accuracy: 0.9905 - precision: 0.9908 - recall: 0.9790 - auc: 0.9998 - prc: 0.9995 - val_loss: 3.9881 - val_tp: 152.0000 - val_fp: 114.0000 - val_tn: 663.0000 - val_fn: 205.0000 - val_accuracy: 0.7187 - val_precision: 0.5714 - val_recall: 0.4258 - val_auc: 0.6684 - val_prc: 0.4895\n",
      "Epoch 191/200\n",
      "71/71 [==============================] - 1s 17ms/step - loss: 0.0168 - tp: 1402.0000 - fp: 15.0000 - tn: 3092.0000 - fn: 27.0000 - accuracy: 0.9907 - precision: 0.9894 - recall: 0.9811 - auc: 0.9998 - prc: 0.9995 - val_loss: 3.7847 - val_tp: 179.0000 - val_fp: 152.0000 - val_tn: 625.0000 - val_fn: 178.0000 - val_accuracy: 0.7090 - val_precision: 0.5408 - val_recall: 0.5014 - val_auc: 0.6742 - val_prc: 0.4831\n",
      "Epoch 192/200\n",
      "71/71 [==============================] - 1s 17ms/step - loss: 0.0161 - tp: 1400.0000 - fp: 18.0000 - tn: 3089.0000 - fn: 29.0000 - accuracy: 0.9896 - precision: 0.9873 - recall: 0.9797 - auc: 0.9997 - prc: 0.9995 - val_loss: 3.7901 - val_tp: 183.0000 - val_fp: 158.0000 - val_tn: 619.0000 - val_fn: 174.0000 - val_accuracy: 0.7072 - val_precision: 0.5367 - val_recall: 0.5126 - val_auc: 0.6824 - val_prc: 0.4924\n",
      "Epoch 193/200\n",
      "71/71 [==============================] - 1s 17ms/step - loss: 0.0167 - tp: 1397.0000 - fp: 20.0000 - tn: 3087.0000 - fn: 32.0000 - accuracy: 0.9885 - precision: 0.9859 - recall: 0.9776 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.8249 - val_tp: 173.0000 - val_fp: 147.0000 - val_tn: 630.0000 - val_fn: 184.0000 - val_accuracy: 0.7081 - val_precision: 0.5406 - val_recall: 0.4846 - val_auc: 0.6783 - val_prc: 0.4888\n",
      "Epoch 194/200\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 0.0160 - tp: 1398.0000 - fp: 12.0000 - tn: 3095.0000 - fn: 31.0000 - accuracy: 0.9905 - precision: 0.9915 - recall: 0.9783 - auc: 0.9998 - prc: 0.9995 - val_loss: 3.8824 - val_tp: 185.0000 - val_fp: 163.0000 - val_tn: 614.0000 - val_fn: 172.0000 - val_accuracy: 0.7046 - val_precision: 0.5316 - val_recall: 0.5182 - val_auc: 0.6829 - val_prc: 0.4839\n",
      "Epoch 195/200\n",
      "71/71 [==============================] - 1s 16ms/step - loss: 0.0162 - tp: 1404.0000 - fp: 18.0000 - tn: 3089.0000 - fn: 25.0000 - accuracy: 0.9905 - precision: 0.9873 - recall: 0.9825 - auc: 0.9997 - prc: 0.9995 - val_loss: 3.8150 - val_tp: 176.0000 - val_fp: 149.0000 - val_tn: 628.0000 - val_fn: 181.0000 - val_accuracy: 0.7090 - val_precision: 0.5415 - val_recall: 0.4930 - val_auc: 0.6765 - val_prc: 0.4860\n",
      "Epoch 196/200\n",
      "71/71 [==============================] - 1s 16ms/step - loss: 0.0165 - tp: 1397.0000 - fp: 20.0000 - tn: 3087.0000 - fn: 32.0000 - accuracy: 0.9885 - precision: 0.9859 - recall: 0.9776 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.7743 - val_tp: 185.0000 - val_fp: 163.0000 - val_tn: 614.0000 - val_fn: 172.0000 - val_accuracy: 0.7046 - val_precision: 0.5316 - val_recall: 0.5182 - val_auc: 0.6798 - val_prc: 0.4834\n",
      "Epoch 197/200\n",
      "71/71 [==============================] - 1s 17ms/step - loss: 0.0162 - tp: 1400.0000 - fp: 14.0000 - tn: 3093.0000 - fn: 29.0000 - accuracy: 0.9905 - precision: 0.9901 - recall: 0.9797 - auc: 0.9998 - prc: 0.9995 - val_loss: 4.0738 - val_tp: 210.0000 - val_fp: 201.0000 - val_tn: 576.0000 - val_fn: 147.0000 - val_accuracy: 0.6931 - val_precision: 0.5109 - val_recall: 0.5882 - val_auc: 0.6857 - val_prc: 0.4813\n",
      "Epoch 198/200\n",
      "71/71 [==============================] - 1s 16ms/step - loss: 0.0168 - tp: 1403.0000 - fp: 21.0000 - tn: 3086.0000 - fn: 26.0000 - accuracy: 0.9896 - precision: 0.9853 - recall: 0.9818 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.8583 - val_tp: 194.0000 - val_fp: 177.0000 - val_tn: 600.0000 - val_fn: 163.0000 - val_accuracy: 0.7002 - val_precision: 0.5229 - val_recall: 0.5434 - val_auc: 0.6863 - val_prc: 0.4850\n",
      "Epoch 199/200\n",
      "71/71 [==============================] - 1s 16ms/step - loss: 0.0174 - tp: 1400.0000 - fp: 20.0000 - tn: 3087.0000 - fn: 29.0000 - accuracy: 0.9892 - precision: 0.9859 - recall: 0.9797 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.9199 - val_tp: 209.0000 - val_fp: 200.0000 - val_tn: 577.0000 - val_fn: 148.0000 - val_accuracy: 0.6931 - val_precision: 0.5110 - val_recall: 0.5854 - val_auc: 0.6855 - val_prc: 0.4854\n",
      "Epoch 200/200\n",
      "71/71 [==============================] - 1s 16ms/step - loss: 0.0161 - tp: 1402.0000 - fp: 16.0000 - tn: 3091.0000 - fn: 27.0000 - accuracy: 0.9905 - precision: 0.9887 - recall: 0.9811 - auc: 0.9998 - prc: 0.9995 - val_loss: 3.9292 - val_tp: 162.0000 - val_fp: 130.0000 - val_tn: 647.0000 - val_fn: 195.0000 - val_accuracy: 0.7134 - val_precision: 0.5548 - val_recall: 0.4538 - val_auc: 0.6702 - val_prc: 0.4890\n"
     ]
    }
   ],
   "source": [
    "# Deep learnig Model\n",
    "def nn_builder(text_vectorizer):\n",
    "    nn = Sequential()\n",
    "    nn.add(Input(shape=(1,), dtype=\"string\"))\n",
    "    nn.add(text_vectorizer)\n",
    "    nn.add(Dense(1500, activation=\"relu\"))\n",
    "    nn.add(Dense(500, activation=\"relu\"))\n",
    "    nn.add(Dropout(0.40))\n",
    "    nn.add(Dense(1, activation=\"sigmoid\"))\n",
    "    nn.compile(loss=experiment_parameters['loss'],\n",
    "               optimizer=experiment_parameters['optimizer'],\n",
    "               metrics=METRICS)\n",
    "    return nn\n",
    "\n",
    "\n",
    "deep_model = nn_builder(tfidf_vectorizer)\n",
    "\n",
    "history = deep_model.fit(X_train, y_train,\n",
    "                         experiment_parameters['batch_size'],\n",
    "                         experiment_parameters['epochs'],\n",
    "                         validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.768409</td>\n",
       "      <td>0.554795</td>\n",
       "      <td>0.713404</td>\n",
       "      <td>0.661602</td>\n",
       "      <td>0.701160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.832690</td>\n",
       "      <td>0.453782</td>\n",
       "      <td>0.713404</td>\n",
       "      <td>0.643236</td>\n",
       "      <td>0.713404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.799259</td>\n",
       "      <td>0.499230</td>\n",
       "      <td>0.713404</td>\n",
       "      <td>0.649244</td>\n",
       "      <td>0.704805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>777.000000</td>\n",
       "      <td>357.000000</td>\n",
       "      <td>0.713404</td>\n",
       "      <td>1134.000000</td>\n",
       "      <td>1134.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0           1  accuracy    macro avg  weighted avg\n",
       "precision    0.768409    0.554795  0.713404     0.661602      0.701160\n",
       "recall       0.832690    0.453782  0.713404     0.643236      0.713404\n",
       "f1-score     0.799259    0.499230  0.713404     0.649244      0.704805\n",
       "support    777.000000  357.000000  0.713404  1134.000000   1134.000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds = deep_model.predict(X_test)\n",
    "pd.DataFrame(classification_report(\n",
    "    y_test, np.where(test_preds >= 0.5, 1, 0), output_dict=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('hate-seepch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7304d3c1a35396b9e299acc644b89f0e56d4154029b20ed6ab08effb23ac070c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
