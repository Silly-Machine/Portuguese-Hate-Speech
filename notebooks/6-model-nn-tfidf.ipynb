{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unable warnings\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enable GPU processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MemoryInfo(free=828375040, total=6233522176)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numba import cuda \n",
    "cuda.get_current_device().reset()\n",
    "cuda.current_context().reset()\n",
    "cuda.current_context().get_memory_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # Restrict TensorFlow to only use the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "        K.clear_session()\n",
    "        K._get_available_gpus()\n",
    "    except RuntimeError as e:\n",
    "        # Visible devices must be set at program startup\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Directory adjustment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Back to main folder\n",
    "path = os.path.dirname(os.getcwd()) + \"/\"\n",
    "os.chdir(path)\n",
    "sys.path.append(path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETL\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Natural language processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from gensim import models\n",
    "import gensim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML preprocessing\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Deep learnig model\n",
    "#from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.pipeline import Pipeline\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Bidirectional\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Train  metrics\n",
    "METRICS = [\n",
    "    tf.keras.metrics.TruePositives(name='tp'),\n",
    "    tf.keras.metrics.FalsePositives(name='fp'),\n",
    "    tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "    tf.keras.metrics.FalseNegatives(name='fn'),\n",
    "    tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "    tf.keras.metrics.Precision(name='precision'),\n",
    "    tf.keras.metrics.Recall(name='recall'),\n",
    "    tf.keras.metrics.AUC(name='auc'),\n",
    "    tf.keras.metrics.AUC(name='prc', curve='PR'),  # precision-recall curve\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data\n",
    "df = pd.read_csv(\"data/corpus/augmented_corpus_fortuna.csv\")\n",
    "\n",
    "# Set target and features\n",
    "target = \"label\"\n",
    "features = \"text_nonstop\"\n",
    "count = f\"length_{features}\"\n",
    "pos = len(df.query('label==1'))\n",
    "neg = len(df.query('label==0'))\n",
    "\n",
    "\n",
    "# Break apart dataset\n",
    "X = df[features].values.astype(\"U\")\n",
    "y = df[target]\n",
    "\n",
    "# Split train abd test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Set k-fold criteria\n",
    "k_fold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Classes balancing\n",
    "longest_text = df[count].max()\n",
    "initial_bias = np.log([pos/neg])\n",
    "\n",
    "weight_for_0 = (1 / neg) * (len(df) / 2.0)\n",
    "weight_for_1 = (1 / pos) * (len(df) / 2.0)\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preset parameters\n",
    "experiment_parameters = {\"classifier\": \"LSTM\",\n",
    "                         \"class_weight\": class_weight,\n",
    "                         \"epochs\": 200,\n",
    "                         \"units\": 50,\n",
    "                         \"dropout\": 0.4,\n",
    "                         \"recurrent_dropout\": 0.2,\n",
    "                         \"kernel_initializer\": 'glorot_uniform',\n",
    "                         \"loss\": \"binary_crossentropy\",\n",
    "                         \"optimizer\": \"adamax\",\n",
    "                         \"batch_size\": 64}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import TextVectorization\n",
    "from keras.layers import Input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TextVectorization(max_tokens=1500, standardize=\"lower_and_strip_punctuation\",\n",
    "                                     split=\"whitespace\", output_mode=\"tf-idf\", ngrams=(1, 2))\n",
    "tfidf_vectorizer.adapt(X_train, batch_size=32)\n",
    "vocab = tfidf_vectorizer.get_vocabulary()\n",
    "out = tfidf_vectorizer(X_train[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "71/71 [==============================] - 2s 12ms/step - loss: 0.8860 - tp: 464.0000 - fp: 789.0000 - tn: 2318.0000 - fn: 965.0000 - accuracy: 0.6133 - precision: 0.3703 - recall: 0.3247 - auc: 0.5204 - prc: 0.3431 - val_loss: 0.5791 - val_tp: 91.0000 - val_fp: 57.0000 - val_tn: 720.0000 - val_fn: 266.0000 - val_accuracy: 0.7152 - val_precision: 0.6149 - val_recall: 0.2549 - val_auc: 0.6737 - val_prc: 0.5296\n",
      "Epoch 2/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.7021 - tp: 588.0000 - fp: 610.0000 - tn: 2497.0000 - fn: 841.0000 - accuracy: 0.6801 - precision: 0.4908 - recall: 0.4115 - auc: 0.6358 - prc: 0.4513 - val_loss: 0.5558 - val_tp: 130.0000 - val_fp: 67.0000 - val_tn: 710.0000 - val_fn: 227.0000 - val_accuracy: 0.7407 - val_precision: 0.6599 - val_recall: 0.3641 - val_auc: 0.7170 - val_prc: 0.5733\n",
      "Epoch 3/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.6070 - tp: 673.0000 - fp: 506.0000 - tn: 2601.0000 - fn: 756.0000 - accuracy: 0.7218 - precision: 0.5708 - recall: 0.4710 - auc: 0.7073 - prc: 0.5420 - val_loss: 0.5486 - val_tp: 130.0000 - val_fp: 60.0000 - val_tn: 717.0000 - val_fn: 227.0000 - val_accuracy: 0.7469 - val_precision: 0.6842 - val_recall: 0.3641 - val_auc: 0.7270 - val_prc: 0.5861\n",
      "Epoch 4/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.5436 - tp: 728.0000 - fp: 414.0000 - tn: 2693.0000 - fn: 701.0000 - accuracy: 0.7542 - precision: 0.6375 - recall: 0.5094 - auc: 0.7571 - prc: 0.6071 - val_loss: 0.5430 - val_tp: 146.0000 - val_fp: 73.0000 - val_tn: 704.0000 - val_fn: 211.0000 - val_accuracy: 0.7496 - val_precision: 0.6667 - val_recall: 0.4090 - val_auc: 0.7400 - val_prc: 0.5956\n",
      "Epoch 5/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.5123 - tp: 746.0000 - fp: 367.0000 - tn: 2740.0000 - fn: 683.0000 - accuracy: 0.7685 - precision: 0.6703 - recall: 0.5220 - auc: 0.7842 - prc: 0.6524 - val_loss: 0.5448 - val_tp: 161.0000 - val_fp: 91.0000 - val_tn: 686.0000 - val_fn: 196.0000 - val_accuracy: 0.7469 - val_precision: 0.6389 - val_recall: 0.4510 - val_auc: 0.7477 - val_prc: 0.5953\n",
      "Epoch 6/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.4701 - tp: 799.0000 - fp: 330.0000 - tn: 2777.0000 - fn: 630.0000 - accuracy: 0.7884 - precision: 0.7077 - recall: 0.5591 - auc: 0.8203 - prc: 0.7030 - val_loss: 0.5581 - val_tp: 129.0000 - val_fp: 52.0000 - val_tn: 725.0000 - val_fn: 228.0000 - val_accuracy: 0.7531 - val_precision: 0.7127 - val_recall: 0.3613 - val_auc: 0.7316 - val_prc: 0.5839\n",
      "Epoch 7/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.4576 - tp: 799.0000 - fp: 287.0000 - tn: 2820.0000 - fn: 630.0000 - accuracy: 0.7978 - precision: 0.7357 - recall: 0.5591 - auc: 0.8304 - prc: 0.7233 - val_loss: 0.5466 - val_tp: 156.0000 - val_fp: 84.0000 - val_tn: 693.0000 - val_fn: 201.0000 - val_accuracy: 0.7487 - val_precision: 0.6500 - val_recall: 0.4370 - val_auc: 0.7462 - val_prc: 0.5912\n",
      "Epoch 8/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.4218 - tp: 852.0000 - fp: 267.0000 - tn: 2840.0000 - fn: 577.0000 - accuracy: 0.8139 - precision: 0.7614 - recall: 0.5962 - auc: 0.8619 - prc: 0.7659 - val_loss: 0.5613 - val_tp: 192.0000 - val_fp: 135.0000 - val_tn: 642.0000 - val_fn: 165.0000 - val_accuracy: 0.7354 - val_precision: 0.5872 - val_recall: 0.5378 - val_auc: 0.7518 - val_prc: 0.5871\n",
      "Epoch 9/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.4006 - tp: 873.0000 - fp: 251.0000 - tn: 2856.0000 - fn: 556.0000 - accuracy: 0.8221 - precision: 0.7767 - recall: 0.6109 - auc: 0.8777 - prc: 0.7903 - val_loss: 0.5572 - val_tp: 178.0000 - val_fp: 115.0000 - val_tn: 662.0000 - val_fn: 179.0000 - val_accuracy: 0.7407 - val_precision: 0.6075 - val_recall: 0.4986 - val_auc: 0.7503 - val_prc: 0.5871\n",
      "Epoch 10/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.3827 - tp: 923.0000 - fp: 228.0000 - tn: 2879.0000 - fn: 506.0000 - accuracy: 0.8382 - precision: 0.8019 - recall: 0.6459 - auc: 0.8931 - prc: 0.8119 - val_loss: 0.5575 - val_tp: 164.0000 - val_fp: 82.0000 - val_tn: 695.0000 - val_fn: 193.0000 - val_accuracy: 0.7575 - val_precision: 0.6667 - val_recall: 0.4594 - val_auc: 0.7467 - val_prc: 0.5864\n",
      "Epoch 11/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.3687 - tp: 928.0000 - fp: 206.0000 - tn: 2901.0000 - fn: 501.0000 - accuracy: 0.8441 - precision: 0.8183 - recall: 0.6494 - auc: 0.9033 - prc: 0.8193 - val_loss: 0.5617 - val_tp: 171.0000 - val_fp: 100.0000 - val_tn: 677.0000 - val_fn: 186.0000 - val_accuracy: 0.7478 - val_precision: 0.6310 - val_recall: 0.4790 - val_auc: 0.7471 - val_prc: 0.5861\n",
      "Epoch 12/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.3484 - tp: 956.0000 - fp: 196.0000 - tn: 2911.0000 - fn: 473.0000 - accuracy: 0.8525 - precision: 0.8299 - recall: 0.6690 - auc: 0.9146 - prc: 0.8481 - val_loss: 0.5796 - val_tp: 140.0000 - val_fp: 62.0000 - val_tn: 715.0000 - val_fn: 217.0000 - val_accuracy: 0.7540 - val_precision: 0.6931 - val_recall: 0.3922 - val_auc: 0.7395 - val_prc: 0.5874\n",
      "Epoch 13/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.3395 - tp: 955.0000 - fp: 184.0000 - tn: 2923.0000 - fn: 474.0000 - accuracy: 0.8549 - precision: 0.8385 - recall: 0.6683 - auc: 0.9196 - prc: 0.8551 - val_loss: 0.5818 - val_tp: 187.0000 - val_fp: 145.0000 - val_tn: 632.0000 - val_fn: 170.0000 - val_accuracy: 0.7222 - val_precision: 0.5633 - val_recall: 0.5238 - val_auc: 0.7468 - val_prc: 0.5834\n",
      "Epoch 14/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.3217 - tp: 1019.0000 - fp: 185.0000 - tn: 2922.0000 - fn: 410.0000 - accuracy: 0.8688 - precision: 0.8463 - recall: 0.7131 - auc: 0.9313 - prc: 0.8701 - val_loss: 0.5780 - val_tp: 175.0000 - val_fp: 105.0000 - val_tn: 672.0000 - val_fn: 182.0000 - val_accuracy: 0.7469 - val_precision: 0.6250 - val_recall: 0.4902 - val_auc: 0.7453 - val_prc: 0.5884\n",
      "Epoch 15/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.3070 - tp: 1037.0000 - fp: 196.0000 - tn: 2911.0000 - fn: 392.0000 - accuracy: 0.8704 - precision: 0.8410 - recall: 0.7257 - auc: 0.9387 - prc: 0.8856 - val_loss: 0.5871 - val_tp: 169.0000 - val_fp: 100.0000 - val_tn: 677.0000 - val_fn: 188.0000 - val_accuracy: 0.7460 - val_precision: 0.6283 - val_recall: 0.4734 - val_auc: 0.7426 - val_prc: 0.5878\n",
      "Epoch 16/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.2978 - tp: 1027.0000 - fp: 158.0000 - tn: 2949.0000 - fn: 402.0000 - accuracy: 0.8765 - precision: 0.8667 - recall: 0.7187 - auc: 0.9426 - prc: 0.8933 - val_loss: 0.6041 - val_tp: 188.0000 - val_fp: 144.0000 - val_tn: 633.0000 - val_fn: 169.0000 - val_accuracy: 0.7240 - val_precision: 0.5663 - val_recall: 0.5266 - val_auc: 0.7419 - val_prc: 0.5750\n",
      "Epoch 17/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.2834 - tp: 1075.0000 - fp: 153.0000 - tn: 2954.0000 - fn: 354.0000 - accuracy: 0.8882 - precision: 0.8754 - recall: 0.7523 - auc: 0.9480 - prc: 0.9044 - val_loss: 0.6046 - val_tp: 185.0000 - val_fp: 136.0000 - val_tn: 641.0000 - val_fn: 172.0000 - val_accuracy: 0.7284 - val_precision: 0.5763 - val_recall: 0.5182 - val_auc: 0.7437 - val_prc: 0.5783\n",
      "Epoch 18/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.2718 - tp: 1098.0000 - fp: 151.0000 - tn: 2956.0000 - fn: 331.0000 - accuracy: 0.8937 - precision: 0.8791 - recall: 0.7684 - auc: 0.9531 - prc: 0.9147 - val_loss: 0.6167 - val_tp: 163.0000 - val_fp: 81.0000 - val_tn: 696.0000 - val_fn: 194.0000 - val_accuracy: 0.7575 - val_precision: 0.6680 - val_recall: 0.4566 - val_auc: 0.7381 - val_prc: 0.5810\n",
      "Epoch 19/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.2605 - tp: 1109.0000 - fp: 148.0000 - tn: 2959.0000 - fn: 320.0000 - accuracy: 0.8968 - precision: 0.8823 - recall: 0.7761 - auc: 0.9592 - prc: 0.9185 - val_loss: 0.6170 - val_tp: 170.0000 - val_fp: 97.0000 - val_tn: 680.0000 - val_fn: 187.0000 - val_accuracy: 0.7496 - val_precision: 0.6367 - val_recall: 0.4762 - val_auc: 0.7391 - val_prc: 0.5811\n",
      "Epoch 20/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.2453 - tp: 1130.0000 - fp: 131.0000 - tn: 2976.0000 - fn: 299.0000 - accuracy: 0.9052 - precision: 0.8961 - recall: 0.7908 - auc: 0.9644 - prc: 0.9321 - val_loss: 0.6296 - val_tp: 188.0000 - val_fp: 131.0000 - val_tn: 646.0000 - val_fn: 169.0000 - val_accuracy: 0.7354 - val_precision: 0.5893 - val_recall: 0.5266 - val_auc: 0.7394 - val_prc: 0.5745\n",
      "Epoch 21/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.2384 - tp: 1144.0000 - fp: 128.0000 - tn: 2979.0000 - fn: 285.0000 - accuracy: 0.9090 - precision: 0.8994 - recall: 0.8006 - auc: 0.9671 - prc: 0.9358 - val_loss: 0.6358 - val_tp: 182.0000 - val_fp: 120.0000 - val_tn: 657.0000 - val_fn: 175.0000 - val_accuracy: 0.7399 - val_precision: 0.6026 - val_recall: 0.5098 - val_auc: 0.7368 - val_prc: 0.5739\n",
      "Epoch 22/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.2283 - tp: 1159.0000 - fp: 127.0000 - tn: 2980.0000 - fn: 270.0000 - accuracy: 0.9125 - precision: 0.9012 - recall: 0.8111 - auc: 0.9706 - prc: 0.9443 - val_loss: 0.6452 - val_tp: 184.0000 - val_fp: 125.0000 - val_tn: 652.0000 - val_fn: 173.0000 - val_accuracy: 0.7372 - val_precision: 0.5955 - val_recall: 0.5154 - val_auc: 0.7369 - val_prc: 0.5714\n",
      "Epoch 23/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.2191 - tp: 1179.0000 - fp: 109.0000 - tn: 2998.0000 - fn: 250.0000 - accuracy: 0.9209 - precision: 0.9154 - recall: 0.8251 - auc: 0.9729 - prc: 0.9485 - val_loss: 0.6643 - val_tp: 197.0000 - val_fp: 149.0000 - val_tn: 628.0000 - val_fn: 160.0000 - val_accuracy: 0.7275 - val_precision: 0.5694 - val_recall: 0.5518 - val_auc: 0.7374 - val_prc: 0.5703\n",
      "Epoch 24/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.2102 - tp: 1192.0000 - fp: 105.0000 - tn: 3002.0000 - fn: 237.0000 - accuracy: 0.9246 - precision: 0.9190 - recall: 0.8341 - auc: 0.9754 - prc: 0.9525 - val_loss: 0.6653 - val_tp: 172.0000 - val_fp: 102.0000 - val_tn: 675.0000 - val_fn: 185.0000 - val_accuracy: 0.7469 - val_precision: 0.6277 - val_recall: 0.4818 - val_auc: 0.7346 - val_prc: 0.5765\n",
      "Epoch 25/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.1951 - tp: 1211.0000 - fp: 102.0000 - tn: 3005.0000 - fn: 218.0000 - accuracy: 0.9295 - precision: 0.9223 - recall: 0.8474 - auc: 0.9798 - prc: 0.9600 - val_loss: 0.6738 - val_tp: 171.0000 - val_fp: 103.0000 - val_tn: 674.0000 - val_fn: 186.0000 - val_accuracy: 0.7451 - val_precision: 0.6241 - val_recall: 0.4790 - val_auc: 0.7332 - val_prc: 0.5730\n",
      "Epoch 26/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.1880 - tp: 1224.0000 - fp: 92.0000 - tn: 3015.0000 - fn: 205.0000 - accuracy: 0.9345 - precision: 0.9301 - recall: 0.8565 - auc: 0.9816 - prc: 0.9645 - val_loss: 0.6843 - val_tp: 179.0000 - val_fp: 119.0000 - val_tn: 658.0000 - val_fn: 178.0000 - val_accuracy: 0.7381 - val_precision: 0.6007 - val_recall: 0.5014 - val_auc: 0.7330 - val_prc: 0.5705\n",
      "Epoch 27/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.1833 - tp: 1231.0000 - fp: 89.0000 - tn: 3018.0000 - fn: 198.0000 - accuracy: 0.9367 - precision: 0.9326 - recall: 0.8614 - auc: 0.9826 - prc: 0.9658 - val_loss: 0.6948 - val_tp: 179.0000 - val_fp: 121.0000 - val_tn: 656.0000 - val_fn: 178.0000 - val_accuracy: 0.7363 - val_precision: 0.5967 - val_recall: 0.5014 - val_auc: 0.7318 - val_prc: 0.5705\n",
      "Epoch 28/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.1776 - tp: 1227.0000 - fp: 86.0000 - tn: 3021.0000 - fn: 202.0000 - accuracy: 0.9365 - precision: 0.9345 - recall: 0.8586 - auc: 0.9838 - prc: 0.9683 - val_loss: 0.7051 - val_tp: 172.0000 - val_fp: 108.0000 - val_tn: 669.0000 - val_fn: 185.0000 - val_accuracy: 0.7416 - val_precision: 0.6143 - val_recall: 0.4818 - val_auc: 0.7307 - val_prc: 0.5721\n",
      "Epoch 29/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.1661 - tp: 1246.0000 - fp: 80.0000 - tn: 3027.0000 - fn: 183.0000 - accuracy: 0.9420 - precision: 0.9397 - recall: 0.8719 - auc: 0.9864 - prc: 0.9727 - val_loss: 0.7131 - val_tp: 181.0000 - val_fp: 130.0000 - val_tn: 647.0000 - val_fn: 176.0000 - val_accuracy: 0.7302 - val_precision: 0.5820 - val_recall: 0.5070 - val_auc: 0.7290 - val_prc: 0.5689\n",
      "Epoch 30/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.1596 - tp: 1265.0000 - fp: 80.0000 - tn: 3027.0000 - fn: 164.0000 - accuracy: 0.9462 - precision: 0.9405 - recall: 0.8852 - auc: 0.9871 - prc: 0.9740 - val_loss: 0.7255 - val_tp: 174.0000 - val_fp: 113.0000 - val_tn: 664.0000 - val_fn: 183.0000 - val_accuracy: 0.7390 - val_precision: 0.6063 - val_recall: 0.4874 - val_auc: 0.7283 - val_prc: 0.5736\n",
      "Epoch 31/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.1541 - tp: 1275.0000 - fp: 86.0000 - tn: 3021.0000 - fn: 154.0000 - accuracy: 0.9471 - precision: 0.9368 - recall: 0.8922 - auc: 0.9880 - prc: 0.9761 - val_loss: 0.7306 - val_tp: 178.0000 - val_fp: 120.0000 - val_tn: 657.0000 - val_fn: 179.0000 - val_accuracy: 0.7363 - val_precision: 0.5973 - val_recall: 0.4986 - val_auc: 0.7275 - val_prc: 0.5703\n",
      "Epoch 32/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.1479 - tp: 1291.0000 - fp: 86.0000 - tn: 3021.0000 - fn: 138.0000 - accuracy: 0.9506 - precision: 0.9375 - recall: 0.9034 - auc: 0.9893 - prc: 0.9792 - val_loss: 0.7486 - val_tp: 176.0000 - val_fp: 118.0000 - val_tn: 659.0000 - val_fn: 181.0000 - val_accuracy: 0.7363 - val_precision: 0.5986 - val_recall: 0.4930 - val_auc: 0.7250 - val_prc: 0.5699\n",
      "Epoch 33/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.1408 - tp: 1294.0000 - fp: 64.0000 - tn: 3043.0000 - fn: 135.0000 - accuracy: 0.9561 - precision: 0.9529 - recall: 0.9055 - auc: 0.9901 - prc: 0.9805 - val_loss: 0.7636 - val_tp: 186.0000 - val_fp: 136.0000 - val_tn: 641.0000 - val_fn: 171.0000 - val_accuracy: 0.7293 - val_precision: 0.5776 - val_recall: 0.5210 - val_auc: 0.7260 - val_prc: 0.5607\n",
      "Epoch 34/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.1369 - tp: 1291.0000 - fp: 67.0000 - tn: 3040.0000 - fn: 138.0000 - accuracy: 0.9548 - precision: 0.9507 - recall: 0.9034 - auc: 0.9909 - prc: 0.9820 - val_loss: 0.7729 - val_tp: 173.0000 - val_fp: 112.0000 - val_tn: 665.0000 - val_fn: 184.0000 - val_accuracy: 0.7390 - val_precision: 0.6070 - val_recall: 0.4846 - val_auc: 0.7250 - val_prc: 0.5683\n",
      "Epoch 35/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.1283 - tp: 1300.0000 - fp: 68.0000 - tn: 3039.0000 - fn: 129.0000 - accuracy: 0.9566 - precision: 0.9503 - recall: 0.9097 - auc: 0.9925 - prc: 0.9852 - val_loss: 0.7881 - val_tp: 175.0000 - val_fp: 115.0000 - val_tn: 662.0000 - val_fn: 182.0000 - val_accuracy: 0.7381 - val_precision: 0.6034 - val_recall: 0.4902 - val_auc: 0.7224 - val_prc: 0.5621\n",
      "Epoch 36/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.1239 - tp: 1321.0000 - fp: 56.0000 - tn: 3051.0000 - fn: 108.0000 - accuracy: 0.9638 - precision: 0.9593 - recall: 0.9244 - auc: 0.9924 - prc: 0.9851 - val_loss: 0.8099 - val_tp: 199.0000 - val_fp: 178.0000 - val_tn: 599.0000 - val_fn: 158.0000 - val_accuracy: 0.7037 - val_precision: 0.5279 - val_recall: 0.5574 - val_auc: 0.7237 - val_prc: 0.5563\n",
      "Epoch 37/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.1219 - tp: 1308.0000 - fp: 59.0000 - tn: 3048.0000 - fn: 121.0000 - accuracy: 0.9603 - precision: 0.9568 - recall: 0.9153 - auc: 0.9929 - prc: 0.9853 - val_loss: 0.8035 - val_tp: 181.0000 - val_fp: 134.0000 - val_tn: 643.0000 - val_fn: 176.0000 - val_accuracy: 0.7266 - val_precision: 0.5746 - val_recall: 0.5070 - val_auc: 0.7232 - val_prc: 0.5588\n",
      "Epoch 38/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.1168 - tp: 1320.0000 - fp: 55.0000 - tn: 3052.0000 - fn: 109.0000 - accuracy: 0.9638 - precision: 0.9600 - recall: 0.9237 - auc: 0.9935 - prc: 0.9868 - val_loss: 0.8177 - val_tp: 180.0000 - val_fp: 128.0000 - val_tn: 649.0000 - val_fn: 177.0000 - val_accuracy: 0.7310 - val_precision: 0.5844 - val_recall: 0.5042 - val_auc: 0.7220 - val_prc: 0.5597\n",
      "Epoch 39/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.1102 - tp: 1330.0000 - fp: 58.0000 - tn: 3049.0000 - fn: 99.0000 - accuracy: 0.9654 - precision: 0.9582 - recall: 0.9307 - auc: 0.9945 - prc: 0.9884 - val_loss: 0.8322 - val_tp: 178.0000 - val_fp: 132.0000 - val_tn: 645.0000 - val_fn: 179.0000 - val_accuracy: 0.7257 - val_precision: 0.5742 - val_recall: 0.4986 - val_auc: 0.7222 - val_prc: 0.5590\n",
      "Epoch 40/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.1054 - tp: 1334.0000 - fp: 50.0000 - tn: 3057.0000 - fn: 95.0000 - accuracy: 0.9680 - precision: 0.9639 - recall: 0.9335 - auc: 0.9948 - prc: 0.9893 - val_loss: 0.8486 - val_tp: 174.0000 - val_fp: 117.0000 - val_tn: 660.0000 - val_fn: 183.0000 - val_accuracy: 0.7354 - val_precision: 0.5979 - val_recall: 0.4874 - val_auc: 0.7224 - val_prc: 0.5585\n",
      "Epoch 41/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.1012 - tp: 1339.0000 - fp: 45.0000 - tn: 3062.0000 - fn: 90.0000 - accuracy: 0.9702 - precision: 0.9675 - recall: 0.9370 - auc: 0.9953 - prc: 0.9905 - val_loss: 0.8635 - val_tp: 192.0000 - val_fp: 170.0000 - val_tn: 607.0000 - val_fn: 165.0000 - val_accuracy: 0.7046 - val_precision: 0.5304 - val_recall: 0.5378 - val_auc: 0.7203 - val_prc: 0.5525\n",
      "Epoch 42/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.1006 - tp: 1336.0000 - fp: 66.0000 - tn: 3041.0000 - fn: 93.0000 - accuracy: 0.9649 - precision: 0.9529 - recall: 0.9349 - auc: 0.9954 - prc: 0.9907 - val_loss: 0.8599 - val_tp: 177.0000 - val_fp: 130.0000 - val_tn: 647.0000 - val_fn: 180.0000 - val_accuracy: 0.7266 - val_precision: 0.5765 - val_recall: 0.4958 - val_auc: 0.7214 - val_prc: 0.5579\n",
      "Epoch 43/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0961 - tp: 1348.0000 - fp: 45.0000 - tn: 3062.0000 - fn: 81.0000 - accuracy: 0.9722 - precision: 0.9677 - recall: 0.9433 - auc: 0.9955 - prc: 0.9906 - val_loss: 0.8739 - val_tp: 179.0000 - val_fp: 135.0000 - val_tn: 642.0000 - val_fn: 178.0000 - val_accuracy: 0.7240 - val_precision: 0.5701 - val_recall: 0.5014 - val_auc: 0.7205 - val_prc: 0.5542\n",
      "Epoch 44/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0948 - tp: 1347.0000 - fp: 47.0000 - tn: 3060.0000 - fn: 82.0000 - accuracy: 0.9716 - precision: 0.9663 - recall: 0.9426 - auc: 0.9958 - prc: 0.9914 - val_loss: 0.9100 - val_tp: 158.0000 - val_fp: 97.0000 - val_tn: 680.0000 - val_fn: 199.0000 - val_accuracy: 0.7390 - val_precision: 0.6196 - val_recall: 0.4426 - val_auc: 0.7207 - val_prc: 0.5630\n",
      "Epoch 45/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0915 - tp: 1349.0000 - fp: 48.0000 - tn: 3059.0000 - fn: 80.0000 - accuracy: 0.9718 - precision: 0.9656 - recall: 0.9440 - auc: 0.9959 - prc: 0.9916 - val_loss: 0.8942 - val_tp: 182.0000 - val_fp: 135.0000 - val_tn: 642.0000 - val_fn: 175.0000 - val_accuracy: 0.7266 - val_precision: 0.5741 - val_recall: 0.5098 - val_auc: 0.7197 - val_prc: 0.5560\n",
      "Epoch 46/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0852 - tp: 1350.0000 - fp: 43.0000 - tn: 3064.0000 - fn: 79.0000 - accuracy: 0.9731 - precision: 0.9691 - recall: 0.9447 - auc: 0.9966 - prc: 0.9931 - val_loss: 0.9067 - val_tp: 173.0000 - val_fp: 133.0000 - val_tn: 644.0000 - val_fn: 184.0000 - val_accuracy: 0.7205 - val_precision: 0.5654 - val_recall: 0.4846 - val_auc: 0.7191 - val_prc: 0.5542\n",
      "Epoch 47/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0810 - tp: 1361.0000 - fp: 38.0000 - tn: 3069.0000 - fn: 68.0000 - accuracy: 0.9766 - precision: 0.9728 - recall: 0.9524 - auc: 0.9970 - prc: 0.9941 - val_loss: 0.9257 - val_tp: 173.0000 - val_fp: 118.0000 - val_tn: 659.0000 - val_fn: 184.0000 - val_accuracy: 0.7337 - val_precision: 0.5945 - val_recall: 0.4846 - val_auc: 0.7195 - val_prc: 0.5595\n",
      "Epoch 48/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0817 - tp: 1359.0000 - fp: 40.0000 - tn: 3067.0000 - fn: 70.0000 - accuracy: 0.9757 - precision: 0.9714 - recall: 0.9510 - auc: 0.9968 - prc: 0.9934 - val_loss: 0.9336 - val_tp: 173.0000 - val_fp: 123.0000 - val_tn: 654.0000 - val_fn: 184.0000 - val_accuracy: 0.7293 - val_precision: 0.5845 - val_recall: 0.4846 - val_auc: 0.7190 - val_prc: 0.5550\n",
      "Epoch 49/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0815 - tp: 1358.0000 - fp: 41.0000 - tn: 3066.0000 - fn: 71.0000 - accuracy: 0.9753 - precision: 0.9707 - recall: 0.9503 - auc: 0.9965 - prc: 0.9931 - val_loss: 0.9353 - val_tp: 184.0000 - val_fp: 147.0000 - val_tn: 630.0000 - val_fn: 173.0000 - val_accuracy: 0.7178 - val_precision: 0.5559 - val_recall: 0.5154 - val_auc: 0.7200 - val_prc: 0.5530\n",
      "Epoch 50/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0768 - tp: 1365.0000 - fp: 39.0000 - tn: 3068.0000 - fn: 64.0000 - accuracy: 0.9773 - precision: 0.9722 - recall: 0.9552 - auc: 0.9972 - prc: 0.9943 - val_loss: 0.9538 - val_tp: 174.0000 - val_fp: 134.0000 - val_tn: 643.0000 - val_fn: 183.0000 - val_accuracy: 0.7205 - val_precision: 0.5649 - val_recall: 0.4874 - val_auc: 0.7184 - val_prc: 0.5522\n",
      "Epoch 51/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0762 - tp: 1368.0000 - fp: 37.0000 - tn: 3070.0000 - fn: 61.0000 - accuracy: 0.9784 - precision: 0.9737 - recall: 0.9573 - auc: 0.9972 - prc: 0.9942 - val_loss: 0.9632 - val_tp: 179.0000 - val_fp: 136.0000 - val_tn: 641.0000 - val_fn: 178.0000 - val_accuracy: 0.7231 - val_precision: 0.5683 - val_recall: 0.5014 - val_auc: 0.7184 - val_prc: 0.5511\n",
      "Epoch 52/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0712 - tp: 1364.0000 - fp: 35.0000 - tn: 3072.0000 - fn: 65.0000 - accuracy: 0.9780 - precision: 0.9750 - recall: 0.9545 - auc: 0.9978 - prc: 0.9954 - val_loss: 0.9780 - val_tp: 189.0000 - val_fp: 166.0000 - val_tn: 611.0000 - val_fn: 168.0000 - val_accuracy: 0.7055 - val_precision: 0.5324 - val_recall: 0.5294 - val_auc: 0.7175 - val_prc: 0.5487\n",
      "Epoch 53/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0742 - tp: 1360.0000 - fp: 38.0000 - tn: 3069.0000 - fn: 69.0000 - accuracy: 0.9764 - precision: 0.9728 - recall: 0.9517 - auc: 0.9972 - prc: 0.9945 - val_loss: 0.9836 - val_tp: 175.0000 - val_fp: 138.0000 - val_tn: 639.0000 - val_fn: 182.0000 - val_accuracy: 0.7178 - val_precision: 0.5591 - val_recall: 0.4902 - val_auc: 0.7170 - val_prc: 0.5517\n",
      "Epoch 54/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0674 - tp: 1367.0000 - fp: 40.0000 - tn: 3067.0000 - fn: 62.0000 - accuracy: 0.9775 - precision: 0.9716 - recall: 0.9566 - auc: 0.9980 - prc: 0.9958 - val_loss: 0.9978 - val_tp: 175.0000 - val_fp: 134.0000 - val_tn: 643.0000 - val_fn: 182.0000 - val_accuracy: 0.7213 - val_precision: 0.5663 - val_recall: 0.4902 - val_auc: 0.7179 - val_prc: 0.5497\n",
      "Epoch 55/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0693 - tp: 1361.0000 - fp: 33.0000 - tn: 3074.0000 - fn: 68.0000 - accuracy: 0.9777 - precision: 0.9763 - recall: 0.9524 - auc: 0.9976 - prc: 0.9952 - val_loss: 0.9973 - val_tp: 184.0000 - val_fp: 169.0000 - val_tn: 608.0000 - val_fn: 173.0000 - val_accuracy: 0.6984 - val_precision: 0.5212 - val_recall: 0.5154 - val_auc: 0.7164 - val_prc: 0.5479\n",
      "Epoch 56/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0665 - tp: 1368.0000 - fp: 36.0000 - tn: 3071.0000 - fn: 61.0000 - accuracy: 0.9786 - precision: 0.9744 - recall: 0.9573 - auc: 0.9979 - prc: 0.9956 - val_loss: 1.0160 - val_tp: 176.0000 - val_fp: 143.0000 - val_tn: 634.0000 - val_fn: 181.0000 - val_accuracy: 0.7143 - val_precision: 0.5517 - val_recall: 0.4930 - val_auc: 0.7158 - val_prc: 0.5471\n",
      "Epoch 57/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0630 - tp: 1367.0000 - fp: 30.0000 - tn: 3077.0000 - fn: 62.0000 - accuracy: 0.9797 - precision: 0.9785 - recall: 0.9566 - auc: 0.9981 - prc: 0.9961 - val_loss: 1.0369 - val_tp: 166.0000 - val_fp: 117.0000 - val_tn: 660.0000 - val_fn: 191.0000 - val_accuracy: 0.7284 - val_precision: 0.5866 - val_recall: 0.4650 - val_auc: 0.7127 - val_prc: 0.5444\n",
      "Epoch 58/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0627 - tp: 1378.0000 - fp: 37.0000 - tn: 3070.0000 - fn: 51.0000 - accuracy: 0.9806 - precision: 0.9739 - recall: 0.9643 - auc: 0.9981 - prc: 0.9961 - val_loss: 1.0374 - val_tp: 180.0000 - val_fp: 150.0000 - val_tn: 627.0000 - val_fn: 177.0000 - val_accuracy: 0.7116 - val_precision: 0.5455 - val_recall: 0.5042 - val_auc: 0.7153 - val_prc: 0.5473\n",
      "Epoch 59/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0626 - tp: 1375.0000 - fp: 37.0000 - tn: 3070.0000 - fn: 54.0000 - accuracy: 0.9799 - precision: 0.9738 - recall: 0.9622 - auc: 0.9981 - prc: 0.9961 - val_loss: 1.0653 - val_tp: 163.0000 - val_fp: 107.0000 - val_tn: 670.0000 - val_fn: 194.0000 - val_accuracy: 0.7346 - val_precision: 0.6037 - val_recall: 0.4566 - val_auc: 0.7122 - val_prc: 0.5468\n",
      "Epoch 60/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0622 - tp: 1369.0000 - fp: 34.0000 - tn: 3073.0000 - fn: 60.0000 - accuracy: 0.9793 - precision: 0.9758 - recall: 0.9580 - auc: 0.9982 - prc: 0.9962 - val_loss: 1.0700 - val_tp: 161.0000 - val_fp: 111.0000 - val_tn: 666.0000 - val_fn: 196.0000 - val_accuracy: 0.7293 - val_precision: 0.5919 - val_recall: 0.4510 - val_auc: 0.7107 - val_prc: 0.5451\n",
      "Epoch 61/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0564 - tp: 1371.0000 - fp: 23.0000 - tn: 3084.0000 - fn: 58.0000 - accuracy: 0.9821 - precision: 0.9835 - recall: 0.9594 - auc: 0.9986 - prc: 0.9970 - val_loss: 1.0745 - val_tp: 173.0000 - val_fp: 129.0000 - val_tn: 648.0000 - val_fn: 184.0000 - val_accuracy: 0.7240 - val_precision: 0.5728 - val_recall: 0.4846 - val_auc: 0.7132 - val_prc: 0.5436\n",
      "Epoch 62/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0567 - tp: 1377.0000 - fp: 25.0000 - tn: 3082.0000 - fn: 52.0000 - accuracy: 0.9830 - precision: 0.9822 - recall: 0.9636 - auc: 0.9985 - prc: 0.9969 - val_loss: 1.0781 - val_tp: 173.0000 - val_fp: 126.0000 - val_tn: 651.0000 - val_fn: 184.0000 - val_accuracy: 0.7266 - val_precision: 0.5786 - val_recall: 0.4846 - val_auc: 0.7124 - val_prc: 0.5433\n",
      "Epoch 63/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0570 - tp: 1377.0000 - fp: 31.0000 - tn: 3076.0000 - fn: 52.0000 - accuracy: 0.9817 - precision: 0.9780 - recall: 0.9636 - auc: 0.9982 - prc: 0.9963 - val_loss: 1.0987 - val_tp: 162.0000 - val_fp: 113.0000 - val_tn: 664.0000 - val_fn: 195.0000 - val_accuracy: 0.7284 - val_precision: 0.5891 - val_recall: 0.4538 - val_auc: 0.7109 - val_prc: 0.5436\n",
      "Epoch 64/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0561 - tp: 1376.0000 - fp: 33.0000 - tn: 3074.0000 - fn: 53.0000 - accuracy: 0.9810 - precision: 0.9766 - recall: 0.9629 - auc: 0.9984 - prc: 0.9968 - val_loss: 1.1027 - val_tp: 168.0000 - val_fp: 128.0000 - val_tn: 649.0000 - val_fn: 189.0000 - val_accuracy: 0.7205 - val_precision: 0.5676 - val_recall: 0.4706 - val_auc: 0.7101 - val_prc: 0.5431\n",
      "Epoch 65/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0547 - tp: 1377.0000 - fp: 34.0000 - tn: 3073.0000 - fn: 52.0000 - accuracy: 0.9810 - precision: 0.9759 - recall: 0.9636 - auc: 0.9986 - prc: 0.9971 - val_loss: 1.1280 - val_tp: 166.0000 - val_fp: 119.0000 - val_tn: 658.0000 - val_fn: 191.0000 - val_accuracy: 0.7266 - val_precision: 0.5825 - val_recall: 0.4650 - val_auc: 0.7104 - val_prc: 0.5402\n",
      "Epoch 66/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0518 - tp: 1374.0000 - fp: 28.0000 - tn: 3079.0000 - fn: 55.0000 - accuracy: 0.9817 - precision: 0.9800 - recall: 0.9615 - auc: 0.9987 - prc: 0.9973 - val_loss: 1.1205 - val_tp: 169.0000 - val_fp: 135.0000 - val_tn: 642.0000 - val_fn: 188.0000 - val_accuracy: 0.7152 - val_precision: 0.5559 - val_recall: 0.4734 - val_auc: 0.7102 - val_prc: 0.5408\n",
      "Epoch 67/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0528 - tp: 1374.0000 - fp: 29.0000 - tn: 3078.0000 - fn: 55.0000 - accuracy: 0.9815 - precision: 0.9793 - recall: 0.9615 - auc: 0.9986 - prc: 0.9971 - val_loss: 1.1241 - val_tp: 174.0000 - val_fp: 138.0000 - val_tn: 639.0000 - val_fn: 183.0000 - val_accuracy: 0.7169 - val_precision: 0.5577 - val_recall: 0.4874 - val_auc: 0.7115 - val_prc: 0.5432\n",
      "Epoch 68/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0527 - tp: 1373.0000 - fp: 32.0000 - tn: 3075.0000 - fn: 56.0000 - accuracy: 0.9806 - precision: 0.9772 - recall: 0.9608 - auc: 0.9986 - prc: 0.9971 - val_loss: 1.1285 - val_tp: 175.0000 - val_fp: 153.0000 - val_tn: 624.0000 - val_fn: 182.0000 - val_accuracy: 0.7046 - val_precision: 0.5335 - val_recall: 0.4902 - val_auc: 0.7111 - val_prc: 0.5422\n",
      "Epoch 69/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0547 - tp: 1373.0000 - fp: 33.0000 - tn: 3074.0000 - fn: 56.0000 - accuracy: 0.9804 - precision: 0.9765 - recall: 0.9608 - auc: 0.9984 - prc: 0.9967 - val_loss: 1.1463 - val_tp: 171.0000 - val_fp: 149.0000 - val_tn: 628.0000 - val_fn: 186.0000 - val_accuracy: 0.7046 - val_precision: 0.5344 - val_recall: 0.4790 - val_auc: 0.7078 - val_prc: 0.5415\n",
      "Epoch 70/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0494 - tp: 1381.0000 - fp: 24.0000 - tn: 3083.0000 - fn: 48.0000 - accuracy: 0.9841 - precision: 0.9829 - recall: 0.9664 - auc: 0.9989 - prc: 0.9977 - val_loss: 1.1699 - val_tp: 167.0000 - val_fp: 119.0000 - val_tn: 658.0000 - val_fn: 190.0000 - val_accuracy: 0.7275 - val_precision: 0.5839 - val_recall: 0.4678 - val_auc: 0.7074 - val_prc: 0.5399\n",
      "Epoch 71/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0490 - tp: 1378.0000 - fp: 25.0000 - tn: 3082.0000 - fn: 51.0000 - accuracy: 0.9832 - precision: 0.9822 - recall: 0.9643 - auc: 0.9988 - prc: 0.9975 - val_loss: 1.1720 - val_tp: 170.0000 - val_fp: 138.0000 - val_tn: 639.0000 - val_fn: 187.0000 - val_accuracy: 0.7134 - val_precision: 0.5519 - val_recall: 0.4762 - val_auc: 0.7069 - val_prc: 0.5387\n",
      "Epoch 72/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0484 - tp: 1381.0000 - fp: 30.0000 - tn: 3077.0000 - fn: 48.0000 - accuracy: 0.9828 - precision: 0.9787 - recall: 0.9664 - auc: 0.9988 - prc: 0.9975 - val_loss: 1.1770 - val_tp: 174.0000 - val_fp: 155.0000 - val_tn: 622.0000 - val_fn: 183.0000 - val_accuracy: 0.7019 - val_precision: 0.5289 - val_recall: 0.4874 - val_auc: 0.7072 - val_prc: 0.5392\n",
      "Epoch 73/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0468 - tp: 1385.0000 - fp: 28.0000 - tn: 3079.0000 - fn: 44.0000 - accuracy: 0.9841 - precision: 0.9802 - recall: 0.9692 - auc: 0.9989 - prc: 0.9978 - val_loss: 1.2002 - val_tp: 166.0000 - val_fp: 122.0000 - val_tn: 655.0000 - val_fn: 191.0000 - val_accuracy: 0.7240 - val_precision: 0.5764 - val_recall: 0.4650 - val_auc: 0.7043 - val_prc: 0.5351\n",
      "Epoch 74/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0466 - tp: 1379.0000 - fp: 27.0000 - tn: 3080.0000 - fn: 50.0000 - accuracy: 0.9830 - precision: 0.9808 - recall: 0.9650 - auc: 0.9990 - prc: 0.9979 - val_loss: 1.1987 - val_tp: 168.0000 - val_fp: 131.0000 - val_tn: 646.0000 - val_fn: 189.0000 - val_accuracy: 0.7178 - val_precision: 0.5619 - val_recall: 0.4706 - val_auc: 0.7068 - val_prc: 0.5376\n",
      "Epoch 75/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0464 - tp: 1380.0000 - fp: 28.0000 - tn: 3079.0000 - fn: 49.0000 - accuracy: 0.9830 - precision: 0.9801 - recall: 0.9657 - auc: 0.9989 - prc: 0.9977 - val_loss: 1.2285 - val_tp: 161.0000 - val_fp: 115.0000 - val_tn: 662.0000 - val_fn: 196.0000 - val_accuracy: 0.7257 - val_precision: 0.5833 - val_recall: 0.4510 - val_auc: 0.7050 - val_prc: 0.5357\n",
      "Epoch 76/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0444 - tp: 1382.0000 - fp: 20.0000 - tn: 3087.0000 - fn: 47.0000 - accuracy: 0.9852 - precision: 0.9857 - recall: 0.9671 - auc: 0.9990 - prc: 0.9979 - val_loss: 1.2143 - val_tp: 168.0000 - val_fp: 130.0000 - val_tn: 647.0000 - val_fn: 189.0000 - val_accuracy: 0.7187 - val_precision: 0.5638 - val_recall: 0.4706 - val_auc: 0.7074 - val_prc: 0.5388\n",
      "Epoch 77/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0463 - tp: 1382.0000 - fp: 29.0000 - tn: 3078.0000 - fn: 47.0000 - accuracy: 0.9832 - precision: 0.9794 - recall: 0.9671 - auc: 0.9988 - prc: 0.9976 - val_loss: 1.2281 - val_tp: 166.0000 - val_fp: 118.0000 - val_tn: 659.0000 - val_fn: 191.0000 - val_accuracy: 0.7275 - val_precision: 0.5845 - val_recall: 0.4650 - val_auc: 0.7039 - val_prc: 0.5346\n",
      "Epoch 78/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0439 - tp: 1382.0000 - fp: 30.0000 - tn: 3077.0000 - fn: 47.0000 - accuracy: 0.9830 - precision: 0.9788 - recall: 0.9671 - auc: 0.9990 - prc: 0.9980 - val_loss: 1.2279 - val_tp: 168.0000 - val_fp: 129.0000 - val_tn: 648.0000 - val_fn: 189.0000 - val_accuracy: 0.7196 - val_precision: 0.5657 - val_recall: 0.4706 - val_auc: 0.7045 - val_prc: 0.5370\n",
      "Epoch 79/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0419 - tp: 1385.0000 - fp: 22.0000 - tn: 3085.0000 - fn: 44.0000 - accuracy: 0.9854 - precision: 0.9844 - recall: 0.9692 - auc: 0.9991 - prc: 0.9981 - val_loss: 1.2521 - val_tp: 174.0000 - val_fp: 161.0000 - val_tn: 616.0000 - val_fn: 183.0000 - val_accuracy: 0.6966 - val_precision: 0.5194 - val_recall: 0.4874 - val_auc: 0.7073 - val_prc: 0.5372\n",
      "Epoch 80/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0450 - tp: 1381.0000 - fp: 27.0000 - tn: 3080.0000 - fn: 48.0000 - accuracy: 0.9835 - precision: 0.9808 - recall: 0.9664 - auc: 0.9989 - prc: 0.9976 - val_loss: 1.2489 - val_tp: 172.0000 - val_fp: 152.0000 - val_tn: 625.0000 - val_fn: 185.0000 - val_accuracy: 0.7028 - val_precision: 0.5309 - val_recall: 0.4818 - val_auc: 0.7062 - val_prc: 0.5363\n",
      "Epoch 81/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0446 - tp: 1386.0000 - fp: 30.0000 - tn: 3077.0000 - fn: 43.0000 - accuracy: 0.9839 - precision: 0.9788 - recall: 0.9699 - auc: 0.9989 - prc: 0.9978 - val_loss: 1.2845 - val_tp: 160.0000 - val_fp: 108.0000 - val_tn: 669.0000 - val_fn: 197.0000 - val_accuracy: 0.7310 - val_precision: 0.5970 - val_recall: 0.4482 - val_auc: 0.7016 - val_prc: 0.5344\n",
      "Epoch 82/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0405 - tp: 1380.0000 - fp: 25.0000 - tn: 3082.0000 - fn: 49.0000 - accuracy: 0.9837 - precision: 0.9822 - recall: 0.9657 - auc: 0.9992 - prc: 0.9983 - val_loss: 1.2645 - val_tp: 168.0000 - val_fp: 137.0000 - val_tn: 640.0000 - val_fn: 189.0000 - val_accuracy: 0.7125 - val_precision: 0.5508 - val_recall: 0.4706 - val_auc: 0.7041 - val_prc: 0.5358\n",
      "Epoch 83/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0415 - tp: 1387.0000 - fp: 24.0000 - tn: 3083.0000 - fn: 42.0000 - accuracy: 0.9854 - precision: 0.9830 - recall: 0.9706 - auc: 0.9991 - prc: 0.9981 - val_loss: 1.2919 - val_tp: 164.0000 - val_fp: 124.0000 - val_tn: 653.0000 - val_fn: 193.0000 - val_accuracy: 0.7205 - val_precision: 0.5694 - val_recall: 0.4594 - val_auc: 0.7030 - val_prc: 0.5359\n",
      "Epoch 84/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0435 - tp: 1380.0000 - fp: 33.0000 - tn: 3074.0000 - fn: 49.0000 - accuracy: 0.9819 - precision: 0.9766 - recall: 0.9657 - auc: 0.9990 - prc: 0.9979 - val_loss: 1.2764 - val_tp: 173.0000 - val_fp: 151.0000 - val_tn: 626.0000 - val_fn: 184.0000 - val_accuracy: 0.7046 - val_precision: 0.5340 - val_recall: 0.4846 - val_auc: 0.7025 - val_prc: 0.5340\n",
      "Epoch 85/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0436 - tp: 1383.0000 - fp: 24.0000 - tn: 3083.0000 - fn: 46.0000 - accuracy: 0.9846 - precision: 0.9829 - recall: 0.9678 - auc: 0.9988 - prc: 0.9976 - val_loss: 1.2851 - val_tp: 167.0000 - val_fp: 142.0000 - val_tn: 635.0000 - val_fn: 190.0000 - val_accuracy: 0.7072 - val_precision: 0.5405 - val_recall: 0.4678 - val_auc: 0.7016 - val_prc: 0.5344\n",
      "Epoch 86/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0411 - tp: 1382.0000 - fp: 27.0000 - tn: 3080.0000 - fn: 47.0000 - accuracy: 0.9837 - precision: 0.9808 - recall: 0.9671 - auc: 0.9991 - prc: 0.9980 - val_loss: 1.2978 - val_tp: 164.0000 - val_fp: 124.0000 - val_tn: 653.0000 - val_fn: 193.0000 - val_accuracy: 0.7205 - val_precision: 0.5694 - val_recall: 0.4594 - val_auc: 0.7018 - val_prc: 0.5317\n",
      "Epoch 87/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0398 - tp: 1387.0000 - fp: 22.0000 - tn: 3085.0000 - fn: 42.0000 - accuracy: 0.9859 - precision: 0.9844 - recall: 0.9706 - auc: 0.9992 - prc: 0.9983 - val_loss: 1.3271 - val_tp: 157.0000 - val_fp: 114.0000 - val_tn: 663.0000 - val_fn: 200.0000 - val_accuracy: 0.7231 - val_precision: 0.5793 - val_recall: 0.4398 - val_auc: 0.7018 - val_prc: 0.5308\n",
      "Epoch 88/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0396 - tp: 1386.0000 - fp: 25.0000 - tn: 3082.0000 - fn: 43.0000 - accuracy: 0.9850 - precision: 0.9823 - recall: 0.9699 - auc: 0.9992 - prc: 0.9983 - val_loss: 1.3156 - val_tp: 172.0000 - val_fp: 149.0000 - val_tn: 628.0000 - val_fn: 185.0000 - val_accuracy: 0.7055 - val_precision: 0.5358 - val_recall: 0.4818 - val_auc: 0.7002 - val_prc: 0.5301\n",
      "Epoch 89/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0418 - tp: 1383.0000 - fp: 28.0000 - tn: 3079.0000 - fn: 46.0000 - accuracy: 0.9837 - precision: 0.9802 - recall: 0.9678 - auc: 0.9990 - prc: 0.9980 - val_loss: 1.3166 - val_tp: 174.0000 - val_fp: 150.0000 - val_tn: 627.0000 - val_fn: 183.0000 - val_accuracy: 0.7063 - val_precision: 0.5370 - val_recall: 0.4874 - val_auc: 0.7023 - val_prc: 0.5317\n",
      "Epoch 90/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0389 - tp: 1385.0000 - fp: 20.0000 - tn: 3087.0000 - fn: 44.0000 - accuracy: 0.9859 - precision: 0.9858 - recall: 0.9692 - auc: 0.9992 - prc: 0.9983 - val_loss: 1.3353 - val_tp: 188.0000 - val_fp: 183.0000 - val_tn: 594.0000 - val_fn: 169.0000 - val_accuracy: 0.6896 - val_precision: 0.5067 - val_recall: 0.5266 - val_auc: 0.7021 - val_prc: 0.5263\n",
      "Epoch 91/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0405 - tp: 1388.0000 - fp: 27.0000 - tn: 3080.0000 - fn: 41.0000 - accuracy: 0.9850 - precision: 0.9809 - recall: 0.9713 - auc: 0.9991 - prc: 0.9980 - val_loss: 1.3529 - val_tp: 157.0000 - val_fp: 113.0000 - val_tn: 664.0000 - val_fn: 200.0000 - val_accuracy: 0.7240 - val_precision: 0.5815 - val_recall: 0.4398 - val_auc: 0.6998 - val_prc: 0.5321\n",
      "Epoch 92/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0378 - tp: 1385.0000 - fp: 23.0000 - tn: 3084.0000 - fn: 44.0000 - accuracy: 0.9852 - precision: 0.9837 - recall: 0.9692 - auc: 0.9992 - prc: 0.9982 - val_loss: 1.3404 - val_tp: 177.0000 - val_fp: 174.0000 - val_tn: 603.0000 - val_fn: 180.0000 - val_accuracy: 0.6878 - val_precision: 0.5043 - val_recall: 0.4958 - val_auc: 0.6990 - val_prc: 0.5255\n",
      "Epoch 93/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0389 - tp: 1387.0000 - fp: 22.0000 - tn: 3085.0000 - fn: 42.0000 - accuracy: 0.9859 - precision: 0.9844 - recall: 0.9706 - auc: 0.9992 - prc: 0.9982 - val_loss: 1.3500 - val_tp: 165.0000 - val_fp: 124.0000 - val_tn: 653.0000 - val_fn: 192.0000 - val_accuracy: 0.7213 - val_precision: 0.5709 - val_recall: 0.4622 - val_auc: 0.7031 - val_prc: 0.5342\n",
      "Epoch 94/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0369 - tp: 1392.0000 - fp: 25.0000 - tn: 3082.0000 - fn: 37.0000 - accuracy: 0.9863 - precision: 0.9824 - recall: 0.9741 - auc: 0.9992 - prc: 0.9984 - val_loss: 1.4183 - val_tp: 150.0000 - val_fp: 100.0000 - val_tn: 677.0000 - val_fn: 207.0000 - val_accuracy: 0.7293 - val_precision: 0.6000 - val_recall: 0.4202 - val_auc: 0.6983 - val_prc: 0.5330\n",
      "Epoch 95/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0364 - tp: 1388.0000 - fp: 20.0000 - tn: 3087.0000 - fn: 41.0000 - accuracy: 0.9866 - precision: 0.9858 - recall: 0.9713 - auc: 0.9993 - prc: 0.9986 - val_loss: 1.3737 - val_tp: 167.0000 - val_fp: 132.0000 - val_tn: 645.0000 - val_fn: 190.0000 - val_accuracy: 0.7160 - val_precision: 0.5585 - val_recall: 0.4678 - val_auc: 0.7011 - val_prc: 0.5293\n",
      "Epoch 96/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0346 - tp: 1394.0000 - fp: 22.0000 - tn: 3085.0000 - fn: 35.0000 - accuracy: 0.9874 - precision: 0.9845 - recall: 0.9755 - auc: 0.9994 - prc: 0.9987 - val_loss: 1.3799 - val_tp: 169.0000 - val_fp: 140.0000 - val_tn: 637.0000 - val_fn: 188.0000 - val_accuracy: 0.7108 - val_precision: 0.5469 - val_recall: 0.4734 - val_auc: 0.7004 - val_prc: 0.5288\n",
      "Epoch 97/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0391 - tp: 1387.0000 - fp: 28.0000 - tn: 3079.0000 - fn: 42.0000 - accuracy: 0.9846 - precision: 0.9802 - recall: 0.9706 - auc: 0.9991 - prc: 0.9981 - val_loss: 1.4063 - val_tp: 158.0000 - val_fp: 114.0000 - val_tn: 663.0000 - val_fn: 199.0000 - val_accuracy: 0.7240 - val_precision: 0.5809 - val_recall: 0.4426 - val_auc: 0.6971 - val_prc: 0.5307\n",
      "Epoch 98/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0353 - tp: 1388.0000 - fp: 28.0000 - tn: 3079.0000 - fn: 41.0000 - accuracy: 0.9848 - precision: 0.9802 - recall: 0.9713 - auc: 0.9993 - prc: 0.9986 - val_loss: 1.4011 - val_tp: 164.0000 - val_fp: 129.0000 - val_tn: 648.0000 - val_fn: 193.0000 - val_accuracy: 0.7160 - val_precision: 0.5597 - val_recall: 0.4594 - val_auc: 0.7000 - val_prc: 0.5293\n",
      "Epoch 99/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0368 - tp: 1390.0000 - fp: 25.0000 - tn: 3082.0000 - fn: 39.0000 - accuracy: 0.9859 - precision: 0.9823 - recall: 0.9727 - auc: 0.9992 - prc: 0.9983 - val_loss: 1.4266 - val_tp: 161.0000 - val_fp: 118.0000 - val_tn: 659.0000 - val_fn: 196.0000 - val_accuracy: 0.7231 - val_precision: 0.5771 - val_recall: 0.4510 - val_auc: 0.6961 - val_prc: 0.5271\n",
      "Epoch 100/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0370 - tp: 1383.0000 - fp: 23.0000 - tn: 3084.0000 - fn: 46.0000 - accuracy: 0.9848 - precision: 0.9836 - recall: 0.9678 - auc: 0.9992 - prc: 0.9984 - val_loss: 1.4119 - val_tp: 169.0000 - val_fp: 143.0000 - val_tn: 634.0000 - val_fn: 188.0000 - val_accuracy: 0.7081 - val_precision: 0.5417 - val_recall: 0.4734 - val_auc: 0.6990 - val_prc: 0.5284\n",
      "Epoch 101/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0328 - tp: 1391.0000 - fp: 23.0000 - tn: 3084.0000 - fn: 38.0000 - accuracy: 0.9866 - precision: 0.9837 - recall: 0.9734 - auc: 0.9994 - prc: 0.9988 - val_loss: 1.4220 - val_tp: 167.0000 - val_fp: 135.0000 - val_tn: 642.0000 - val_fn: 190.0000 - val_accuracy: 0.7134 - val_precision: 0.5530 - val_recall: 0.4678 - val_auc: 0.6987 - val_prc: 0.5285\n",
      "Epoch 102/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0360 - tp: 1393.0000 - fp: 30.0000 - tn: 3077.0000 - fn: 36.0000 - accuracy: 0.9854 - precision: 0.9789 - recall: 0.9748 - auc: 0.9993 - prc: 0.9985 - val_loss: 1.4321 - val_tp: 159.0000 - val_fp: 123.0000 - val_tn: 654.0000 - val_fn: 198.0000 - val_accuracy: 0.7169 - val_precision: 0.5638 - val_recall: 0.4454 - val_auc: 0.6972 - val_prc: 0.5270\n",
      "Epoch 103/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0334 - tp: 1397.0000 - fp: 20.0000 - tn: 3087.0000 - fn: 32.0000 - accuracy: 0.9885 - precision: 0.9859 - recall: 0.9776 - auc: 0.9994 - prc: 0.9987 - val_loss: 1.4304 - val_tp: 164.0000 - val_fp: 132.0000 - val_tn: 645.0000 - val_fn: 193.0000 - val_accuracy: 0.7134 - val_precision: 0.5541 - val_recall: 0.4594 - val_auc: 0.6983 - val_prc: 0.5286\n",
      "Epoch 104/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0350 - tp: 1390.0000 - fp: 23.0000 - tn: 3084.0000 - fn: 39.0000 - accuracy: 0.9863 - precision: 0.9837 - recall: 0.9727 - auc: 0.9993 - prc: 0.9984 - val_loss: 1.4412 - val_tp: 162.0000 - val_fp: 128.0000 - val_tn: 649.0000 - val_fn: 195.0000 - val_accuracy: 0.7152 - val_precision: 0.5586 - val_recall: 0.4538 - val_auc: 0.7000 - val_prc: 0.5293\n",
      "Epoch 105/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0332 - tp: 1395.0000 - fp: 26.0000 - tn: 3081.0000 - fn: 34.0000 - accuracy: 0.9868 - precision: 0.9817 - recall: 0.9762 - auc: 0.9994 - prc: 0.9987 - val_loss: 1.4676 - val_tp: 162.0000 - val_fp: 120.0000 - val_tn: 657.0000 - val_fn: 195.0000 - val_accuracy: 0.7222 - val_precision: 0.5745 - val_recall: 0.4538 - val_auc: 0.6984 - val_prc: 0.5292\n",
      "Epoch 106/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0330 - tp: 1392.0000 - fp: 19.0000 - tn: 3088.0000 - fn: 37.0000 - accuracy: 0.9877 - precision: 0.9865 - recall: 0.9741 - auc: 0.9994 - prc: 0.9987 - val_loss: 1.4454 - val_tp: 168.0000 - val_fp: 144.0000 - val_tn: 633.0000 - val_fn: 189.0000 - val_accuracy: 0.7063 - val_precision: 0.5385 - val_recall: 0.4706 - val_auc: 0.6986 - val_prc: 0.5254\n",
      "Epoch 107/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0349 - tp: 1389.0000 - fp: 26.0000 - tn: 3081.0000 - fn: 40.0000 - accuracy: 0.9854 - precision: 0.9816 - recall: 0.9720 - auc: 0.9993 - prc: 0.9984 - val_loss: 1.4524 - val_tp: 169.0000 - val_fp: 132.0000 - val_tn: 645.0000 - val_fn: 188.0000 - val_accuracy: 0.7178 - val_precision: 0.5615 - val_recall: 0.4734 - val_auc: 0.6987 - val_prc: 0.5267\n",
      "Epoch 108/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0330 - tp: 1386.0000 - fp: 20.0000 - tn: 3087.0000 - fn: 43.0000 - accuracy: 0.9861 - precision: 0.9858 - recall: 0.9699 - auc: 0.9994 - prc: 0.9987 - val_loss: 1.4448 - val_tp: 176.0000 - val_fp: 154.0000 - val_tn: 623.0000 - val_fn: 181.0000 - val_accuracy: 0.7046 - val_precision: 0.5333 - val_recall: 0.4930 - val_auc: 0.6982 - val_prc: 0.5249\n",
      "Epoch 109/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0334 - tp: 1394.0000 - fp: 26.0000 - tn: 3081.0000 - fn: 35.0000 - accuracy: 0.9866 - precision: 0.9817 - recall: 0.9755 - auc: 0.9993 - prc: 0.9986 - val_loss: 1.4687 - val_tp: 172.0000 - val_fp: 151.0000 - val_tn: 626.0000 - val_fn: 185.0000 - val_accuracy: 0.7037 - val_precision: 0.5325 - val_recall: 0.4818 - val_auc: 0.6963 - val_prc: 0.5200\n",
      "Epoch 110/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0327 - tp: 1386.0000 - fp: 18.0000 - tn: 3089.0000 - fn: 43.0000 - accuracy: 0.9866 - precision: 0.9872 - recall: 0.9699 - auc: 0.9993 - prc: 0.9986 - val_loss: 1.4824 - val_tp: 178.0000 - val_fp: 172.0000 - val_tn: 605.0000 - val_fn: 179.0000 - val_accuracy: 0.6905 - val_precision: 0.5086 - val_recall: 0.4986 - val_auc: 0.6963 - val_prc: 0.5177\n",
      "Epoch 111/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0330 - tp: 1393.0000 - fp: 24.0000 - tn: 3083.0000 - fn: 36.0000 - accuracy: 0.9868 - precision: 0.9831 - recall: 0.9748 - auc: 0.9994 - prc: 0.9986 - val_loss: 1.4830 - val_tp: 170.0000 - val_fp: 146.0000 - val_tn: 631.0000 - val_fn: 187.0000 - val_accuracy: 0.7063 - val_precision: 0.5380 - val_recall: 0.4762 - val_auc: 0.6974 - val_prc: 0.5214\n",
      "Epoch 112/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0324 - tp: 1395.0000 - fp: 23.0000 - tn: 3084.0000 - fn: 34.0000 - accuracy: 0.9874 - precision: 0.9838 - recall: 0.9762 - auc: 0.9994 - prc: 0.9987 - val_loss: 1.4917 - val_tp: 173.0000 - val_fp: 149.0000 - val_tn: 628.0000 - val_fn: 184.0000 - val_accuracy: 0.7063 - val_precision: 0.5373 - val_recall: 0.4846 - val_auc: 0.6980 - val_prc: 0.5231\n",
      "Epoch 113/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0319 - tp: 1394.0000 - fp: 23.0000 - tn: 3084.0000 - fn: 35.0000 - accuracy: 0.9872 - precision: 0.9838 - recall: 0.9755 - auc: 0.9994 - prc: 0.9987 - val_loss: 1.5094 - val_tp: 175.0000 - val_fp: 156.0000 - val_tn: 621.0000 - val_fn: 182.0000 - val_accuracy: 0.7019 - val_precision: 0.5287 - val_recall: 0.4902 - val_auc: 0.6987 - val_prc: 0.5196\n",
      "Epoch 114/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0315 - tp: 1398.0000 - fp: 21.0000 - tn: 3086.0000 - fn: 31.0000 - accuracy: 0.9885 - precision: 0.9852 - recall: 0.9783 - auc: 0.9994 - prc: 0.9987 - val_loss: 1.5229 - val_tp: 162.0000 - val_fp: 124.0000 - val_tn: 653.0000 - val_fn: 195.0000 - val_accuracy: 0.7187 - val_precision: 0.5664 - val_recall: 0.4538 - val_auc: 0.6994 - val_prc: 0.5276\n",
      "Epoch 115/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0313 - tp: 1393.0000 - fp: 21.0000 - tn: 3086.0000 - fn: 36.0000 - accuracy: 0.9874 - precision: 0.9851 - recall: 0.9748 - auc: 0.9994 - prc: 0.9988 - val_loss: 1.5229 - val_tp: 176.0000 - val_fp: 153.0000 - val_tn: 624.0000 - val_fn: 181.0000 - val_accuracy: 0.7055 - val_precision: 0.5350 - val_recall: 0.4930 - val_auc: 0.6983 - val_prc: 0.5235\n",
      "Epoch 116/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0330 - tp: 1395.0000 - fp: 25.0000 - tn: 3082.0000 - fn: 34.0000 - accuracy: 0.9870 - precision: 0.9824 - recall: 0.9762 - auc: 0.9993 - prc: 0.9986 - val_loss: 1.5395 - val_tp: 155.0000 - val_fp: 118.0000 - val_tn: 659.0000 - val_fn: 202.0000 - val_accuracy: 0.7178 - val_precision: 0.5678 - val_recall: 0.4342 - val_auc: 0.6973 - val_prc: 0.5307\n",
      "Epoch 117/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0323 - tp: 1398.0000 - fp: 22.0000 - tn: 3085.0000 - fn: 31.0000 - accuracy: 0.9883 - precision: 0.9845 - recall: 0.9783 - auc: 0.9993 - prc: 0.9986 - val_loss: 1.5198 - val_tp: 171.0000 - val_fp: 139.0000 - val_tn: 638.0000 - val_fn: 186.0000 - val_accuracy: 0.7134 - val_precision: 0.5516 - val_recall: 0.4790 - val_auc: 0.6983 - val_prc: 0.5274\n",
      "Epoch 118/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0302 - tp: 1397.0000 - fp: 20.0000 - tn: 3087.0000 - fn: 32.0000 - accuracy: 0.9885 - precision: 0.9859 - recall: 0.9776 - auc: 0.9995 - prc: 0.9989 - val_loss: 1.5379 - val_tp: 176.0000 - val_fp: 156.0000 - val_tn: 621.0000 - val_fn: 181.0000 - val_accuracy: 0.7028 - val_precision: 0.5301 - val_recall: 0.4930 - val_auc: 0.6983 - val_prc: 0.5214\n",
      "Epoch 119/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0314 - tp: 1392.0000 - fp: 21.0000 - tn: 3086.0000 - fn: 37.0000 - accuracy: 0.9872 - precision: 0.9851 - recall: 0.9741 - auc: 0.9994 - prc: 0.9987 - val_loss: 1.5673 - val_tp: 157.0000 - val_fp: 117.0000 - val_tn: 660.0000 - val_fn: 200.0000 - val_accuracy: 0.7205 - val_precision: 0.5730 - val_recall: 0.4398 - val_auc: 0.6975 - val_prc: 0.5283\n",
      "Epoch 120/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0302 - tp: 1395.0000 - fp: 26.0000 - tn: 3081.0000 - fn: 34.0000 - accuracy: 0.9868 - precision: 0.9817 - recall: 0.9762 - auc: 0.9994 - prc: 0.9988 - val_loss: 1.5493 - val_tp: 167.0000 - val_fp: 125.0000 - val_tn: 652.0000 - val_fn: 190.0000 - val_accuracy: 0.7222 - val_precision: 0.5719 - val_recall: 0.4678 - val_auc: 0.6978 - val_prc: 0.5248\n",
      "Epoch 121/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0302 - tp: 1393.0000 - fp: 23.0000 - tn: 3084.0000 - fn: 36.0000 - accuracy: 0.9870 - precision: 0.9838 - recall: 0.9748 - auc: 0.9994 - prc: 0.9988 - val_loss: 1.5905 - val_tp: 156.0000 - val_fp: 115.0000 - val_tn: 662.0000 - val_fn: 201.0000 - val_accuracy: 0.7213 - val_precision: 0.5756 - val_recall: 0.4370 - val_auc: 0.6957 - val_prc: 0.5267\n",
      "Epoch 122/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0307 - tp: 1389.0000 - fp: 23.0000 - tn: 3084.0000 - fn: 40.0000 - accuracy: 0.9861 - precision: 0.9837 - recall: 0.9720 - auc: 0.9994 - prc: 0.9988 - val_loss: 1.5658 - val_tp: 173.0000 - val_fp: 140.0000 - val_tn: 637.0000 - val_fn: 184.0000 - val_accuracy: 0.7143 - val_precision: 0.5527 - val_recall: 0.4846 - val_auc: 0.6978 - val_prc: 0.5216\n",
      "Epoch 123/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0302 - tp: 1394.0000 - fp: 25.0000 - tn: 3082.0000 - fn: 35.0000 - accuracy: 0.9868 - precision: 0.9824 - recall: 0.9755 - auc: 0.9994 - prc: 0.9988 - val_loss: 1.5757 - val_tp: 164.0000 - val_fp: 129.0000 - val_tn: 648.0000 - val_fn: 193.0000 - val_accuracy: 0.7160 - val_precision: 0.5597 - val_recall: 0.4594 - val_auc: 0.6987 - val_prc: 0.5316\n",
      "Epoch 124/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0310 - tp: 1395.0000 - fp: 27.0000 - tn: 3080.0000 - fn: 34.0000 - accuracy: 0.9866 - precision: 0.9810 - recall: 0.9762 - auc: 0.9994 - prc: 0.9987 - val_loss: 1.5920 - val_tp: 162.0000 - val_fp: 128.0000 - val_tn: 649.0000 - val_fn: 195.0000 - val_accuracy: 0.7152 - val_precision: 0.5586 - val_recall: 0.4538 - val_auc: 0.6966 - val_prc: 0.5273\n",
      "Epoch 125/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0303 - tp: 1389.0000 - fp: 22.0000 - tn: 3085.0000 - fn: 40.0000 - accuracy: 0.9863 - precision: 0.9844 - recall: 0.9720 - auc: 0.9994 - prc: 0.9988 - val_loss: 1.5755 - val_tp: 177.0000 - val_fp: 157.0000 - val_tn: 620.0000 - val_fn: 180.0000 - val_accuracy: 0.7028 - val_precision: 0.5299 - val_recall: 0.4958 - val_auc: 0.6977 - val_prc: 0.5195\n",
      "Epoch 126/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0311 - tp: 1391.0000 - fp: 26.0000 - tn: 3081.0000 - fn: 38.0000 - accuracy: 0.9859 - precision: 0.9817 - recall: 0.9734 - auc: 0.9994 - prc: 0.9987 - val_loss: 1.5973 - val_tp: 189.0000 - val_fp: 194.0000 - val_tn: 583.0000 - val_fn: 168.0000 - val_accuracy: 0.6808 - val_precision: 0.4935 - val_recall: 0.5294 - val_auc: 0.6940 - val_prc: 0.5140\n",
      "Epoch 127/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0315 - tp: 1393.0000 - fp: 23.0000 - tn: 3084.0000 - fn: 36.0000 - accuracy: 0.9870 - precision: 0.9838 - recall: 0.9748 - auc: 0.9994 - prc: 0.9987 - val_loss: 1.5750 - val_tp: 171.0000 - val_fp: 143.0000 - val_tn: 634.0000 - val_fn: 186.0000 - val_accuracy: 0.7099 - val_precision: 0.5446 - val_recall: 0.4790 - val_auc: 0.6972 - val_prc: 0.5210\n",
      "Epoch 128/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0307 - tp: 1393.0000 - fp: 24.0000 - tn: 3083.0000 - fn: 36.0000 - accuracy: 0.9868 - precision: 0.9831 - recall: 0.9748 - auc: 0.9994 - prc: 0.9988 - val_loss: 1.6423 - val_tp: 154.0000 - val_fp: 115.0000 - val_tn: 662.0000 - val_fn: 203.0000 - val_accuracy: 0.7196 - val_precision: 0.5725 - val_recall: 0.4314 - val_auc: 0.6939 - val_prc: 0.5226\n",
      "Epoch 129/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0280 - tp: 1391.0000 - fp: 17.0000 - tn: 3090.0000 - fn: 38.0000 - accuracy: 0.9879 - precision: 0.9879 - recall: 0.9734 - auc: 0.9995 - prc: 0.9990 - val_loss: 1.6146 - val_tp: 176.0000 - val_fp: 154.0000 - val_tn: 623.0000 - val_fn: 181.0000 - val_accuracy: 0.7046 - val_precision: 0.5333 - val_recall: 0.4930 - val_auc: 0.6973 - val_prc: 0.5170\n",
      "Epoch 130/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0312 - tp: 1394.0000 - fp: 24.0000 - tn: 3083.0000 - fn: 35.0000 - accuracy: 0.9870 - precision: 0.9831 - recall: 0.9755 - auc: 0.9994 - prc: 0.9987 - val_loss: 1.5940 - val_tp: 174.0000 - val_fp: 155.0000 - val_tn: 622.0000 - val_fn: 183.0000 - val_accuracy: 0.7019 - val_precision: 0.5289 - val_recall: 0.4874 - val_auc: 0.6980 - val_prc: 0.5217\n",
      "Epoch 131/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0281 - tp: 1396.0000 - fp: 19.0000 - tn: 3088.0000 - fn: 33.0000 - accuracy: 0.9885 - precision: 0.9866 - recall: 0.9769 - auc: 0.9995 - prc: 0.9989 - val_loss: 1.6294 - val_tp: 168.0000 - val_fp: 139.0000 - val_tn: 638.0000 - val_fn: 189.0000 - val_accuracy: 0.7108 - val_precision: 0.5472 - val_recall: 0.4706 - val_auc: 0.6959 - val_prc: 0.5214\n",
      "Epoch 132/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0296 - tp: 1397.0000 - fp: 25.0000 - tn: 3082.0000 - fn: 32.0000 - accuracy: 0.9874 - precision: 0.9824 - recall: 0.9776 - auc: 0.9995 - prc: 0.9988 - val_loss: 1.6425 - val_tp: 158.0000 - val_fp: 122.0000 - val_tn: 655.0000 - val_fn: 199.0000 - val_accuracy: 0.7169 - val_precision: 0.5643 - val_recall: 0.4426 - val_auc: 0.6970 - val_prc: 0.5267\n",
      "Epoch 133/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0292 - tp: 1394.0000 - fp: 22.0000 - tn: 3085.0000 - fn: 35.0000 - accuracy: 0.9874 - precision: 0.9845 - recall: 0.9755 - auc: 0.9995 - prc: 0.9989 - val_loss: 1.6215 - val_tp: 180.0000 - val_fp: 167.0000 - val_tn: 610.0000 - val_fn: 177.0000 - val_accuracy: 0.6966 - val_precision: 0.5187 - val_recall: 0.5042 - val_auc: 0.6972 - val_prc: 0.5175\n",
      "Epoch 134/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0310 - tp: 1390.0000 - fp: 25.0000 - tn: 3082.0000 - fn: 39.0000 - accuracy: 0.9859 - precision: 0.9823 - recall: 0.9727 - auc: 0.9994 - prc: 0.9987 - val_loss: 1.6122 - val_tp: 169.0000 - val_fp: 140.0000 - val_tn: 637.0000 - val_fn: 188.0000 - val_accuracy: 0.7108 - val_precision: 0.5469 - val_recall: 0.4734 - val_auc: 0.6981 - val_prc: 0.5233\n",
      "Epoch 135/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0300 - tp: 1397.0000 - fp: 30.0000 - tn: 3077.0000 - fn: 32.0000 - accuracy: 0.9863 - precision: 0.9790 - recall: 0.9776 - auc: 0.9994 - prc: 0.9988 - val_loss: 1.6579 - val_tp: 157.0000 - val_fp: 121.0000 - val_tn: 656.0000 - val_fn: 200.0000 - val_accuracy: 0.7169 - val_precision: 0.5647 - val_recall: 0.4398 - val_auc: 0.6927 - val_prc: 0.5223\n",
      "Epoch 136/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0307 - tp: 1389.0000 - fp: 22.0000 - tn: 3085.0000 - fn: 40.0000 - accuracy: 0.9863 - precision: 0.9844 - recall: 0.9720 - auc: 0.9994 - prc: 0.9987 - val_loss: 1.6337 - val_tp: 171.0000 - val_fp: 143.0000 - val_tn: 634.0000 - val_fn: 186.0000 - val_accuracy: 0.7099 - val_precision: 0.5446 - val_recall: 0.4790 - val_auc: 0.6959 - val_prc: 0.5189\n",
      "Epoch 137/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0292 - tp: 1390.0000 - fp: 22.0000 - tn: 3085.0000 - fn: 39.0000 - accuracy: 0.9866 - precision: 0.9844 - recall: 0.9727 - auc: 0.9995 - prc: 0.9989 - val_loss: 1.6870 - val_tp: 155.0000 - val_fp: 115.0000 - val_tn: 662.0000 - val_fn: 202.0000 - val_accuracy: 0.7205 - val_precision: 0.5741 - val_recall: 0.4342 - val_auc: 0.6954 - val_prc: 0.5236\n",
      "Epoch 138/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0271 - tp: 1396.0000 - fp: 11.0000 - tn: 3096.0000 - fn: 33.0000 - accuracy: 0.9903 - precision: 0.9922 - recall: 0.9769 - auc: 0.9996 - prc: 0.9991 - val_loss: 1.6555 - val_tp: 176.0000 - val_fp: 153.0000 - val_tn: 624.0000 - val_fn: 181.0000 - val_accuracy: 0.7055 - val_precision: 0.5350 - val_recall: 0.4930 - val_auc: 0.6995 - val_prc: 0.5211\n",
      "Epoch 139/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0309 - tp: 1396.0000 - fp: 26.0000 - tn: 3081.0000 - fn: 33.0000 - accuracy: 0.9870 - precision: 0.9817 - recall: 0.9769 - auc: 0.9994 - prc: 0.9987 - val_loss: 1.6532 - val_tp: 165.0000 - val_fp: 128.0000 - val_tn: 649.0000 - val_fn: 192.0000 - val_accuracy: 0.7178 - val_precision: 0.5631 - val_recall: 0.4622 - val_auc: 0.6962 - val_prc: 0.5215\n",
      "Epoch 140/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0284 - tp: 1393.0000 - fp: 18.0000 - tn: 3089.0000 - fn: 36.0000 - accuracy: 0.9881 - precision: 0.9872 - recall: 0.9748 - auc: 0.9995 - prc: 0.9990 - val_loss: 1.6565 - val_tp: 172.0000 - val_fp: 140.0000 - val_tn: 637.0000 - val_fn: 185.0000 - val_accuracy: 0.7134 - val_precision: 0.5513 - val_recall: 0.4818 - val_auc: 0.6982 - val_prc: 0.5233\n",
      "Epoch 141/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0275 - tp: 1398.0000 - fp: 22.0000 - tn: 3085.0000 - fn: 31.0000 - accuracy: 0.9883 - precision: 0.9845 - recall: 0.9783 - auc: 0.9995 - prc: 0.9990 - val_loss: 1.6642 - val_tp: 173.0000 - val_fp: 147.0000 - val_tn: 630.0000 - val_fn: 184.0000 - val_accuracy: 0.7081 - val_precision: 0.5406 - val_recall: 0.4846 - val_auc: 0.6957 - val_prc: 0.5193\n",
      "Epoch 142/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0286 - tp: 1396.0000 - fp: 21.0000 - tn: 3086.0000 - fn: 33.0000 - accuracy: 0.9881 - precision: 0.9852 - recall: 0.9769 - auc: 0.9995 - prc: 0.9989 - val_loss: 1.6778 - val_tp: 167.0000 - val_fp: 138.0000 - val_tn: 639.0000 - val_fn: 190.0000 - val_accuracy: 0.7108 - val_precision: 0.5475 - val_recall: 0.4678 - val_auc: 0.6960 - val_prc: 0.5232\n",
      "Epoch 143/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0281 - tp: 1394.0000 - fp: 18.0000 - tn: 3089.0000 - fn: 35.0000 - accuracy: 0.9883 - precision: 0.9873 - recall: 0.9755 - auc: 0.9995 - prc: 0.9990 - val_loss: 1.6731 - val_tp: 171.0000 - val_fp: 142.0000 - val_tn: 635.0000 - val_fn: 186.0000 - val_accuracy: 0.7108 - val_precision: 0.5463 - val_recall: 0.4790 - val_auc: 0.6972 - val_prc: 0.5191\n",
      "Epoch 144/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0282 - tp: 1396.0000 - fp: 23.0000 - tn: 3084.0000 - fn: 33.0000 - accuracy: 0.9877 - precision: 0.9838 - recall: 0.9769 - auc: 0.9995 - prc: 0.9990 - val_loss: 1.6727 - val_tp: 183.0000 - val_fp: 168.0000 - val_tn: 609.0000 - val_fn: 174.0000 - val_accuracy: 0.6984 - val_precision: 0.5214 - val_recall: 0.5126 - val_auc: 0.6962 - val_prc: 0.5124\n",
      "Epoch 145/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0290 - tp: 1393.0000 - fp: 27.0000 - tn: 3080.0000 - fn: 36.0000 - accuracy: 0.9861 - precision: 0.9810 - recall: 0.9748 - auc: 0.9995 - prc: 0.9989 - val_loss: 1.7057 - val_tp: 159.0000 - val_fp: 121.0000 - val_tn: 656.0000 - val_fn: 198.0000 - val_accuracy: 0.7187 - val_precision: 0.5679 - val_recall: 0.4454 - val_auc: 0.6934 - val_prc: 0.5206\n",
      "Epoch 146/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0272 - tp: 1397.0000 - fp: 20.0000 - tn: 3087.0000 - fn: 32.0000 - accuracy: 0.9885 - precision: 0.9859 - recall: 0.9776 - auc: 0.9995 - prc: 0.9990 - val_loss: 1.6894 - val_tp: 176.0000 - val_fp: 144.0000 - val_tn: 633.0000 - val_fn: 181.0000 - val_accuracy: 0.7134 - val_precision: 0.5500 - val_recall: 0.4930 - val_auc: 0.6958 - val_prc: 0.5182\n",
      "Epoch 147/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0300 - tp: 1390.0000 - fp: 25.0000 - tn: 3082.0000 - fn: 39.0000 - accuracy: 0.9859 - precision: 0.9823 - recall: 0.9727 - auc: 0.9994 - prc: 0.9988 - val_loss: 1.6902 - val_tp: 171.0000 - val_fp: 140.0000 - val_tn: 637.0000 - val_fn: 186.0000 - val_accuracy: 0.7125 - val_precision: 0.5498 - val_recall: 0.4790 - val_auc: 0.6948 - val_prc: 0.5181\n",
      "Epoch 148/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0285 - tp: 1399.0000 - fp: 21.0000 - tn: 3086.0000 - fn: 30.0000 - accuracy: 0.9888 - precision: 0.9852 - recall: 0.9790 - auc: 0.9995 - prc: 0.9988 - val_loss: 1.7004 - val_tp: 176.0000 - val_fp: 144.0000 - val_tn: 633.0000 - val_fn: 181.0000 - val_accuracy: 0.7134 - val_precision: 0.5500 - val_recall: 0.4930 - val_auc: 0.6953 - val_prc: 0.5164\n"
     ]
    }
   ],
   "source": [
    "# Simple Model\n",
    "def nn_builder(text_vectorizer):\n",
    "    nn = Sequential()\n",
    "    nn.add(Input(shape=(1,), dtype=\"string\"))\n",
    "    nn.add(text_vectorizer)\n",
    "    nn.add(Dense(500, activation=\"relu\"))\n",
    "    nn.add(Dropout(0.4))\n",
    "    nn.add(Dense(1, activation=\"sigmoid\"))\n",
    "    nn.compile(loss=experiment_parameters['loss'],\n",
    "               optimizer=experiment_parameters['optimizer'],\n",
    "               metrics=METRICS)\n",
    "    return nn\n",
    "\n",
    "\n",
    "nn_model = nn_builder(tfidf_vectorizer)\n",
    "\n",
    "history = nn_model.fit(X_train, y_train,\n",
    "                       experiment_parameters['batch_size'],\n",
    "                       experiment_parameters['epochs'],\n",
    "                       validation_data=(X_test, y_test),\n",
    "                       callbacks=[EarlyStopping(monitor=\"loss\",\n",
    "                                                patience=10,\n",
    "                                                restore_best_weights=True)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.775155</td>\n",
       "      <td>0.534954</td>\n",
       "      <td>0.705467</td>\n",
       "      <td>0.655055</td>\n",
       "      <td>0.699536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.803089</td>\n",
       "      <td>0.492997</td>\n",
       "      <td>0.705467</td>\n",
       "      <td>0.648043</td>\n",
       "      <td>0.705467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.788875</td>\n",
       "      <td>0.513120</td>\n",
       "      <td>0.705467</td>\n",
       "      <td>0.650997</td>\n",
       "      <td>0.702063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>777.000000</td>\n",
       "      <td>357.000000</td>\n",
       "      <td>0.705467</td>\n",
       "      <td>1134.000000</td>\n",
       "      <td>1134.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0           1  accuracy    macro avg  weighted avg\n",
       "precision    0.775155    0.534954  0.705467     0.655055      0.699536\n",
       "recall       0.803089    0.492997  0.705467     0.648043      0.705467\n",
       "f1-score     0.788875    0.513120  0.705467     0.650997      0.702063\n",
       "support    777.000000  357.000000  0.705467  1134.000000   1134.000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds = nn_model.predict(X_test)\n",
    "pd.DataFrame(classification_report(\n",
    "    y_test, np.where(test_preds >= 0.5, 1, 0), output_dict=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "71/71 [==============================] - 2s 12ms/step - loss: 1.0905 - tp: 548.0000 - fp: 775.0000 - tn: 3109.0000 - fn: 1238.0000 - accuracy: 0.6450 - precision: 0.4142 - recall: 0.3068 - auc: 0.5674 - prc: 0.3777 - val_loss: 0.6486 - val_tp: 231.0000 - val_fp: 294.0000 - val_tn: 483.0000 - val_fn: 126.0000 - val_accuracy: 0.6296 - val_precision: 0.4400 - val_recall: 0.6471 - val_auc: 0.6933 - val_prc: 0.5217\n",
      "Epoch 2/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.5655 - tp: 472.0000 - fp: 274.0000 - tn: 2833.0000 - fn: 957.0000 - accuracy: 0.7286 - precision: 0.6327 - recall: 0.3303 - auc: 0.7125 - prc: 0.5500 - val_loss: 0.5684 - val_tp: 100.0000 - val_fp: 35.0000 - val_tn: 742.0000 - val_fn: 257.0000 - val_accuracy: 0.7425 - val_precision: 0.7407 - val_recall: 0.2801 - val_auc: 0.6949 - val_prc: 0.5529\n",
      "Epoch 3/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.4920 - tp: 653.0000 - fp: 249.0000 - tn: 2858.0000 - fn: 776.0000 - accuracy: 0.7740 - precision: 0.7239 - recall: 0.4570 - auc: 0.8045 - prc: 0.6746 - val_loss: 0.5974 - val_tp: 89.0000 - val_fp: 29.0000 - val_tn: 748.0000 - val_fn: 268.0000 - val_accuracy: 0.7381 - val_precision: 0.7542 - val_recall: 0.2493 - val_auc: 0.6880 - val_prc: 0.5526\n",
      "Epoch 4/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.4429 - tp: 750.0000 - fp: 227.0000 - tn: 2880.0000 - fn: 679.0000 - accuracy: 0.8003 - precision: 0.7677 - recall: 0.5248 - auc: 0.8519 - prc: 0.7308 - val_loss: 0.5927 - val_tp: 202.0000 - val_fp: 179.0000 - val_tn: 598.0000 - val_fn: 155.0000 - val_accuracy: 0.7055 - val_precision: 0.5302 - val_recall: 0.5658 - val_auc: 0.7246 - val_prc: 0.5631\n",
      "Epoch 5/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.4051 - tp: 878.0000 - fp: 262.0000 - tn: 2845.0000 - fn: 551.0000 - accuracy: 0.8208 - precision: 0.7702 - recall: 0.6144 - auc: 0.8766 - prc: 0.7780 - val_loss: 0.5742 - val_tp: 164.0000 - val_fp: 106.0000 - val_tn: 671.0000 - val_fn: 193.0000 - val_accuracy: 0.7363 - val_precision: 0.6074 - val_recall: 0.4594 - val_auc: 0.7250 - val_prc: 0.5781\n",
      "Epoch 6/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.3572 - tp: 938.0000 - fp: 225.0000 - tn: 2882.0000 - fn: 491.0000 - accuracy: 0.8422 - precision: 0.8065 - recall: 0.6564 - auc: 0.9101 - prc: 0.8292 - val_loss: 0.5970 - val_tp: 165.0000 - val_fp: 100.0000 - val_tn: 677.0000 - val_fn: 192.0000 - val_accuracy: 0.7425 - val_precision: 0.6226 - val_recall: 0.4622 - val_auc: 0.7226 - val_prc: 0.5703\n",
      "Epoch 7/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.3197 - tp: 1015.0000 - fp: 206.0000 - tn: 2901.0000 - fn: 414.0000 - accuracy: 0.8633 - precision: 0.8313 - recall: 0.7103 - auc: 0.9287 - prc: 0.8662 - val_loss: 0.6450 - val_tp: 141.0000 - val_fp: 69.0000 - val_tn: 708.0000 - val_fn: 216.0000 - val_accuracy: 0.7487 - val_precision: 0.6714 - val_recall: 0.3950 - val_auc: 0.7157 - val_prc: 0.5735\n",
      "Epoch 8/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.2858 - tp: 1071.0000 - fp: 183.0000 - tn: 2924.0000 - fn: 358.0000 - accuracy: 0.8807 - precision: 0.8541 - recall: 0.7495 - auc: 0.9443 - prc: 0.8899 - val_loss: 0.6504 - val_tp: 175.0000 - val_fp: 121.0000 - val_tn: 656.0000 - val_fn: 182.0000 - val_accuracy: 0.7328 - val_precision: 0.5912 - val_recall: 0.4902 - val_auc: 0.7253 - val_prc: 0.5674\n",
      "Epoch 9/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.2399 - tp: 1146.0000 - fp: 149.0000 - tn: 2958.0000 - fn: 283.0000 - accuracy: 0.9048 - precision: 0.8849 - recall: 0.8020 - auc: 0.9636 - prc: 0.9269 - val_loss: 0.6796 - val_tp: 167.0000 - val_fp: 106.0000 - val_tn: 671.0000 - val_fn: 190.0000 - val_accuracy: 0.7390 - val_precision: 0.6117 - val_recall: 0.4678 - val_auc: 0.7214 - val_prc: 0.5677\n",
      "Epoch 10/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.2158 - tp: 1187.0000 - fp: 133.0000 - tn: 2974.0000 - fn: 242.0000 - accuracy: 0.9173 - precision: 0.8992 - recall: 0.8307 - auc: 0.9700 - prc: 0.9403 - val_loss: 0.7063 - val_tp: 184.0000 - val_fp: 132.0000 - val_tn: 645.0000 - val_fn: 173.0000 - val_accuracy: 0.7310 - val_precision: 0.5823 - val_recall: 0.5154 - val_auc: 0.7234 - val_prc: 0.5626\n",
      "Epoch 11/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.1840 - tp: 1221.0000 - fp: 114.0000 - tn: 2993.0000 - fn: 208.0000 - accuracy: 0.9290 - precision: 0.9146 - recall: 0.8544 - auc: 0.9793 - prc: 0.9576 - val_loss: 0.8246 - val_tp: 230.0000 - val_fp: 240.0000 - val_tn: 537.0000 - val_fn: 127.0000 - val_accuracy: 0.6764 - val_precision: 0.4894 - val_recall: 0.6443 - val_auc: 0.7210 - val_prc: 0.5469\n",
      "Epoch 12/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.1625 - tp: 1259.0000 - fp: 110.0000 - tn: 2997.0000 - fn: 170.0000 - accuracy: 0.9383 - precision: 0.9196 - recall: 0.8810 - auc: 0.9835 - prc: 0.9671 - val_loss: 0.8124 - val_tp: 163.0000 - val_fp: 102.0000 - val_tn: 675.0000 - val_fn: 194.0000 - val_accuracy: 0.7390 - val_precision: 0.6151 - val_recall: 0.4566 - val_auc: 0.7180 - val_prc: 0.5624\n",
      "Epoch 13/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.1457 - tp: 1277.0000 - fp: 96.0000 - tn: 3011.0000 - fn: 152.0000 - accuracy: 0.9453 - precision: 0.9301 - recall: 0.8936 - auc: 0.9865 - prc: 0.9730 - val_loss: 0.8071 - val_tp: 191.0000 - val_fp: 138.0000 - val_tn: 639.0000 - val_fn: 166.0000 - val_accuracy: 0.7319 - val_precision: 0.5805 - val_recall: 0.5350 - val_auc: 0.7196 - val_prc: 0.5647\n",
      "Epoch 14/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.1199 - tp: 1321.0000 - fp: 89.0000 - tn: 3018.0000 - fn: 108.0000 - accuracy: 0.9566 - precision: 0.9369 - recall: 0.9244 - auc: 0.9912 - prc: 0.9825 - val_loss: 0.8854 - val_tp: 180.0000 - val_fp: 123.0000 - val_tn: 654.0000 - val_fn: 177.0000 - val_accuracy: 0.7354 - val_precision: 0.5941 - val_recall: 0.5042 - val_auc: 0.7166 - val_prc: 0.5587\n",
      "Epoch 15/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.1016 - tp: 1333.0000 - fp: 66.0000 - tn: 3041.0000 - fn: 96.0000 - accuracy: 0.9643 - precision: 0.9528 - recall: 0.9328 - auc: 0.9943 - prc: 0.9879 - val_loss: 0.9231 - val_tp: 185.0000 - val_fp: 135.0000 - val_tn: 642.0000 - val_fn: 172.0000 - val_accuracy: 0.7293 - val_precision: 0.5781 - val_recall: 0.5182 - val_auc: 0.7158 - val_prc: 0.5575\n",
      "Epoch 16/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0863 - tp: 1346.0000 - fp: 51.0000 - tn: 3056.0000 - fn: 83.0000 - accuracy: 0.9705 - precision: 0.9635 - recall: 0.9419 - auc: 0.9956 - prc: 0.9913 - val_loss: 1.0001 - val_tp: 146.0000 - val_fp: 95.0000 - val_tn: 682.0000 - val_fn: 211.0000 - val_accuracy: 0.7302 - val_precision: 0.6058 - val_recall: 0.4090 - val_auc: 0.7075 - val_prc: 0.5545\n",
      "Epoch 17/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0743 - tp: 1366.0000 - fp: 47.0000 - tn: 3060.0000 - fn: 63.0000 - accuracy: 0.9757 - precision: 0.9667 - recall: 0.9559 - auc: 0.9970 - prc: 0.9938 - val_loss: 1.0794 - val_tp: 140.0000 - val_fp: 87.0000 - val_tn: 690.0000 - val_fn: 217.0000 - val_accuracy: 0.7319 - val_precision: 0.6167 - val_recall: 0.3922 - val_auc: 0.7013 - val_prc: 0.5489\n",
      "Epoch 18/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0771 - tp: 1359.0000 - fp: 43.0000 - tn: 3064.0000 - fn: 70.0000 - accuracy: 0.9751 - precision: 0.9693 - recall: 0.9510 - auc: 0.9963 - prc: 0.9926 - val_loss: 1.0434 - val_tp: 179.0000 - val_fp: 141.0000 - val_tn: 636.0000 - val_fn: 178.0000 - val_accuracy: 0.7187 - val_precision: 0.5594 - val_recall: 0.5014 - val_auc: 0.7053 - val_prc: 0.5460\n",
      "Epoch 19/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0655 - tp: 1360.0000 - fp: 34.0000 - tn: 3073.0000 - fn: 69.0000 - accuracy: 0.9773 - precision: 0.9756 - recall: 0.9517 - auc: 0.9975 - prc: 0.9948 - val_loss: 1.1137 - val_tp: 163.0000 - val_fp: 120.0000 - val_tn: 657.0000 - val_fn: 194.0000 - val_accuracy: 0.7231 - val_precision: 0.5760 - val_recall: 0.4566 - val_auc: 0.7012 - val_prc: 0.5424\n",
      "Epoch 20/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0662 - tp: 1362.0000 - fp: 39.0000 - tn: 3068.0000 - fn: 67.0000 - accuracy: 0.9766 - precision: 0.9722 - recall: 0.9531 - auc: 0.9972 - prc: 0.9943 - val_loss: 1.1219 - val_tp: 175.0000 - val_fp: 140.0000 - val_tn: 637.0000 - val_fn: 182.0000 - val_accuracy: 0.7160 - val_precision: 0.5556 - val_recall: 0.4902 - val_auc: 0.7043 - val_prc: 0.5451\n",
      "Epoch 21/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0565 - tp: 1370.0000 - fp: 28.0000 - tn: 3079.0000 - fn: 59.0000 - accuracy: 0.9808 - precision: 0.9800 - recall: 0.9587 - auc: 0.9980 - prc: 0.9960 - val_loss: 1.1756 - val_tp: 205.0000 - val_fp: 202.0000 - val_tn: 575.0000 - val_fn: 152.0000 - val_accuracy: 0.6878 - val_precision: 0.5037 - val_recall: 0.5742 - val_auc: 0.7072 - val_prc: 0.5421\n",
      "Epoch 22/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0599 - tp: 1371.0000 - fp: 43.0000 - tn: 3064.0000 - fn: 58.0000 - accuracy: 0.9777 - precision: 0.9696 - recall: 0.9594 - auc: 0.9977 - prc: 0.9953 - val_loss: 1.2074 - val_tp: 156.0000 - val_fp: 115.0000 - val_tn: 662.0000 - val_fn: 201.0000 - val_accuracy: 0.7213 - val_precision: 0.5756 - val_recall: 0.4370 - val_auc: 0.7023 - val_prc: 0.5409\n",
      "Epoch 23/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0515 - tp: 1373.0000 - fp: 37.0000 - tn: 3070.0000 - fn: 56.0000 - accuracy: 0.9795 - precision: 0.9738 - recall: 0.9608 - auc: 0.9985 - prc: 0.9968 - val_loss: 1.2748 - val_tp: 149.0000 - val_fp: 107.0000 - val_tn: 670.0000 - val_fn: 208.0000 - val_accuracy: 0.7222 - val_precision: 0.5820 - val_recall: 0.4174 - val_auc: 0.6965 - val_prc: 0.5414\n",
      "Epoch 24/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0481 - tp: 1377.0000 - fp: 30.0000 - tn: 3077.0000 - fn: 52.0000 - accuracy: 0.9819 - precision: 0.9787 - recall: 0.9636 - auc: 0.9984 - prc: 0.9967 - val_loss: 1.2982 - val_tp: 156.0000 - val_fp: 113.0000 - val_tn: 664.0000 - val_fn: 201.0000 - val_accuracy: 0.7231 - val_precision: 0.5799 - val_recall: 0.4370 - val_auc: 0.7014 - val_prc: 0.5432\n",
      "Epoch 25/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0486 - tp: 1375.0000 - fp: 31.0000 - tn: 3076.0000 - fn: 54.0000 - accuracy: 0.9813 - precision: 0.9780 - recall: 0.9622 - auc: 0.9984 - prc: 0.9968 - val_loss: 1.2582 - val_tp: 199.0000 - val_fp: 189.0000 - val_tn: 588.0000 - val_fn: 158.0000 - val_accuracy: 0.6940 - val_precision: 0.5129 - val_recall: 0.5574 - val_auc: 0.7066 - val_prc: 0.5459\n",
      "Epoch 26/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0425 - tp: 1392.0000 - fp: 31.0000 - tn: 3076.0000 - fn: 37.0000 - accuracy: 0.9850 - precision: 0.9782 - recall: 0.9741 - auc: 0.9989 - prc: 0.9977 - val_loss: 1.4514 - val_tp: 138.0000 - val_fp: 80.0000 - val_tn: 697.0000 - val_fn: 219.0000 - val_accuracy: 0.7363 - val_precision: 0.6330 - val_recall: 0.3866 - val_auc: 0.6914 - val_prc: 0.5364\n",
      "Epoch 27/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0595 - tp: 1369.0000 - fp: 40.0000 - tn: 3067.0000 - fn: 60.0000 - accuracy: 0.9780 - precision: 0.9716 - recall: 0.9580 - auc: 0.9971 - prc: 0.9941 - val_loss: 1.2903 - val_tp: 182.0000 - val_fp: 163.0000 - val_tn: 614.0000 - val_fn: 175.0000 - val_accuracy: 0.7019 - val_precision: 0.5275 - val_recall: 0.5098 - val_auc: 0.6999 - val_prc: 0.5379\n",
      "Epoch 28/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0472 - tp: 1382.0000 - fp: 35.0000 - tn: 3072.0000 - fn: 47.0000 - accuracy: 0.9819 - precision: 0.9753 - recall: 0.9671 - auc: 0.9980 - prc: 0.9958 - val_loss: 1.3060 - val_tp: 174.0000 - val_fp: 154.0000 - val_tn: 623.0000 - val_fn: 183.0000 - val_accuracy: 0.7028 - val_precision: 0.5305 - val_recall: 0.4874 - val_auc: 0.6999 - val_prc: 0.5390\n",
      "Epoch 29/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0382 - tp: 1388.0000 - fp: 29.0000 - tn: 3078.0000 - fn: 41.0000 - accuracy: 0.9846 - precision: 0.9795 - recall: 0.9713 - auc: 0.9989 - prc: 0.9971 - val_loss: 1.4141 - val_tp: 146.0000 - val_fp: 102.0000 - val_tn: 675.0000 - val_fn: 211.0000 - val_accuracy: 0.7240 - val_precision: 0.5887 - val_recall: 0.4090 - val_auc: 0.6939 - val_prc: 0.5384\n",
      "Epoch 30/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0461 - tp: 1383.0000 - fp: 31.0000 - tn: 3076.0000 - fn: 46.0000 - accuracy: 0.9830 - precision: 0.9781 - recall: 0.9678 - auc: 0.9981 - prc: 0.9967 - val_loss: 1.3974 - val_tp: 144.0000 - val_fp: 97.0000 - val_tn: 680.0000 - val_fn: 213.0000 - val_accuracy: 0.7266 - val_precision: 0.5975 - val_recall: 0.4034 - val_auc: 0.6958 - val_prc: 0.5392\n",
      "Epoch 31/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0409 - tp: 1391.0000 - fp: 35.0000 - tn: 3072.0000 - fn: 38.0000 - accuracy: 0.9839 - precision: 0.9755 - recall: 0.9734 - auc: 0.9985 - prc: 0.9974 - val_loss: 1.4032 - val_tp: 166.0000 - val_fp: 132.0000 - val_tn: 645.0000 - val_fn: 191.0000 - val_accuracy: 0.7152 - val_precision: 0.5570 - val_recall: 0.4650 - val_auc: 0.7001 - val_prc: 0.5406\n",
      "Epoch 32/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0377 - tp: 1386.0000 - fp: 29.0000 - tn: 3078.0000 - fn: 43.0000 - accuracy: 0.9841 - precision: 0.9795 - recall: 0.9699 - auc: 0.9990 - prc: 0.9980 - val_loss: 1.4064 - val_tp: 151.0000 - val_fp: 113.0000 - val_tn: 664.0000 - val_fn: 206.0000 - val_accuracy: 0.7187 - val_precision: 0.5720 - val_recall: 0.4230 - val_auc: 0.6960 - val_prc: 0.5411\n",
      "Epoch 33/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0369 - tp: 1384.0000 - fp: 32.0000 - tn: 3075.0000 - fn: 45.0000 - accuracy: 0.9830 - precision: 0.9774 - recall: 0.9685 - auc: 0.9991 - prc: 0.9981 - val_loss: 1.4008 - val_tp: 174.0000 - val_fp: 150.0000 - val_tn: 627.0000 - val_fn: 183.0000 - val_accuracy: 0.7063 - val_precision: 0.5370 - val_recall: 0.4874 - val_auc: 0.7032 - val_prc: 0.5388\n",
      "Epoch 34/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0421 - tp: 1381.0000 - fp: 33.0000 - tn: 3074.0000 - fn: 48.0000 - accuracy: 0.9821 - precision: 0.9767 - recall: 0.9664 - auc: 0.9988 - prc: 0.9975 - val_loss: 1.4855 - val_tp: 153.0000 - val_fp: 106.0000 - val_tn: 671.0000 - val_fn: 204.0000 - val_accuracy: 0.7266 - val_precision: 0.5907 - val_recall: 0.4286 - val_auc: 0.6977 - val_prc: 0.5412\n",
      "Epoch 35/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0392 - tp: 1387.0000 - fp: 27.0000 - tn: 3080.0000 - fn: 42.0000 - accuracy: 0.9848 - precision: 0.9809 - recall: 0.9706 - auc: 0.9989 - prc: 0.9977 - val_loss: 1.5156 - val_tp: 147.0000 - val_fp: 99.0000 - val_tn: 678.0000 - val_fn: 210.0000 - val_accuracy: 0.7275 - val_precision: 0.5976 - val_recall: 0.4118 - val_auc: 0.6937 - val_prc: 0.5394\n",
      "Epoch 36/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0426 - tp: 1381.0000 - fp: 29.0000 - tn: 3078.0000 - fn: 48.0000 - accuracy: 0.9830 - precision: 0.9794 - recall: 0.9664 - auc: 0.9987 - prc: 0.9973 - val_loss: 1.4863 - val_tp: 186.0000 - val_fp: 178.0000 - val_tn: 599.0000 - val_fn: 171.0000 - val_accuracy: 0.6922 - val_precision: 0.5110 - val_recall: 0.5210 - val_auc: 0.7038 - val_prc: 0.5342\n",
      "Epoch 37/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0436 - tp: 1384.0000 - fp: 37.0000 - tn: 3070.0000 - fn: 45.0000 - accuracy: 0.9819 - precision: 0.9740 - recall: 0.9685 - auc: 0.9987 - prc: 0.9973 - val_loss: 1.4589 - val_tp: 158.0000 - val_fp: 123.0000 - val_tn: 654.0000 - val_fn: 199.0000 - val_accuracy: 0.7160 - val_precision: 0.5623 - val_recall: 0.4426 - val_auc: 0.6971 - val_prc: 0.5399\n",
      "Epoch 38/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0356 - tp: 1386.0000 - fp: 27.0000 - tn: 3080.0000 - fn: 43.0000 - accuracy: 0.9846 - precision: 0.9809 - recall: 0.9699 - auc: 0.9991 - prc: 0.9981 - val_loss: 1.5392 - val_tp: 200.0000 - val_fp: 207.0000 - val_tn: 570.0000 - val_fn: 157.0000 - val_accuracy: 0.6790 - val_precision: 0.4914 - val_recall: 0.5602 - val_auc: 0.7040 - val_prc: 0.5310\n",
      "Epoch 39/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0363 - tp: 1394.0000 - fp: 28.0000 - tn: 3079.0000 - fn: 35.0000 - accuracy: 0.9861 - precision: 0.9803 - recall: 0.9755 - auc: 0.9990 - prc: 0.9980 - val_loss: 1.5009 - val_tp: 202.0000 - val_fp: 209.0000 - val_tn: 568.0000 - val_fn: 155.0000 - val_accuracy: 0.6790 - val_precision: 0.4915 - val_recall: 0.5658 - val_auc: 0.7035 - val_prc: 0.5310\n",
      "Epoch 40/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0332 - tp: 1388.0000 - fp: 30.0000 - tn: 3077.0000 - fn: 41.0000 - accuracy: 0.9843 - precision: 0.9788 - recall: 0.9713 - auc: 0.9992 - prc: 0.9984 - val_loss: 1.5059 - val_tp: 159.0000 - val_fp: 130.0000 - val_tn: 647.0000 - val_fn: 198.0000 - val_accuracy: 0.7108 - val_precision: 0.5502 - val_recall: 0.4454 - val_auc: 0.6984 - val_prc: 0.5382\n",
      "Epoch 41/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0327 - tp: 1390.0000 - fp: 31.0000 - tn: 3076.0000 - fn: 39.0000 - accuracy: 0.9846 - precision: 0.9782 - recall: 0.9727 - auc: 0.9993 - prc: 0.9985 - val_loss: 1.4944 - val_tp: 181.0000 - val_fp: 171.0000 - val_tn: 606.0000 - val_fn: 176.0000 - val_accuracy: 0.6940 - val_precision: 0.5142 - val_recall: 0.5070 - val_auc: 0.7014 - val_prc: 0.5344\n",
      "Epoch 42/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0342 - tp: 1390.0000 - fp: 31.0000 - tn: 3076.0000 - fn: 39.0000 - accuracy: 0.9846 - precision: 0.9782 - recall: 0.9727 - auc: 0.9992 - prc: 0.9983 - val_loss: 1.5306 - val_tp: 180.0000 - val_fp: 167.0000 - val_tn: 610.0000 - val_fn: 177.0000 - val_accuracy: 0.6966 - val_precision: 0.5187 - val_recall: 0.5042 - val_auc: 0.7049 - val_prc: 0.5437\n",
      "Epoch 43/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0326 - tp: 1393.0000 - fp: 31.0000 - tn: 3076.0000 - fn: 36.0000 - accuracy: 0.9852 - precision: 0.9782 - recall: 0.9748 - auc: 0.9993 - prc: 0.9985 - val_loss: 1.5390 - val_tp: 176.0000 - val_fp: 151.0000 - val_tn: 626.0000 - val_fn: 181.0000 - val_accuracy: 0.7072 - val_precision: 0.5382 - val_recall: 0.4930 - val_auc: 0.7000 - val_prc: 0.5387\n",
      "Epoch 44/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0342 - tp: 1393.0000 - fp: 30.0000 - tn: 3077.0000 - fn: 36.0000 - accuracy: 0.9854 - precision: 0.9789 - recall: 0.9748 - auc: 0.9992 - prc: 0.9983 - val_loss: 1.6054 - val_tp: 139.0000 - val_fp: 97.0000 - val_tn: 680.0000 - val_fn: 218.0000 - val_accuracy: 0.7222 - val_precision: 0.5890 - val_recall: 0.3894 - val_auc: 0.6906 - val_prc: 0.5335\n",
      "Epoch 45/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0356 - tp: 1391.0000 - fp: 26.0000 - tn: 3081.0000 - fn: 38.0000 - accuracy: 0.9859 - precision: 0.9817 - recall: 0.9734 - auc: 0.9991 - prc: 0.9981 - val_loss: 1.6779 - val_tp: 136.0000 - val_fp: 91.0000 - val_tn: 686.0000 - val_fn: 221.0000 - val_accuracy: 0.7249 - val_precision: 0.5991 - val_recall: 0.3810 - val_auc: 0.6880 - val_prc: 0.5314\n",
      "Epoch 46/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0361 - tp: 1386.0000 - fp: 36.0000 - tn: 3071.0000 - fn: 43.0000 - accuracy: 0.9826 - precision: 0.9747 - recall: 0.9699 - auc: 0.9991 - prc: 0.9982 - val_loss: 1.5498 - val_tp: 170.0000 - val_fp: 147.0000 - val_tn: 630.0000 - val_fn: 187.0000 - val_accuracy: 0.7055 - val_precision: 0.5363 - val_recall: 0.4762 - val_auc: 0.7001 - val_prc: 0.5365\n",
      "Epoch 47/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0322 - tp: 1390.0000 - fp: 27.0000 - tn: 3080.0000 - fn: 39.0000 - accuracy: 0.9854 - precision: 0.9809 - recall: 0.9727 - auc: 0.9990 - prc: 0.9983 - val_loss: 1.6349 - val_tp: 147.0000 - val_fp: 109.0000 - val_tn: 668.0000 - val_fn: 210.0000 - val_accuracy: 0.7187 - val_precision: 0.5742 - val_recall: 0.4118 - val_auc: 0.6938 - val_prc: 0.5342\n",
      "Epoch 48/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0313 - tp: 1395.0000 - fp: 30.0000 - tn: 3077.0000 - fn: 34.0000 - accuracy: 0.9859 - precision: 0.9789 - recall: 0.9762 - auc: 0.9993 - prc: 0.9986 - val_loss: 1.6223 - val_tp: 160.0000 - val_fp: 128.0000 - val_tn: 649.0000 - val_fn: 197.0000 - val_accuracy: 0.7134 - val_precision: 0.5556 - val_recall: 0.4482 - val_auc: 0.6937 - val_prc: 0.5353\n",
      "Epoch 49/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0328 - tp: 1395.0000 - fp: 33.0000 - tn: 3074.0000 - fn: 34.0000 - accuracy: 0.9852 - precision: 0.9769 - recall: 0.9762 - auc: 0.9993 - prc: 0.9985 - val_loss: 1.5567 - val_tp: 160.0000 - val_fp: 122.0000 - val_tn: 655.0000 - val_fn: 197.0000 - val_accuracy: 0.7187 - val_precision: 0.5674 - val_recall: 0.4482 - val_auc: 0.6949 - val_prc: 0.5363\n",
      "Epoch 50/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0327 - tp: 1391.0000 - fp: 26.0000 - tn: 3081.0000 - fn: 38.0000 - accuracy: 0.9859 - precision: 0.9817 - recall: 0.9734 - auc: 0.9989 - prc: 0.9982 - val_loss: 1.5636 - val_tp: 166.0000 - val_fp: 133.0000 - val_tn: 644.0000 - val_fn: 191.0000 - val_accuracy: 0.7143 - val_precision: 0.5552 - val_recall: 0.4650 - val_auc: 0.6988 - val_prc: 0.5347\n",
      "Epoch 51/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0312 - tp: 1398.0000 - fp: 32.0000 - tn: 3075.0000 - fn: 31.0000 - accuracy: 0.9861 - precision: 0.9776 - recall: 0.9783 - auc: 0.9994 - prc: 0.9987 - val_loss: 1.7367 - val_tp: 135.0000 - val_fp: 88.0000 - val_tn: 689.0000 - val_fn: 222.0000 - val_accuracy: 0.7266 - val_precision: 0.6054 - val_recall: 0.3782 - val_auc: 0.6852 - val_prc: 0.5311\n",
      "Epoch 52/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0407 - tp: 1384.0000 - fp: 31.0000 - tn: 3076.0000 - fn: 45.0000 - accuracy: 0.9832 - precision: 0.9781 - recall: 0.9685 - auc: 0.9988 - prc: 0.9976 - val_loss: 1.5791 - val_tp: 207.0000 - val_fp: 210.0000 - val_tn: 567.0000 - val_fn: 150.0000 - val_accuracy: 0.6825 - val_precision: 0.4964 - val_recall: 0.5798 - val_auc: 0.7031 - val_prc: 0.5252\n",
      "Epoch 53/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0331 - tp: 1386.0000 - fp: 27.0000 - tn: 3080.0000 - fn: 43.0000 - accuracy: 0.9846 - precision: 0.9809 - recall: 0.9699 - auc: 0.9993 - prc: 0.9984 - val_loss: 1.7661 - val_tp: 142.0000 - val_fp: 101.0000 - val_tn: 676.0000 - val_fn: 215.0000 - val_accuracy: 0.7213 - val_precision: 0.5844 - val_recall: 0.3978 - val_auc: 0.6910 - val_prc: 0.5286\n",
      "Epoch 54/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0320 - tp: 1393.0000 - fp: 30.0000 - tn: 3077.0000 - fn: 36.0000 - accuracy: 0.9854 - precision: 0.9789 - recall: 0.9748 - auc: 0.9993 - prc: 0.9985 - val_loss: 1.5923 - val_tp: 196.0000 - val_fp: 189.0000 - val_tn: 588.0000 - val_fn: 161.0000 - val_accuracy: 0.6914 - val_precision: 0.5091 - val_recall: 0.5490 - val_auc: 0.7005 - val_prc: 0.5282\n",
      "Epoch 55/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0270 - tp: 1399.0000 - fp: 28.0000 - tn: 3079.0000 - fn: 30.0000 - accuracy: 0.9872 - precision: 0.9804 - recall: 0.9790 - auc: 0.9995 - prc: 0.9989 - val_loss: 1.6658 - val_tp: 152.0000 - val_fp: 114.0000 - val_tn: 663.0000 - val_fn: 205.0000 - val_accuracy: 0.7187 - val_precision: 0.5714 - val_recall: 0.4258 - val_auc: 0.6876 - val_prc: 0.5255\n",
      "Epoch 56/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0301 - tp: 1395.0000 - fp: 30.0000 - tn: 3077.0000 - fn: 34.0000 - accuracy: 0.9859 - precision: 0.9789 - recall: 0.9762 - auc: 0.9994 - prc: 0.9987 - val_loss: 1.6944 - val_tp: 153.0000 - val_fp: 119.0000 - val_tn: 658.0000 - val_fn: 204.0000 - val_accuracy: 0.7152 - val_precision: 0.5625 - val_recall: 0.4286 - val_auc: 0.6884 - val_prc: 0.5250\n",
      "Epoch 57/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0304 - tp: 1390.0000 - fp: 25.0000 - tn: 3082.0000 - fn: 39.0000 - accuracy: 0.9859 - precision: 0.9823 - recall: 0.9727 - auc: 0.9994 - prc: 0.9986 - val_loss: 1.6376 - val_tp: 188.0000 - val_fp: 180.0000 - val_tn: 597.0000 - val_fn: 169.0000 - val_accuracy: 0.6922 - val_precision: 0.5109 - val_recall: 0.5266 - val_auc: 0.7021 - val_prc: 0.5235\n",
      "Epoch 58/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0305 - tp: 1393.0000 - fp: 24.0000 - tn: 3083.0000 - fn: 36.0000 - accuracy: 0.9868 - precision: 0.9831 - recall: 0.9748 - auc: 0.9994 - prc: 0.9987 - val_loss: 1.7155 - val_tp: 216.0000 - val_fp: 240.0000 - val_tn: 537.0000 - val_fn: 141.0000 - val_accuracy: 0.6640 - val_precision: 0.4737 - val_recall: 0.6050 - val_auc: 0.6968 - val_prc: 0.5070\n",
      "Epoch 59/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0257 - tp: 1400.0000 - fp: 22.0000 - tn: 3085.0000 - fn: 29.0000 - accuracy: 0.9888 - precision: 0.9845 - recall: 0.9797 - auc: 0.9996 - prc: 0.9991 - val_loss: 1.8349 - val_tp: 150.0000 - val_fp: 113.0000 - val_tn: 664.0000 - val_fn: 207.0000 - val_accuracy: 0.7178 - val_precision: 0.5703 - val_recall: 0.4202 - val_auc: 0.6878 - val_prc: 0.5256\n",
      "Epoch 60/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0311 - tp: 1389.0000 - fp: 22.0000 - tn: 3085.0000 - fn: 40.0000 - accuracy: 0.9863 - precision: 0.9844 - recall: 0.9720 - auc: 0.9986 - prc: 0.9981 - val_loss: 1.6883 - val_tp: 160.0000 - val_fp: 141.0000 - val_tn: 636.0000 - val_fn: 197.0000 - val_accuracy: 0.7019 - val_precision: 0.5316 - val_recall: 0.4482 - val_auc: 0.6938 - val_prc: 0.5225\n",
      "Epoch 61/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0277 - tp: 1394.0000 - fp: 27.0000 - tn: 3080.0000 - fn: 35.0000 - accuracy: 0.9863 - precision: 0.9810 - recall: 0.9755 - auc: 0.9995 - prc: 0.9989 - val_loss: 1.7376 - val_tp: 148.0000 - val_fp: 109.0000 - val_tn: 668.0000 - val_fn: 209.0000 - val_accuracy: 0.7196 - val_precision: 0.5759 - val_recall: 0.4146 - val_auc: 0.6895 - val_prc: 0.5279\n",
      "Epoch 62/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0298 - tp: 1391.0000 - fp: 25.0000 - tn: 3082.0000 - fn: 38.0000 - accuracy: 0.9861 - precision: 0.9823 - recall: 0.9734 - auc: 0.9994 - prc: 0.9987 - val_loss: 1.6943 - val_tp: 159.0000 - val_fp: 122.0000 - val_tn: 655.0000 - val_fn: 198.0000 - val_accuracy: 0.7178 - val_precision: 0.5658 - val_recall: 0.4454 - val_auc: 0.6907 - val_prc: 0.5247\n",
      "Epoch 63/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0277 - tp: 1390.0000 - fp: 26.0000 - tn: 3081.0000 - fn: 39.0000 - accuracy: 0.9857 - precision: 0.9816 - recall: 0.9727 - auc: 0.9995 - prc: 0.9989 - val_loss: 1.8024 - val_tp: 139.0000 - val_fp: 95.0000 - val_tn: 682.0000 - val_fn: 218.0000 - val_accuracy: 0.7240 - val_precision: 0.5940 - val_recall: 0.3894 - val_auc: 0.6838 - val_prc: 0.5255\n",
      "Epoch 64/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0259 - tp: 1399.0000 - fp: 27.0000 - tn: 3080.0000 - fn: 30.0000 - accuracy: 0.9874 - precision: 0.9811 - recall: 0.9790 - auc: 0.9995 - prc: 0.9990 - val_loss: 1.7607 - val_tp: 155.0000 - val_fp: 114.0000 - val_tn: 663.0000 - val_fn: 202.0000 - val_accuracy: 0.7213 - val_precision: 0.5762 - val_recall: 0.4342 - val_auc: 0.6905 - val_prc: 0.5264\n",
      "Epoch 65/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0323 - tp: 1392.0000 - fp: 31.0000 - tn: 3076.0000 - fn: 37.0000 - accuracy: 0.9850 - precision: 0.9782 - recall: 0.9741 - auc: 0.9993 - prc: 0.9985 - val_loss: 1.6869 - val_tp: 181.0000 - val_fp: 170.0000 - val_tn: 607.0000 - val_fn: 176.0000 - val_accuracy: 0.6949 - val_precision: 0.5157 - val_recall: 0.5070 - val_auc: 0.6932 - val_prc: 0.5277\n",
      "Epoch 66/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0274 - tp: 1390.0000 - fp: 25.0000 - tn: 3082.0000 - fn: 39.0000 - accuracy: 0.9859 - precision: 0.9823 - recall: 0.9727 - auc: 0.9994 - prc: 0.9988 - val_loss: 2.0352 - val_tp: 129.0000 - val_fp: 79.0000 - val_tn: 698.0000 - val_fn: 228.0000 - val_accuracy: 0.7293 - val_precision: 0.6202 - val_recall: 0.3613 - val_auc: 0.6769 - val_prc: 0.5197\n",
      "Epoch 67/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0278 - tp: 1388.0000 - fp: 29.0000 - tn: 3078.0000 - fn: 41.0000 - accuracy: 0.9846 - precision: 0.9795 - recall: 0.9713 - auc: 0.9994 - prc: 0.9988 - val_loss: 1.7905 - val_tp: 180.0000 - val_fp: 167.0000 - val_tn: 610.0000 - val_fn: 177.0000 - val_accuracy: 0.6966 - val_precision: 0.5187 - val_recall: 0.5042 - val_auc: 0.6947 - val_prc: 0.5246\n",
      "Epoch 68/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0285 - tp: 1393.0000 - fp: 26.0000 - tn: 3081.0000 - fn: 36.0000 - accuracy: 0.9863 - precision: 0.9817 - recall: 0.9748 - auc: 0.9994 - prc: 0.9988 - val_loss: 1.7996 - val_tp: 208.0000 - val_fp: 213.0000 - val_tn: 564.0000 - val_fn: 149.0000 - val_accuracy: 0.6808 - val_precision: 0.4941 - val_recall: 0.5826 - val_auc: 0.6979 - val_prc: 0.5082\n",
      "Epoch 69/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0265 - tp: 1394.0000 - fp: 24.0000 - tn: 3083.0000 - fn: 35.0000 - accuracy: 0.9870 - precision: 0.9831 - recall: 0.9755 - auc: 0.9995 - prc: 0.9989 - val_loss: 1.7422 - val_tp: 169.0000 - val_fp: 159.0000 - val_tn: 618.0000 - val_fn: 188.0000 - val_accuracy: 0.6940 - val_precision: 0.5152 - val_recall: 0.4734 - val_auc: 0.6930 - val_prc: 0.5289\n",
      "Epoch 70/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0243 - tp: 1398.0000 - fp: 26.0000 - tn: 3081.0000 - fn: 31.0000 - accuracy: 0.9874 - precision: 0.9817 - recall: 0.9783 - auc: 0.9996 - prc: 0.9991 - val_loss: 1.7991 - val_tp: 163.0000 - val_fp: 141.0000 - val_tn: 636.0000 - val_fn: 194.0000 - val_accuracy: 0.7046 - val_precision: 0.5362 - val_recall: 0.4566 - val_auc: 0.6863 - val_prc: 0.5239\n",
      "Epoch 71/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0277 - tp: 1391.0000 - fp: 26.0000 - tn: 3081.0000 - fn: 38.0000 - accuracy: 0.9859 - precision: 0.9817 - recall: 0.9734 - auc: 0.9994 - prc: 0.9988 - val_loss: 1.7215 - val_tp: 213.0000 - val_fp: 228.0000 - val_tn: 549.0000 - val_fn: 144.0000 - val_accuracy: 0.6720 - val_precision: 0.4830 - val_recall: 0.5966 - val_auc: 0.6995 - val_prc: 0.5150\n",
      "Epoch 72/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0254 - tp: 1398.0000 - fp: 29.0000 - tn: 3078.0000 - fn: 31.0000 - accuracy: 0.9868 - precision: 0.9797 - recall: 0.9783 - auc: 0.9995 - prc: 0.9990 - val_loss: 1.8483 - val_tp: 170.0000 - val_fp: 155.0000 - val_tn: 622.0000 - val_fn: 187.0000 - val_accuracy: 0.6984 - val_precision: 0.5231 - val_recall: 0.4762 - val_auc: 0.6896 - val_prc: 0.5213\n",
      "Epoch 73/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0261 - tp: 1393.0000 - fp: 30.0000 - tn: 3077.0000 - fn: 36.0000 - accuracy: 0.9854 - precision: 0.9789 - recall: 0.9748 - auc: 0.9995 - prc: 0.9989 - val_loss: 1.8245 - val_tp: 165.0000 - val_fp: 145.0000 - val_tn: 632.0000 - val_fn: 192.0000 - val_accuracy: 0.7028 - val_precision: 0.5323 - val_recall: 0.4622 - val_auc: 0.6869 - val_prc: 0.5231\n",
      "Epoch 74/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0238 - tp: 1399.0000 - fp: 30.0000 - tn: 3077.0000 - fn: 30.0000 - accuracy: 0.9868 - precision: 0.9790 - recall: 0.9790 - auc: 0.9996 - prc: 0.9991 - val_loss: 1.9015 - val_tp: 166.0000 - val_fp: 151.0000 - val_tn: 626.0000 - val_fn: 191.0000 - val_accuracy: 0.6984 - val_precision: 0.5237 - val_recall: 0.4650 - val_auc: 0.6886 - val_prc: 0.5250\n",
      "Epoch 75/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0245 - tp: 1396.0000 - fp: 27.0000 - tn: 3080.0000 - fn: 33.0000 - accuracy: 0.9868 - precision: 0.9810 - recall: 0.9769 - auc: 0.9995 - prc: 0.9990 - val_loss: 1.8235 - val_tp: 168.0000 - val_fp: 146.0000 - val_tn: 631.0000 - val_fn: 189.0000 - val_accuracy: 0.7046 - val_precision: 0.5350 - val_recall: 0.4706 - val_auc: 0.6902 - val_prc: 0.5244\n",
      "Epoch 76/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0237 - tp: 1395.0000 - fp: 23.0000 - tn: 3084.0000 - fn: 34.0000 - accuracy: 0.9874 - precision: 0.9838 - recall: 0.9762 - auc: 0.9996 - prc: 0.9991 - val_loss: 1.9181 - val_tp: 160.0000 - val_fp: 132.0000 - val_tn: 645.0000 - val_fn: 197.0000 - val_accuracy: 0.7099 - val_precision: 0.5479 - val_recall: 0.4482 - val_auc: 0.6866 - val_prc: 0.5239\n",
      "Epoch 77/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0238 - tp: 1397.0000 - fp: 25.0000 - tn: 3082.0000 - fn: 32.0000 - accuracy: 0.9874 - precision: 0.9824 - recall: 0.9776 - auc: 0.9996 - prc: 0.9991 - val_loss: 1.8754 - val_tp: 212.0000 - val_fp: 218.0000 - val_tn: 559.0000 - val_fn: 145.0000 - val_accuracy: 0.6799 - val_precision: 0.4930 - val_recall: 0.5938 - val_auc: 0.6958 - val_prc: 0.5030\n",
      "Epoch 78/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0239 - tp: 1396.0000 - fp: 25.0000 - tn: 3082.0000 - fn: 33.0000 - accuracy: 0.9872 - precision: 0.9824 - recall: 0.9769 - auc: 0.9996 - prc: 0.9991 - val_loss: 1.8953 - val_tp: 196.0000 - val_fp: 196.0000 - val_tn: 581.0000 - val_fn: 161.0000 - val_accuracy: 0.6852 - val_precision: 0.5000 - val_recall: 0.5490 - val_auc: 0.6919 - val_prc: 0.5051\n",
      "Epoch 79/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0219 - tp: 1399.0000 - fp: 25.0000 - tn: 3082.0000 - fn: 30.0000 - accuracy: 0.9879 - precision: 0.9824 - recall: 0.9790 - auc: 0.9996 - prc: 0.9992 - val_loss: 1.9152 - val_tp: 182.0000 - val_fp: 165.0000 - val_tn: 612.0000 - val_fn: 175.0000 - val_accuracy: 0.7002 - val_precision: 0.5245 - val_recall: 0.5098 - val_auc: 0.6904 - val_prc: 0.5197\n",
      "Epoch 80/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0224 - tp: 1397.0000 - fp: 26.0000 - tn: 3081.0000 - fn: 32.0000 - accuracy: 0.9872 - precision: 0.9817 - recall: 0.9776 - auc: 0.9996 - prc: 0.9991 - val_loss: 2.0133 - val_tp: 200.0000 - val_fp: 196.0000 - val_tn: 581.0000 - val_fn: 157.0000 - val_accuracy: 0.6887 - val_precision: 0.5051 - val_recall: 0.5602 - val_auc: 0.6885 - val_prc: 0.4966\n",
      "Epoch 81/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0232 - tp: 1405.0000 - fp: 32.0000 - tn: 3075.0000 - fn: 24.0000 - accuracy: 0.9877 - precision: 0.9777 - recall: 0.9832 - auc: 0.9996 - prc: 0.9991 - val_loss: 1.9591 - val_tp: 169.0000 - val_fp: 150.0000 - val_tn: 627.0000 - val_fn: 188.0000 - val_accuracy: 0.7019 - val_precision: 0.5298 - val_recall: 0.4734 - val_auc: 0.6892 - val_prc: 0.5239\n",
      "Epoch 82/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0231 - tp: 1391.0000 - fp: 23.0000 - tn: 3084.0000 - fn: 38.0000 - accuracy: 0.9866 - precision: 0.9837 - recall: 0.9734 - auc: 0.9996 - prc: 0.9991 - val_loss: 1.9326 - val_tp: 169.0000 - val_fp: 145.0000 - val_tn: 632.0000 - val_fn: 188.0000 - val_accuracy: 0.7063 - val_precision: 0.5382 - val_recall: 0.4734 - val_auc: 0.6899 - val_prc: 0.5241\n",
      "Epoch 83/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0231 - tp: 1393.0000 - fp: 25.0000 - tn: 3082.0000 - fn: 36.0000 - accuracy: 0.9866 - precision: 0.9824 - recall: 0.9748 - auc: 0.9996 - prc: 0.9991 - val_loss: 1.9912 - val_tp: 161.0000 - val_fp: 128.0000 - val_tn: 649.0000 - val_fn: 196.0000 - val_accuracy: 0.7143 - val_precision: 0.5571 - val_recall: 0.4510 - val_auc: 0.6876 - val_prc: 0.5219\n",
      "Epoch 84/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0209 - tp: 1399.0000 - fp: 28.0000 - tn: 3079.0000 - fn: 30.0000 - accuracy: 0.9872 - precision: 0.9804 - recall: 0.9790 - auc: 0.9996 - prc: 0.9992 - val_loss: 2.0620 - val_tp: 166.0000 - val_fp: 148.0000 - val_tn: 629.0000 - val_fn: 191.0000 - val_accuracy: 0.7011 - val_precision: 0.5287 - val_recall: 0.4650 - val_auc: 0.6869 - val_prc: 0.5204\n",
      "Epoch 85/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0230 - tp: 1393.0000 - fp: 22.0000 - tn: 3085.0000 - fn: 36.0000 - accuracy: 0.9872 - precision: 0.9845 - recall: 0.9748 - auc: 0.9996 - prc: 0.9991 - val_loss: 2.1740 - val_tp: 145.0000 - val_fp: 107.0000 - val_tn: 670.0000 - val_fn: 212.0000 - val_accuracy: 0.7187 - val_precision: 0.5754 - val_recall: 0.4062 - val_auc: 0.6783 - val_prc: 0.5214\n",
      "Epoch 86/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0210 - tp: 1398.0000 - fp: 24.0000 - tn: 3083.0000 - fn: 31.0000 - accuracy: 0.9879 - precision: 0.9831 - recall: 0.9783 - auc: 0.9997 - prc: 0.9993 - val_loss: 2.1012 - val_tp: 180.0000 - val_fp: 163.0000 - val_tn: 614.0000 - val_fn: 177.0000 - val_accuracy: 0.7002 - val_precision: 0.5248 - val_recall: 0.5042 - val_auc: 0.6888 - val_prc: 0.5113\n",
      "Epoch 87/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0204 - tp: 1394.0000 - fp: 23.0000 - tn: 3084.0000 - fn: 35.0000 - accuracy: 0.9872 - precision: 0.9838 - recall: 0.9755 - auc: 0.9996 - prc: 0.9992 - val_loss: 2.0881 - val_tp: 202.0000 - val_fp: 201.0000 - val_tn: 576.0000 - val_fn: 155.0000 - val_accuracy: 0.6861 - val_precision: 0.5012 - val_recall: 0.5658 - val_auc: 0.6871 - val_prc: 0.4932\n",
      "Epoch 88/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0215 - tp: 1395.0000 - fp: 26.0000 - tn: 3081.0000 - fn: 34.0000 - accuracy: 0.9868 - precision: 0.9817 - recall: 0.9762 - auc: 0.9996 - prc: 0.9992 - val_loss: 2.1086 - val_tp: 168.0000 - val_fp: 144.0000 - val_tn: 633.0000 - val_fn: 189.0000 - val_accuracy: 0.7063 - val_precision: 0.5385 - val_recall: 0.4706 - val_auc: 0.6888 - val_prc: 0.5165\n",
      "Epoch 89/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0215 - tp: 1399.0000 - fp: 28.0000 - tn: 3079.0000 - fn: 30.0000 - accuracy: 0.9872 - precision: 0.9804 - recall: 0.9790 - auc: 0.9996 - prc: 0.9992 - val_loss: 2.1830 - val_tp: 181.0000 - val_fp: 165.0000 - val_tn: 612.0000 - val_fn: 176.0000 - val_accuracy: 0.6993 - val_precision: 0.5231 - val_recall: 0.5070 - val_auc: 0.6851 - val_prc: 0.5071\n",
      "Epoch 90/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0217 - tp: 1392.0000 - fp: 26.0000 - tn: 3081.0000 - fn: 37.0000 - accuracy: 0.9861 - precision: 0.9817 - recall: 0.9741 - auc: 0.9996 - prc: 0.9991 - val_loss: 2.1752 - val_tp: 160.0000 - val_fp: 131.0000 - val_tn: 646.0000 - val_fn: 197.0000 - val_accuracy: 0.7108 - val_precision: 0.5498 - val_recall: 0.4482 - val_auc: 0.6804 - val_prc: 0.5138\n",
      "Epoch 91/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0206 - tp: 1400.0000 - fp: 21.0000 - tn: 3086.0000 - fn: 29.0000 - accuracy: 0.9890 - precision: 0.9852 - recall: 0.9797 - auc: 0.9997 - prc: 0.9993 - val_loss: 2.2480 - val_tp: 156.0000 - val_fp: 124.0000 - val_tn: 653.0000 - val_fn: 201.0000 - val_accuracy: 0.7134 - val_precision: 0.5571 - val_recall: 0.4370 - val_auc: 0.6781 - val_prc: 0.5116\n",
      "Epoch 92/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0200 - tp: 1395.0000 - fp: 22.0000 - tn: 3085.0000 - fn: 34.0000 - accuracy: 0.9877 - precision: 0.9845 - recall: 0.9762 - auc: 0.9997 - prc: 0.9993 - val_loss: 2.0950 - val_tp: 171.0000 - val_fp: 156.0000 - val_tn: 621.0000 - val_fn: 186.0000 - val_accuracy: 0.6984 - val_precision: 0.5229 - val_recall: 0.4790 - val_auc: 0.6878 - val_prc: 0.5141\n",
      "Epoch 93/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0198 - tp: 1402.0000 - fp: 31.0000 - tn: 3076.0000 - fn: 27.0000 - accuracy: 0.9872 - precision: 0.9784 - recall: 0.9811 - auc: 0.9996 - prc: 0.9992 - val_loss: 2.2247 - val_tp: 160.0000 - val_fp: 139.0000 - val_tn: 638.0000 - val_fn: 197.0000 - val_accuracy: 0.7037 - val_precision: 0.5351 - val_recall: 0.4482 - val_auc: 0.6790 - val_prc: 0.5127\n",
      "Epoch 94/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0207 - tp: 1399.0000 - fp: 23.0000 - tn: 3084.0000 - fn: 30.0000 - accuracy: 0.9883 - precision: 0.9838 - recall: 0.9790 - auc: 0.9996 - prc: 0.9992 - val_loss: 2.1839 - val_tp: 199.0000 - val_fp: 193.0000 - val_tn: 584.0000 - val_fn: 158.0000 - val_accuracy: 0.6905 - val_precision: 0.5077 - val_recall: 0.5574 - val_auc: 0.6894 - val_prc: 0.4993\n",
      "Epoch 95/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0208 - tp: 1394.0000 - fp: 23.0000 - tn: 3084.0000 - fn: 35.0000 - accuracy: 0.9872 - precision: 0.9838 - recall: 0.9755 - auc: 0.9996 - prc: 0.9992 - val_loss: 2.3025 - val_tp: 159.0000 - val_fp: 130.0000 - val_tn: 647.0000 - val_fn: 198.0000 - val_accuracy: 0.7108 - val_precision: 0.5502 - val_recall: 0.4454 - val_auc: 0.6787 - val_prc: 0.5084\n",
      "Epoch 96/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0201 - tp: 1396.0000 - fp: 24.0000 - tn: 3083.0000 - fn: 33.0000 - accuracy: 0.9874 - precision: 0.9831 - recall: 0.9769 - auc: 0.9996 - prc: 0.9992 - val_loss: 2.2525 - val_tp: 170.0000 - val_fp: 150.0000 - val_tn: 627.0000 - val_fn: 187.0000 - val_accuracy: 0.7028 - val_precision: 0.5312 - val_recall: 0.4762 - val_auc: 0.6840 - val_prc: 0.5067\n",
      "Epoch 97/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0194 - tp: 1400.0000 - fp: 23.0000 - tn: 3084.0000 - fn: 29.0000 - accuracy: 0.9885 - precision: 0.9838 - recall: 0.9797 - auc: 0.9997 - prc: 0.9993 - val_loss: 2.4573 - val_tp: 145.0000 - val_fp: 106.0000 - val_tn: 671.0000 - val_fn: 212.0000 - val_accuracy: 0.7196 - val_precision: 0.5777 - val_recall: 0.4062 - val_auc: 0.6649 - val_prc: 0.5069\n",
      "Epoch 98/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0210 - tp: 1389.0000 - fp: 22.0000 - tn: 3085.0000 - fn: 40.0000 - accuracy: 0.9863 - precision: 0.9844 - recall: 0.9720 - auc: 0.9996 - prc: 0.9991 - val_loss: 2.1659 - val_tp: 179.0000 - val_fp: 160.0000 - val_tn: 617.0000 - val_fn: 178.0000 - val_accuracy: 0.7019 - val_precision: 0.5280 - val_recall: 0.5014 - val_auc: 0.6870 - val_prc: 0.5088\n",
      "Epoch 99/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0197 - tp: 1398.0000 - fp: 27.0000 - tn: 3080.0000 - fn: 31.0000 - accuracy: 0.9872 - precision: 0.9811 - recall: 0.9783 - auc: 0.9997 - prc: 0.9993 - val_loss: 2.4600 - val_tp: 155.0000 - val_fp: 129.0000 - val_tn: 648.0000 - val_fn: 202.0000 - val_accuracy: 0.7081 - val_precision: 0.5458 - val_recall: 0.4342 - val_auc: 0.6742 - val_prc: 0.5092\n",
      "Epoch 100/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0202 - tp: 1398.0000 - fp: 27.0000 - tn: 3080.0000 - fn: 31.0000 - accuracy: 0.9872 - precision: 0.9811 - recall: 0.9783 - auc: 0.9996 - prc: 0.9992 - val_loss: 2.4366 - val_tp: 165.0000 - val_fp: 135.0000 - val_tn: 642.0000 - val_fn: 192.0000 - val_accuracy: 0.7116 - val_precision: 0.5500 - val_recall: 0.4622 - val_auc: 0.6759 - val_prc: 0.5034\n",
      "Epoch 101/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0199 - tp: 1398.0000 - fp: 25.0000 - tn: 3082.0000 - fn: 31.0000 - accuracy: 0.9877 - precision: 0.9824 - recall: 0.9783 - auc: 0.9997 - prc: 0.9993 - val_loss: 2.2538 - val_tp: 203.0000 - val_fp: 198.0000 - val_tn: 579.0000 - val_fn: 154.0000 - val_accuracy: 0.6896 - val_precision: 0.5062 - val_recall: 0.5686 - val_auc: 0.6886 - val_prc: 0.4971\n",
      "Epoch 102/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0206 - tp: 1399.0000 - fp: 30.0000 - tn: 3077.0000 - fn: 30.0000 - accuracy: 0.9868 - precision: 0.9790 - recall: 0.9790 - auc: 0.9996 - prc: 0.9992 - val_loss: 2.3497 - val_tp: 169.0000 - val_fp: 151.0000 - val_tn: 626.0000 - val_fn: 188.0000 - val_accuracy: 0.7011 - val_precision: 0.5281 - val_recall: 0.4734 - val_auc: 0.6801 - val_prc: 0.5011\n",
      "Epoch 103/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0197 - tp: 1396.0000 - fp: 22.0000 - tn: 3085.0000 - fn: 33.0000 - accuracy: 0.9879 - precision: 0.9845 - recall: 0.9769 - auc: 0.9997 - prc: 0.9993 - val_loss: 2.3317 - val_tp: 171.0000 - val_fp: 149.0000 - val_tn: 628.0000 - val_fn: 186.0000 - val_accuracy: 0.7046 - val_precision: 0.5344 - val_recall: 0.4790 - val_auc: 0.6796 - val_prc: 0.5025\n",
      "Epoch 104/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0196 - tp: 1397.0000 - fp: 28.0000 - tn: 3079.0000 - fn: 32.0000 - accuracy: 0.9868 - precision: 0.9804 - recall: 0.9776 - auc: 0.9997 - prc: 0.9993 - val_loss: 2.4253 - val_tp: 159.0000 - val_fp: 133.0000 - val_tn: 644.0000 - val_fn: 198.0000 - val_accuracy: 0.7081 - val_precision: 0.5445 - val_recall: 0.4454 - val_auc: 0.6742 - val_prc: 0.5007\n",
      "Epoch 105/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0193 - tp: 1399.0000 - fp: 22.0000 - tn: 3085.0000 - fn: 30.0000 - accuracy: 0.9885 - precision: 0.9845 - recall: 0.9790 - auc: 0.9997 - prc: 0.9993 - val_loss: 2.4703 - val_tp: 157.0000 - val_fp: 130.0000 - val_tn: 647.0000 - val_fn: 200.0000 - val_accuracy: 0.7090 - val_precision: 0.5470 - val_recall: 0.4398 - val_auc: 0.6759 - val_prc: 0.5073\n",
      "Epoch 106/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0195 - tp: 1397.0000 - fp: 24.0000 - tn: 3083.0000 - fn: 32.0000 - accuracy: 0.9877 - precision: 0.9831 - recall: 0.9776 - auc: 0.9996 - prc: 0.9992 - val_loss: 2.3988 - val_tp: 176.0000 - val_fp: 156.0000 - val_tn: 621.0000 - val_fn: 181.0000 - val_accuracy: 0.7028 - val_precision: 0.5301 - val_recall: 0.4930 - val_auc: 0.6821 - val_prc: 0.4998\n",
      "Epoch 107/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0188 - tp: 1404.0000 - fp: 24.0000 - tn: 3083.0000 - fn: 25.0000 - accuracy: 0.9892 - precision: 0.9832 - recall: 0.9825 - auc: 0.9997 - prc: 0.9993 - val_loss: 2.5751 - val_tp: 140.0000 - val_fp: 103.0000 - val_tn: 674.0000 - val_fn: 217.0000 - val_accuracy: 0.7178 - val_precision: 0.5761 - val_recall: 0.3922 - val_auc: 0.6644 - val_prc: 0.5010\n",
      "Epoch 108/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0200 - tp: 1398.0000 - fp: 23.0000 - tn: 3084.0000 - fn: 31.0000 - accuracy: 0.9881 - precision: 0.9838 - recall: 0.9783 - auc: 0.9996 - prc: 0.9993 - val_loss: 2.5093 - val_tp: 144.0000 - val_fp: 110.0000 - val_tn: 667.0000 - val_fn: 213.0000 - val_accuracy: 0.7152 - val_precision: 0.5669 - val_recall: 0.4034 - val_auc: 0.6668 - val_prc: 0.5027\n",
      "Epoch 109/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0196 - tp: 1399.0000 - fp: 24.0000 - tn: 3083.0000 - fn: 30.0000 - accuracy: 0.9881 - precision: 0.9831 - recall: 0.9790 - auc: 0.9997 - prc: 0.9993 - val_loss: 2.5004 - val_tp: 161.0000 - val_fp: 136.0000 - val_tn: 641.0000 - val_fn: 196.0000 - val_accuracy: 0.7072 - val_precision: 0.5421 - val_recall: 0.4510 - val_auc: 0.6726 - val_prc: 0.5006\n",
      "Epoch 110/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0184 - tp: 1392.0000 - fp: 17.0000 - tn: 3090.0000 - fn: 37.0000 - accuracy: 0.9881 - precision: 0.9879 - recall: 0.9741 - auc: 0.9997 - prc: 0.9994 - val_loss: 2.5545 - val_tp: 174.0000 - val_fp: 158.0000 - val_tn: 619.0000 - val_fn: 183.0000 - val_accuracy: 0.6993 - val_precision: 0.5241 - val_recall: 0.4874 - val_auc: 0.6790 - val_prc: 0.5000\n",
      "Epoch 111/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0180 - tp: 1400.0000 - fp: 22.0000 - tn: 3085.0000 - fn: 29.0000 - accuracy: 0.9888 - precision: 0.9845 - recall: 0.9797 - auc: 0.9997 - prc: 0.9994 - val_loss: 2.6425 - val_tp: 165.0000 - val_fp: 144.0000 - val_tn: 633.0000 - val_fn: 192.0000 - val_accuracy: 0.7037 - val_precision: 0.5340 - val_recall: 0.4622 - val_auc: 0.6754 - val_prc: 0.4990\n",
      "Epoch 112/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0184 - tp: 1394.0000 - fp: 18.0000 - tn: 3089.0000 - fn: 35.0000 - accuracy: 0.9883 - precision: 0.9873 - recall: 0.9755 - auc: 0.9997 - prc: 0.9993 - val_loss: 2.5351 - val_tp: 179.0000 - val_fp: 166.0000 - val_tn: 611.0000 - val_fn: 178.0000 - val_accuracy: 0.6966 - val_precision: 0.5188 - val_recall: 0.5014 - val_auc: 0.6796 - val_prc: 0.4965\n",
      "Epoch 113/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0182 - tp: 1403.0000 - fp: 22.0000 - tn: 3085.0000 - fn: 26.0000 - accuracy: 0.9894 - precision: 0.9846 - recall: 0.9818 - auc: 0.9997 - prc: 0.9994 - val_loss: 2.6089 - val_tp: 188.0000 - val_fp: 183.0000 - val_tn: 594.0000 - val_fn: 169.0000 - val_accuracy: 0.6896 - val_precision: 0.5067 - val_recall: 0.5266 - val_auc: 0.6811 - val_prc: 0.4945\n",
      "Epoch 114/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0192 - tp: 1401.0000 - fp: 30.0000 - tn: 3077.0000 - fn: 28.0000 - accuracy: 0.9872 - precision: 0.9790 - recall: 0.9804 - auc: 0.9996 - prc: 0.9992 - val_loss: 2.5692 - val_tp: 165.0000 - val_fp: 135.0000 - val_tn: 642.0000 - val_fn: 192.0000 - val_accuracy: 0.7116 - val_precision: 0.5500 - val_recall: 0.4622 - val_auc: 0.6749 - val_prc: 0.5023\n",
      "Epoch 115/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0183 - tp: 1398.0000 - fp: 26.0000 - tn: 3081.0000 - fn: 31.0000 - accuracy: 0.9874 - precision: 0.9817 - recall: 0.9783 - auc: 0.9997 - prc: 0.9993 - val_loss: 2.6011 - val_tp: 191.0000 - val_fp: 189.0000 - val_tn: 588.0000 - val_fn: 166.0000 - val_accuracy: 0.6869 - val_precision: 0.5026 - val_recall: 0.5350 - val_auc: 0.6815 - val_prc: 0.4905\n",
      "Epoch 116/200\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.0189 - tp: 1400.0000 - fp: 25.0000 - tn: 3082.0000 - fn: 29.0000 - accuracy: 0.9881 - precision: 0.9825 - recall: 0.9797 - auc: 0.9997 - prc: 0.9993 - val_loss: 2.5949 - val_tp: 178.0000 - val_fp: 158.0000 - val_tn: 619.0000 - val_fn: 179.0000 - val_accuracy: 0.7028 - val_precision: 0.5298 - val_recall: 0.4986 - val_auc: 0.6787 - val_prc: 0.4979\n",
      "Epoch 117/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0182 - tp: 1395.0000 - fp: 18.0000 - tn: 3089.0000 - fn: 34.0000 - accuracy: 0.9885 - precision: 0.9873 - recall: 0.9762 - auc: 0.9997 - prc: 0.9993 - val_loss: 2.6246 - val_tp: 159.0000 - val_fp: 136.0000 - val_tn: 641.0000 - val_fn: 198.0000 - val_accuracy: 0.7055 - val_precision: 0.5390 - val_recall: 0.4454 - val_auc: 0.6691 - val_prc: 0.4964\n",
      "Epoch 118/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0187 - tp: 1398.0000 - fp: 22.0000 - tn: 3085.0000 - fn: 31.0000 - accuracy: 0.9883 - precision: 0.9845 - recall: 0.9783 - auc: 0.9997 - prc: 0.9993 - val_loss: 2.7382 - val_tp: 158.0000 - val_fp: 131.0000 - val_tn: 646.0000 - val_fn: 199.0000 - val_accuracy: 0.7090 - val_precision: 0.5467 - val_recall: 0.4426 - val_auc: 0.6742 - val_prc: 0.5037\n",
      "Epoch 119/200\n",
      "71/71 [==============================] - 1s 7ms/step - loss: 0.0189 - tp: 1399.0000 - fp: 26.0000 - tn: 3081.0000 - fn: 30.0000 - accuracy: 0.9877 - precision: 0.9818 - recall: 0.9790 - auc: 0.9997 - prc: 0.9993 - val_loss: 2.7542 - val_tp: 152.0000 - val_fp: 125.0000 - val_tn: 652.0000 - val_fn: 205.0000 - val_accuracy: 0.7090 - val_precision: 0.5487 - val_recall: 0.4258 - val_auc: 0.6709 - val_prc: 0.5012\n",
      "Epoch 120/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0187 - tp: 1396.0000 - fp: 22.0000 - tn: 3085.0000 - fn: 33.0000 - accuracy: 0.9879 - precision: 0.9845 - recall: 0.9769 - auc: 0.9997 - prc: 0.9993 - val_loss: 2.8359 - val_tp: 192.0000 - val_fp: 188.0000 - val_tn: 589.0000 - val_fn: 165.0000 - val_accuracy: 0.6887 - val_precision: 0.5053 - val_recall: 0.5378 - val_auc: 0.6819 - val_prc: 0.4873\n",
      "Epoch 121/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0184 - tp: 1396.0000 - fp: 21.0000 - tn: 3086.0000 - fn: 33.0000 - accuracy: 0.9881 - precision: 0.9852 - recall: 0.9769 - auc: 0.9997 - prc: 0.9994 - val_loss: 2.7301 - val_tp: 185.0000 - val_fp: 177.0000 - val_tn: 600.0000 - val_fn: 172.0000 - val_accuracy: 0.6922 - val_precision: 0.5110 - val_recall: 0.5182 - val_auc: 0.6807 - val_prc: 0.4959\n",
      "Epoch 122/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0180 - tp: 1396.0000 - fp: 18.0000 - tn: 3089.0000 - fn: 33.0000 - accuracy: 0.9888 - precision: 0.9873 - recall: 0.9769 - auc: 0.9997 - prc: 0.9994 - val_loss: 2.7065 - val_tp: 185.0000 - val_fp: 167.0000 - val_tn: 610.0000 - val_fn: 172.0000 - val_accuracy: 0.7011 - val_precision: 0.5256 - val_recall: 0.5182 - val_auc: 0.6813 - val_prc: 0.4973\n",
      "Epoch 123/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0175 - tp: 1404.0000 - fp: 22.0000 - tn: 3085.0000 - fn: 25.0000 - accuracy: 0.9896 - precision: 0.9846 - recall: 0.9825 - auc: 0.9997 - prc: 0.9994 - val_loss: 2.9180 - val_tp: 141.0000 - val_fp: 109.0000 - val_tn: 668.0000 - val_fn: 216.0000 - val_accuracy: 0.7134 - val_precision: 0.5640 - val_recall: 0.3950 - val_auc: 0.6612 - val_prc: 0.4967\n",
      "Epoch 124/200\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.0188 - tp: 1391.0000 - fp: 17.0000 - tn: 3090.0000 - fn: 38.0000 - accuracy: 0.9879 - precision: 0.9879 - recall: 0.9734 - auc: 0.9997 - prc: 0.9993 - val_loss: 2.7613 - val_tp: 156.0000 - val_fp: 134.0000 - val_tn: 643.0000 - val_fn: 201.0000 - val_accuracy: 0.7046 - val_precision: 0.5379 - val_recall: 0.4370 - val_auc: 0.6711 - val_prc: 0.4975\n",
      "Epoch 125/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0178 - tp: 1393.0000 - fp: 14.0000 - tn: 3093.0000 - fn: 36.0000 - accuracy: 0.9890 - precision: 0.9900 - recall: 0.9748 - auc: 0.9997 - prc: 0.9994 - val_loss: 2.8568 - val_tp: 185.0000 - val_fp: 172.0000 - val_tn: 605.0000 - val_fn: 172.0000 - val_accuracy: 0.6966 - val_precision: 0.5182 - val_recall: 0.5182 - val_auc: 0.6791 - val_prc: 0.4920\n",
      "Epoch 126/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0182 - tp: 1395.0000 - fp: 20.0000 - tn: 3087.0000 - fn: 34.0000 - accuracy: 0.9881 - precision: 0.9859 - recall: 0.9762 - auc: 0.9997 - prc: 0.9993 - val_loss: 2.7021 - val_tp: 174.0000 - val_fp: 154.0000 - val_tn: 623.0000 - val_fn: 183.0000 - val_accuracy: 0.7028 - val_precision: 0.5305 - val_recall: 0.4874 - val_auc: 0.6759 - val_prc: 0.4927\n",
      "Epoch 127/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0178 - tp: 1399.0000 - fp: 25.0000 - tn: 3082.0000 - fn: 30.0000 - accuracy: 0.9879 - precision: 0.9824 - recall: 0.9790 - auc: 0.9997 - prc: 0.9993 - val_loss: 2.9317 - val_tp: 162.0000 - val_fp: 134.0000 - val_tn: 643.0000 - val_fn: 195.0000 - val_accuracy: 0.7099 - val_precision: 0.5473 - val_recall: 0.4538 - val_auc: 0.6738 - val_prc: 0.5019\n",
      "Epoch 128/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0174 - tp: 1395.0000 - fp: 12.0000 - tn: 3095.0000 - fn: 34.0000 - accuracy: 0.9899 - precision: 0.9915 - recall: 0.9762 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.0285 - val_tp: 170.0000 - val_fp: 148.0000 - val_tn: 629.0000 - val_fn: 187.0000 - val_accuracy: 0.7046 - val_precision: 0.5346 - val_recall: 0.4762 - val_auc: 0.6751 - val_prc: 0.4942\n",
      "Epoch 129/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0198 - tp: 1395.0000 - fp: 23.0000 - tn: 3084.0000 - fn: 34.0000 - accuracy: 0.9874 - precision: 0.9838 - recall: 0.9762 - auc: 0.9996 - prc: 0.9992 - val_loss: 2.7479 - val_tp: 182.0000 - val_fp: 165.0000 - val_tn: 612.0000 - val_fn: 175.0000 - val_accuracy: 0.7002 - val_precision: 0.5245 - val_recall: 0.5098 - val_auc: 0.6768 - val_prc: 0.4929\n",
      "Epoch 130/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0185 - tp: 1393.0000 - fp: 16.0000 - tn: 3091.0000 - fn: 36.0000 - accuracy: 0.9885 - precision: 0.9886 - recall: 0.9748 - auc: 0.9997 - prc: 0.9993 - val_loss: 2.9892 - val_tp: 152.0000 - val_fp: 127.0000 - val_tn: 650.0000 - val_fn: 205.0000 - val_accuracy: 0.7072 - val_precision: 0.5448 - val_recall: 0.4258 - val_auc: 0.6661 - val_prc: 0.4949\n",
      "Epoch 131/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0180 - tp: 1398.0000 - fp: 16.0000 - tn: 3091.0000 - fn: 31.0000 - accuracy: 0.9896 - precision: 0.9887 - recall: 0.9783 - auc: 0.9997 - prc: 0.9994 - val_loss: 2.8934 - val_tp: 164.0000 - val_fp: 144.0000 - val_tn: 633.0000 - val_fn: 193.0000 - val_accuracy: 0.7028 - val_precision: 0.5325 - val_recall: 0.4594 - val_auc: 0.6719 - val_prc: 0.4950\n",
      "Epoch 132/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0175 - tp: 1405.0000 - fp: 25.0000 - tn: 3082.0000 - fn: 24.0000 - accuracy: 0.9892 - precision: 0.9825 - recall: 0.9832 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.1181 - val_tp: 144.0000 - val_fp: 112.0000 - val_tn: 665.0000 - val_fn: 213.0000 - val_accuracy: 0.7134 - val_precision: 0.5625 - val_recall: 0.4034 - val_auc: 0.6564 - val_prc: 0.4928\n",
      "Epoch 133/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0175 - tp: 1397.0000 - fp: 24.0000 - tn: 3083.0000 - fn: 32.0000 - accuracy: 0.9877 - precision: 0.9831 - recall: 0.9776 - auc: 0.9997 - prc: 0.9993 - val_loss: 3.0160 - val_tp: 199.0000 - val_fp: 200.0000 - val_tn: 577.0000 - val_fn: 158.0000 - val_accuracy: 0.6843 - val_precision: 0.4987 - val_recall: 0.5574 - val_auc: 0.6860 - val_prc: 0.4908\n",
      "Epoch 134/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0176 - tp: 1399.0000 - fp: 23.0000 - tn: 3084.0000 - fn: 30.0000 - accuracy: 0.9883 - precision: 0.9838 - recall: 0.9790 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.0087 - val_tp: 190.0000 - val_fp: 183.0000 - val_tn: 594.0000 - val_fn: 167.0000 - val_accuracy: 0.6914 - val_precision: 0.5094 - val_recall: 0.5322 - val_auc: 0.6787 - val_prc: 0.4913\n",
      "Epoch 135/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0171 - tp: 1401.0000 - fp: 21.0000 - tn: 3086.0000 - fn: 28.0000 - accuracy: 0.9892 - precision: 0.9852 - recall: 0.9804 - auc: 0.9997 - prc: 0.9994 - val_loss: 2.9945 - val_tp: 184.0000 - val_fp: 171.0000 - val_tn: 606.0000 - val_fn: 173.0000 - val_accuracy: 0.6966 - val_precision: 0.5183 - val_recall: 0.5154 - val_auc: 0.6798 - val_prc: 0.4955\n",
      "Epoch 136/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0172 - tp: 1401.0000 - fp: 21.0000 - tn: 3086.0000 - fn: 28.0000 - accuracy: 0.9892 - precision: 0.9852 - recall: 0.9804 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.1003 - val_tp: 154.0000 - val_fp: 127.0000 - val_tn: 650.0000 - val_fn: 203.0000 - val_accuracy: 0.7090 - val_precision: 0.5480 - val_recall: 0.4314 - val_auc: 0.6645 - val_prc: 0.4950\n",
      "Epoch 137/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0176 - tp: 1398.0000 - fp: 19.0000 - tn: 3088.0000 - fn: 31.0000 - accuracy: 0.9890 - precision: 0.9866 - recall: 0.9783 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.2312 - val_tp: 215.0000 - val_fp: 226.0000 - val_tn: 551.0000 - val_fn: 142.0000 - val_accuracy: 0.6755 - val_precision: 0.4875 - val_recall: 0.6022 - val_auc: 0.6784 - val_prc: 0.4696\n",
      "Epoch 138/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0180 - tp: 1399.0000 - fp: 24.0000 - tn: 3083.0000 - fn: 30.0000 - accuracy: 0.9881 - precision: 0.9831 - recall: 0.9790 - auc: 0.9997 - prc: 0.9993 - val_loss: 3.1368 - val_tp: 171.0000 - val_fp: 158.0000 - val_tn: 619.0000 - val_fn: 186.0000 - val_accuracy: 0.6966 - val_precision: 0.5198 - val_recall: 0.4790 - val_auc: 0.6761 - val_prc: 0.4923\n",
      "Epoch 139/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0176 - tp: 1402.0000 - fp: 18.0000 - tn: 3089.0000 - fn: 27.0000 - accuracy: 0.9901 - precision: 0.9873 - recall: 0.9811 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.1115 - val_tp: 177.0000 - val_fp: 163.0000 - val_tn: 614.0000 - val_fn: 180.0000 - val_accuracy: 0.6975 - val_precision: 0.5206 - val_recall: 0.4958 - val_auc: 0.6801 - val_prc: 0.4956\n",
      "Epoch 140/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0180 - tp: 1396.0000 - fp: 17.0000 - tn: 3090.0000 - fn: 33.0000 - accuracy: 0.9890 - precision: 0.9880 - recall: 0.9769 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.0464 - val_tp: 175.0000 - val_fp: 161.0000 - val_tn: 616.0000 - val_fn: 182.0000 - val_accuracy: 0.6975 - val_precision: 0.5208 - val_recall: 0.4902 - val_auc: 0.6823 - val_prc: 0.4994\n",
      "Epoch 141/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0179 - tp: 1405.0000 - fp: 21.0000 - tn: 3086.0000 - fn: 24.0000 - accuracy: 0.9901 - precision: 0.9853 - recall: 0.9832 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.0062 - val_tp: 165.0000 - val_fp: 143.0000 - val_tn: 634.0000 - val_fn: 192.0000 - val_accuracy: 0.7046 - val_precision: 0.5357 - val_recall: 0.4622 - val_auc: 0.6727 - val_prc: 0.4930\n",
      "Epoch 142/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0173 - tp: 1399.0000 - fp: 17.0000 - tn: 3090.0000 - fn: 30.0000 - accuracy: 0.9896 - precision: 0.9880 - recall: 0.9790 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.2290 - val_tp: 153.0000 - val_fp: 128.0000 - val_tn: 649.0000 - val_fn: 204.0000 - val_accuracy: 0.7072 - val_precision: 0.5445 - val_recall: 0.4286 - val_auc: 0.6655 - val_prc: 0.4983\n",
      "Epoch 143/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0185 - tp: 1397.0000 - fp: 17.0000 - tn: 3090.0000 - fn: 32.0000 - accuracy: 0.9892 - precision: 0.9880 - recall: 0.9776 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.2087 - val_tp: 199.0000 - val_fp: 202.0000 - val_tn: 575.0000 - val_fn: 158.0000 - val_accuracy: 0.6825 - val_precision: 0.4963 - val_recall: 0.5574 - val_auc: 0.6803 - val_prc: 0.4762\n",
      "Epoch 144/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0179 - tp: 1403.0000 - fp: 26.0000 - tn: 3081.0000 - fn: 26.0000 - accuracy: 0.9885 - precision: 0.9818 - recall: 0.9818 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.1781 - val_tp: 151.0000 - val_fp: 124.0000 - val_tn: 653.0000 - val_fn: 206.0000 - val_accuracy: 0.7090 - val_precision: 0.5491 - val_recall: 0.4230 - val_auc: 0.6595 - val_prc: 0.4924\n",
      "Epoch 145/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0171 - tp: 1395.0000 - fp: 15.0000 - tn: 3092.0000 - fn: 34.0000 - accuracy: 0.9892 - precision: 0.9894 - recall: 0.9762 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.2998 - val_tp: 158.0000 - val_fp: 132.0000 - val_tn: 645.0000 - val_fn: 199.0000 - val_accuracy: 0.7081 - val_precision: 0.5448 - val_recall: 0.4426 - val_auc: 0.6654 - val_prc: 0.4946\n",
      "Epoch 146/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0170 - tp: 1399.0000 - fp: 19.0000 - tn: 3088.0000 - fn: 30.0000 - accuracy: 0.9892 - precision: 0.9866 - recall: 0.9790 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.2806 - val_tp: 161.0000 - val_fp: 141.0000 - val_tn: 636.0000 - val_fn: 196.0000 - val_accuracy: 0.7028 - val_precision: 0.5331 - val_recall: 0.4510 - val_auc: 0.6659 - val_prc: 0.4888\n",
      "Epoch 147/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0175 - tp: 1401.0000 - fp: 17.0000 - tn: 3090.0000 - fn: 28.0000 - accuracy: 0.9901 - precision: 0.9880 - recall: 0.9804 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.1743 - val_tp: 157.0000 - val_fp: 137.0000 - val_tn: 640.0000 - val_fn: 200.0000 - val_accuracy: 0.7028 - val_precision: 0.5340 - val_recall: 0.4398 - val_auc: 0.6640 - val_prc: 0.4912\n",
      "Epoch 148/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0175 - tp: 1397.0000 - fp: 24.0000 - tn: 3083.0000 - fn: 32.0000 - accuracy: 0.9877 - precision: 0.9831 - recall: 0.9776 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.2904 - val_tp: 163.0000 - val_fp: 138.0000 - val_tn: 639.0000 - val_fn: 194.0000 - val_accuracy: 0.7072 - val_precision: 0.5415 - val_recall: 0.4566 - val_auc: 0.6678 - val_prc: 0.4948\n",
      "Epoch 149/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0170 - tp: 1399.0000 - fp: 24.0000 - tn: 3083.0000 - fn: 30.0000 - accuracy: 0.9881 - precision: 0.9831 - recall: 0.9790 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.2708 - val_tp: 185.0000 - val_fp: 172.0000 - val_tn: 605.0000 - val_fn: 172.0000 - val_accuracy: 0.6966 - val_precision: 0.5182 - val_recall: 0.5182 - val_auc: 0.6812 - val_prc: 0.4898\n",
      "Epoch 150/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0177 - tp: 1404.0000 - fp: 23.0000 - tn: 3084.0000 - fn: 25.0000 - accuracy: 0.9894 - precision: 0.9839 - recall: 0.9825 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.3405 - val_tp: 169.0000 - val_fp: 147.0000 - val_tn: 630.0000 - val_fn: 188.0000 - val_accuracy: 0.7046 - val_precision: 0.5348 - val_recall: 0.4734 - val_auc: 0.6691 - val_prc: 0.4911\n",
      "Epoch 151/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0176 - tp: 1402.0000 - fp: 25.0000 - tn: 3082.0000 - fn: 27.0000 - accuracy: 0.9885 - precision: 0.9825 - recall: 0.9811 - auc: 0.9997 - prc: 0.9993 - val_loss: 3.2825 - val_tp: 155.0000 - val_fp: 130.0000 - val_tn: 647.0000 - val_fn: 202.0000 - val_accuracy: 0.7072 - val_precision: 0.5439 - val_recall: 0.4342 - val_auc: 0.6650 - val_prc: 0.4934\n",
      "Epoch 152/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0171 - tp: 1404.0000 - fp: 25.0000 - tn: 3082.0000 - fn: 25.0000 - accuracy: 0.9890 - precision: 0.9825 - recall: 0.9825 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.2712 - val_tp: 163.0000 - val_fp: 143.0000 - val_tn: 634.0000 - val_fn: 194.0000 - val_accuracy: 0.7028 - val_precision: 0.5327 - val_recall: 0.4566 - val_auc: 0.6666 - val_prc: 0.4893\n",
      "Epoch 153/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0169 - tp: 1407.0000 - fp: 27.0000 - tn: 3080.0000 - fn: 22.0000 - accuracy: 0.9892 - precision: 0.9812 - recall: 0.9846 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.4862 - val_tp: 146.0000 - val_fp: 112.0000 - val_tn: 665.0000 - val_fn: 211.0000 - val_accuracy: 0.7152 - val_precision: 0.5659 - val_recall: 0.4090 - val_auc: 0.6538 - val_prc: 0.4917\n",
      "Epoch 154/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0177 - tp: 1397.0000 - fp: 22.0000 - tn: 3085.0000 - fn: 32.0000 - accuracy: 0.9881 - precision: 0.9845 - recall: 0.9776 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.3241 - val_tp: 158.0000 - val_fp: 138.0000 - val_tn: 639.0000 - val_fn: 199.0000 - val_accuracy: 0.7028 - val_precision: 0.5338 - val_recall: 0.4426 - val_auc: 0.6612 - val_prc: 0.4839\n",
      "Epoch 155/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0172 - tp: 1398.0000 - fp: 20.0000 - tn: 3087.0000 - fn: 31.0000 - accuracy: 0.9888 - precision: 0.9859 - recall: 0.9783 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.2085 - val_tp: 177.0000 - val_fp: 165.0000 - val_tn: 612.0000 - val_fn: 180.0000 - val_accuracy: 0.6958 - val_precision: 0.5175 - val_recall: 0.4958 - val_auc: 0.6758 - val_prc: 0.4945\n",
      "Epoch 156/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0182 - tp: 1397.0000 - fp: 20.0000 - tn: 3087.0000 - fn: 32.0000 - accuracy: 0.9885 - precision: 0.9859 - recall: 0.9776 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.2960 - val_tp: 157.0000 - val_fp: 138.0000 - val_tn: 639.0000 - val_fn: 200.0000 - val_accuracy: 0.7019 - val_precision: 0.5322 - val_recall: 0.4398 - val_auc: 0.6661 - val_prc: 0.4909\n",
      "Epoch 157/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0175 - tp: 1403.0000 - fp: 21.0000 - tn: 3086.0000 - fn: 26.0000 - accuracy: 0.9896 - precision: 0.9853 - recall: 0.9818 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.3974 - val_tp: 172.0000 - val_fp: 153.0000 - val_tn: 624.0000 - val_fn: 185.0000 - val_accuracy: 0.7019 - val_precision: 0.5292 - val_recall: 0.4818 - val_auc: 0.6710 - val_prc: 0.4913\n",
      "Epoch 158/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0164 - tp: 1400.0000 - fp: 12.0000 - tn: 3095.0000 - fn: 29.0000 - accuracy: 0.9910 - precision: 0.9915 - recall: 0.9797 - auc: 0.9998 - prc: 0.9995 - val_loss: 3.4088 - val_tp: 173.0000 - val_fp: 153.0000 - val_tn: 624.0000 - val_fn: 184.0000 - val_accuracy: 0.7028 - val_precision: 0.5307 - val_recall: 0.4846 - val_auc: 0.6734 - val_prc: 0.4903\n",
      "Epoch 159/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0162 - tp: 1402.0000 - fp: 15.0000 - tn: 3092.0000 - fn: 27.0000 - accuracy: 0.9907 - precision: 0.9894 - recall: 0.9811 - auc: 0.9998 - prc: 0.9995 - val_loss: 3.5313 - val_tp: 173.0000 - val_fp: 151.0000 - val_tn: 626.0000 - val_fn: 184.0000 - val_accuracy: 0.7046 - val_precision: 0.5340 - val_recall: 0.4846 - val_auc: 0.6721 - val_prc: 0.4889\n",
      "Epoch 160/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0177 - tp: 1407.0000 - fp: 23.0000 - tn: 3084.0000 - fn: 22.0000 - accuracy: 0.9901 - precision: 0.9839 - recall: 0.9846 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.3781 - val_tp: 182.0000 - val_fp: 177.0000 - val_tn: 600.0000 - val_fn: 175.0000 - val_accuracy: 0.6896 - val_precision: 0.5070 - val_recall: 0.5098 - val_auc: 0.6760 - val_prc: 0.4829\n",
      "Epoch 161/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0165 - tp: 1399.0000 - fp: 20.0000 - tn: 3087.0000 - fn: 30.0000 - accuracy: 0.9890 - precision: 0.9859 - recall: 0.9790 - auc: 0.9997 - prc: 0.9995 - val_loss: 3.5229 - val_tp: 156.0000 - val_fp: 131.0000 - val_tn: 646.0000 - val_fn: 201.0000 - val_accuracy: 0.7072 - val_precision: 0.5436 - val_recall: 0.4370 - val_auc: 0.6628 - val_prc: 0.4885\n",
      "Epoch 162/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0169 - tp: 1395.0000 - fp: 14.0000 - tn: 3093.0000 - fn: 34.0000 - accuracy: 0.9894 - precision: 0.9901 - recall: 0.9762 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.4784 - val_tp: 160.0000 - val_fp: 134.0000 - val_tn: 643.0000 - val_fn: 197.0000 - val_accuracy: 0.7081 - val_precision: 0.5442 - val_recall: 0.4482 - val_auc: 0.6654 - val_prc: 0.4912\n",
      "Epoch 163/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0165 - tp: 1401.0000 - fp: 19.0000 - tn: 3088.0000 - fn: 28.0000 - accuracy: 0.9896 - precision: 0.9866 - recall: 0.9804 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.7595 - val_tp: 143.0000 - val_fp: 114.0000 - val_tn: 663.0000 - val_fn: 214.0000 - val_accuracy: 0.7108 - val_precision: 0.5564 - val_recall: 0.4006 - val_auc: 0.6540 - val_prc: 0.4873\n",
      "Epoch 164/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0175 - tp: 1395.0000 - fp: 21.0000 - tn: 3086.0000 - fn: 34.0000 - accuracy: 0.9879 - precision: 0.9852 - recall: 0.9762 - auc: 0.9997 - prc: 0.9993 - val_loss: 3.4196 - val_tp: 178.0000 - val_fp: 166.0000 - val_tn: 611.0000 - val_fn: 179.0000 - val_accuracy: 0.6958 - val_precision: 0.5174 - val_recall: 0.4986 - val_auc: 0.6754 - val_prc: 0.4904\n",
      "Epoch 165/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0169 - tp: 1395.0000 - fp: 21.0000 - tn: 3086.0000 - fn: 34.0000 - accuracy: 0.9879 - precision: 0.9852 - recall: 0.9762 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.4052 - val_tp: 175.0000 - val_fp: 162.0000 - val_tn: 615.0000 - val_fn: 182.0000 - val_accuracy: 0.6966 - val_precision: 0.5193 - val_recall: 0.4902 - val_auc: 0.6732 - val_prc: 0.4902\n",
      "Epoch 166/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0167 - tp: 1396.0000 - fp: 16.0000 - tn: 3091.0000 - fn: 33.0000 - accuracy: 0.9892 - precision: 0.9887 - recall: 0.9769 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.4860 - val_tp: 164.0000 - val_fp: 149.0000 - val_tn: 628.0000 - val_fn: 193.0000 - val_accuracy: 0.6984 - val_precision: 0.5240 - val_recall: 0.4594 - val_auc: 0.6690 - val_prc: 0.4904\n",
      "Epoch 167/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0172 - tp: 1399.0000 - fp: 15.0000 - tn: 3092.0000 - fn: 30.0000 - accuracy: 0.9901 - precision: 0.9894 - recall: 0.9790 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.4867 - val_tp: 191.0000 - val_fp: 186.0000 - val_tn: 591.0000 - val_fn: 166.0000 - val_accuracy: 0.6896 - val_precision: 0.5066 - val_recall: 0.5350 - val_auc: 0.6800 - val_prc: 0.4824\n",
      "Epoch 168/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0172 - tp: 1402.0000 - fp: 15.0000 - tn: 3092.0000 - fn: 27.0000 - accuracy: 0.9907 - precision: 0.9894 - recall: 0.9811 - auc: 0.9998 - prc: 0.9995 - val_loss: 3.6242 - val_tp: 188.0000 - val_fp: 186.0000 - val_tn: 591.0000 - val_fn: 169.0000 - val_accuracy: 0.6869 - val_precision: 0.5027 - val_recall: 0.5266 - val_auc: 0.6754 - val_prc: 0.4742\n",
      "Epoch 169/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0164 - tp: 1398.0000 - fp: 17.0000 - tn: 3090.0000 - fn: 31.0000 - accuracy: 0.9894 - precision: 0.9880 - recall: 0.9783 - auc: 0.9997 - prc: 0.9995 - val_loss: 3.7021 - val_tp: 157.0000 - val_fp: 134.0000 - val_tn: 643.0000 - val_fn: 200.0000 - val_accuracy: 0.7055 - val_precision: 0.5395 - val_recall: 0.4398 - val_auc: 0.6606 - val_prc: 0.4894\n",
      "Epoch 170/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0163 - tp: 1396.0000 - fp: 19.0000 - tn: 3088.0000 - fn: 33.0000 - accuracy: 0.9885 - precision: 0.9866 - recall: 0.9769 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.5621 - val_tp: 176.0000 - val_fp: 169.0000 - val_tn: 608.0000 - val_fn: 181.0000 - val_accuracy: 0.6914 - val_precision: 0.5101 - val_recall: 0.4930 - val_auc: 0.6735 - val_prc: 0.4866\n",
      "Epoch 171/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0169 - tp: 1402.0000 - fp: 19.0000 - tn: 3088.0000 - fn: 27.0000 - accuracy: 0.9899 - precision: 0.9866 - recall: 0.9811 - auc: 0.9997 - prc: 0.9995 - val_loss: 3.6818 - val_tp: 153.0000 - val_fp: 125.0000 - val_tn: 652.0000 - val_fn: 204.0000 - val_accuracy: 0.7099 - val_precision: 0.5504 - val_recall: 0.4286 - val_auc: 0.6576 - val_prc: 0.4885\n",
      "Epoch 172/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0169 - tp: 1398.0000 - fp: 18.0000 - tn: 3089.0000 - fn: 31.0000 - accuracy: 0.9892 - precision: 0.9873 - recall: 0.9783 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.6961 - val_tp: 163.0000 - val_fp: 140.0000 - val_tn: 637.0000 - val_fn: 194.0000 - val_accuracy: 0.7055 - val_precision: 0.5380 - val_recall: 0.4566 - val_auc: 0.6653 - val_prc: 0.4875\n",
      "Epoch 173/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0161 - tp: 1396.0000 - fp: 18.0000 - tn: 3089.0000 - fn: 33.0000 - accuracy: 0.9888 - precision: 0.9873 - recall: 0.9769 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.8265 - val_tp: 136.0000 - val_fp: 109.0000 - val_tn: 668.0000 - val_fn: 221.0000 - val_accuracy: 0.7090 - val_precision: 0.5551 - val_recall: 0.3810 - val_auc: 0.6547 - val_prc: 0.4905\n",
      "Epoch 174/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0172 - tp: 1400.0000 - fp: 16.0000 - tn: 3091.0000 - fn: 29.0000 - accuracy: 0.9901 - precision: 0.9887 - recall: 0.9797 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.7366 - val_tp: 196.0000 - val_fp: 195.0000 - val_tn: 582.0000 - val_fn: 161.0000 - val_accuracy: 0.6861 - val_precision: 0.5013 - val_recall: 0.5490 - val_auc: 0.6783 - val_prc: 0.4719\n",
      "Epoch 175/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0166 - tp: 1401.0000 - fp: 17.0000 - tn: 3090.0000 - fn: 28.0000 - accuracy: 0.9901 - precision: 0.9880 - recall: 0.9804 - auc: 0.9997 - prc: 0.9995 - val_loss: 3.7639 - val_tp: 161.0000 - val_fp: 139.0000 - val_tn: 638.0000 - val_fn: 196.0000 - val_accuracy: 0.7046 - val_precision: 0.5367 - val_recall: 0.4510 - val_auc: 0.6666 - val_prc: 0.4899\n",
      "Epoch 176/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0171 - tp: 1396.0000 - fp: 23.0000 - tn: 3084.0000 - fn: 33.0000 - accuracy: 0.9877 - precision: 0.9838 - recall: 0.9769 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.6635 - val_tp: 155.0000 - val_fp: 126.0000 - val_tn: 651.0000 - val_fn: 202.0000 - val_accuracy: 0.7108 - val_precision: 0.5516 - val_recall: 0.4342 - val_auc: 0.6659 - val_prc: 0.4911\n",
      "Epoch 177/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0163 - tp: 1398.0000 - fp: 18.0000 - tn: 3089.0000 - fn: 31.0000 - accuracy: 0.9892 - precision: 0.9873 - recall: 0.9783 - auc: 0.9997 - prc: 0.9995 - val_loss: 3.8071 - val_tp: 154.0000 - val_fp: 129.0000 - val_tn: 648.0000 - val_fn: 203.0000 - val_accuracy: 0.7072 - val_precision: 0.5442 - val_recall: 0.4314 - val_auc: 0.6605 - val_prc: 0.4892\n",
      "Epoch 178/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0172 - tp: 1393.0000 - fp: 17.0000 - tn: 3090.0000 - fn: 36.0000 - accuracy: 0.9883 - precision: 0.9879 - recall: 0.9748 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.6668 - val_tp: 165.0000 - val_fp: 141.0000 - val_tn: 636.0000 - val_fn: 192.0000 - val_accuracy: 0.7063 - val_precision: 0.5392 - val_recall: 0.4622 - val_auc: 0.6665 - val_prc: 0.4875\n",
      "Epoch 179/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0171 - tp: 1398.0000 - fp: 19.0000 - tn: 3088.0000 - fn: 31.0000 - accuracy: 0.9890 - precision: 0.9866 - recall: 0.9783 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.6899 - val_tp: 168.0000 - val_fp: 152.0000 - val_tn: 625.0000 - val_fn: 189.0000 - val_accuracy: 0.6993 - val_precision: 0.5250 - val_recall: 0.4706 - val_auc: 0.6681 - val_prc: 0.4861\n",
      "Epoch 180/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0168 - tp: 1396.0000 - fp: 15.0000 - tn: 3092.0000 - fn: 33.0000 - accuracy: 0.9894 - precision: 0.9894 - recall: 0.9769 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.7178 - val_tp: 169.0000 - val_fp: 151.0000 - val_tn: 626.0000 - val_fn: 188.0000 - val_accuracy: 0.7011 - val_precision: 0.5281 - val_recall: 0.4734 - val_auc: 0.6706 - val_prc: 0.4884\n",
      "Epoch 181/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0170 - tp: 1396.0000 - fp: 13.0000 - tn: 3094.0000 - fn: 33.0000 - accuracy: 0.9899 - precision: 0.9908 - recall: 0.9769 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.7397 - val_tp: 181.0000 - val_fp: 165.0000 - val_tn: 612.0000 - val_fn: 176.0000 - val_accuracy: 0.6993 - val_precision: 0.5231 - val_recall: 0.5070 - val_auc: 0.6724 - val_prc: 0.4836\n",
      "Epoch 182/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0171 - tp: 1398.0000 - fp: 11.0000 - tn: 3096.0000 - fn: 31.0000 - accuracy: 0.9907 - precision: 0.9922 - recall: 0.9783 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.7246 - val_tp: 191.0000 - val_fp: 184.0000 - val_tn: 593.0000 - val_fn: 166.0000 - val_accuracy: 0.6914 - val_precision: 0.5093 - val_recall: 0.5350 - val_auc: 0.6781 - val_prc: 0.4765\n",
      "Epoch 183/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0172 - tp: 1400.0000 - fp: 18.0000 - tn: 3089.0000 - fn: 29.0000 - accuracy: 0.9896 - precision: 0.9873 - recall: 0.9797 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.9054 - val_tp: 145.0000 - val_fp: 112.0000 - val_tn: 665.0000 - val_fn: 212.0000 - val_accuracy: 0.7143 - val_precision: 0.5642 - val_recall: 0.4062 - val_auc: 0.6594 - val_prc: 0.4933\n",
      "Epoch 184/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0168 - tp: 1399.0000 - fp: 11.0000 - tn: 3096.0000 - fn: 30.0000 - accuracy: 0.9910 - precision: 0.9922 - recall: 0.9790 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.8750 - val_tp: 164.0000 - val_fp: 143.0000 - val_tn: 634.0000 - val_fn: 193.0000 - val_accuracy: 0.7037 - val_precision: 0.5342 - val_recall: 0.4594 - val_auc: 0.6658 - val_prc: 0.4885\n",
      "Epoch 185/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0166 - tp: 1392.0000 - fp: 10.0000 - tn: 3097.0000 - fn: 37.0000 - accuracy: 0.9896 - precision: 0.9929 - recall: 0.9741 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.8127 - val_tp: 185.0000 - val_fp: 171.0000 - val_tn: 606.0000 - val_fn: 172.0000 - val_accuracy: 0.6975 - val_precision: 0.5197 - val_recall: 0.5182 - val_auc: 0.6733 - val_prc: 0.4820\n",
      "Epoch 186/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0165 - tp: 1397.0000 - fp: 11.0000 - tn: 3096.0000 - fn: 32.0000 - accuracy: 0.9905 - precision: 0.9922 - recall: 0.9776 - auc: 0.9997 - prc: 0.9995 - val_loss: 3.8400 - val_tp: 163.0000 - val_fp: 138.0000 - val_tn: 639.0000 - val_fn: 194.0000 - val_accuracy: 0.7072 - val_precision: 0.5415 - val_recall: 0.4566 - val_auc: 0.6663 - val_prc: 0.4901\n",
      "Epoch 187/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0164 - tp: 1397.0000 - fp: 16.0000 - tn: 3091.0000 - fn: 32.0000 - accuracy: 0.9894 - precision: 0.9887 - recall: 0.9776 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.9201 - val_tp: 152.0000 - val_fp: 124.0000 - val_tn: 653.0000 - val_fn: 205.0000 - val_accuracy: 0.7099 - val_precision: 0.5507 - val_recall: 0.4258 - val_auc: 0.6633 - val_prc: 0.4912\n",
      "Epoch 188/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0169 - tp: 1397.0000 - fp: 17.0000 - tn: 3090.0000 - fn: 32.0000 - accuracy: 0.9892 - precision: 0.9880 - recall: 0.9776 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.6814 - val_tp: 178.0000 - val_fp: 160.0000 - val_tn: 617.0000 - val_fn: 179.0000 - val_accuracy: 0.7011 - val_precision: 0.5266 - val_recall: 0.4986 - val_auc: 0.6717 - val_prc: 0.4862\n",
      "Epoch 189/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0164 - tp: 1395.0000 - fp: 17.0000 - tn: 3090.0000 - fn: 34.0000 - accuracy: 0.9888 - precision: 0.9880 - recall: 0.9762 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.8358 - val_tp: 189.0000 - val_fp: 184.0000 - val_tn: 593.0000 - val_fn: 168.0000 - val_accuracy: 0.6896 - val_precision: 0.5067 - val_recall: 0.5294 - val_auc: 0.6694 - val_prc: 0.4698\n",
      "Epoch 190/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0157 - tp: 1401.0000 - fp: 19.0000 - tn: 3088.0000 - fn: 28.0000 - accuracy: 0.9896 - precision: 0.9866 - recall: 0.9804 - auc: 0.9998 - prc: 0.9995 - val_loss: 4.0681 - val_tp: 155.0000 - val_fp: 129.0000 - val_tn: 648.0000 - val_fn: 202.0000 - val_accuracy: 0.7081 - val_precision: 0.5458 - val_recall: 0.4342 - val_auc: 0.6599 - val_prc: 0.4849\n",
      "Epoch 191/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0169 - tp: 1395.0000 - fp: 9.0000 - tn: 3098.0000 - fn: 34.0000 - accuracy: 0.9905 - precision: 0.9936 - recall: 0.9762 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.9724 - val_tp: 172.0000 - val_fp: 154.0000 - val_tn: 623.0000 - val_fn: 185.0000 - val_accuracy: 0.7011 - val_precision: 0.5276 - val_recall: 0.4818 - val_auc: 0.6644 - val_prc: 0.4800\n",
      "Epoch 192/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0164 - tp: 1392.0000 - fp: 11.0000 - tn: 3096.0000 - fn: 37.0000 - accuracy: 0.9894 - precision: 0.9922 - recall: 0.9741 - auc: 0.9997 - prc: 0.9994 - val_loss: 3.9063 - val_tp: 175.0000 - val_fp: 159.0000 - val_tn: 618.0000 - val_fn: 182.0000 - val_accuracy: 0.6993 - val_precision: 0.5240 - val_recall: 0.4902 - val_auc: 0.6671 - val_prc: 0.4808\n",
      "Epoch 193/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0160 - tp: 1398.0000 - fp: 15.0000 - tn: 3092.0000 - fn: 31.0000 - accuracy: 0.9899 - precision: 0.9894 - recall: 0.9783 - auc: 0.9998 - prc: 0.9995 - val_loss: 4.0227 - val_tp: 169.0000 - val_fp: 154.0000 - val_tn: 623.0000 - val_fn: 188.0000 - val_accuracy: 0.6984 - val_precision: 0.5232 - val_recall: 0.4734 - val_auc: 0.6623 - val_prc: 0.4782\n",
      "Epoch 194/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0163 - tp: 1401.0000 - fp: 11.0000 - tn: 3096.0000 - fn: 28.0000 - accuracy: 0.9914 - precision: 0.9922 - recall: 0.9804 - auc: 0.9998 - prc: 0.9995 - val_loss: 3.9066 - val_tp: 178.0000 - val_fp: 163.0000 - val_tn: 614.0000 - val_fn: 179.0000 - val_accuracy: 0.6984 - val_precision: 0.5220 - val_recall: 0.4986 - val_auc: 0.6659 - val_prc: 0.4812\n",
      "Epoch 195/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0163 - tp: 1398.0000 - fp: 12.0000 - tn: 3095.0000 - fn: 31.0000 - accuracy: 0.9905 - precision: 0.9915 - recall: 0.9783 - auc: 0.9997 - prc: 0.9994 - val_loss: 4.0727 - val_tp: 157.0000 - val_fp: 139.0000 - val_tn: 638.0000 - val_fn: 200.0000 - val_accuracy: 0.7011 - val_precision: 0.5304 - val_recall: 0.4398 - val_auc: 0.6616 - val_prc: 0.4833\n",
      "Epoch 196/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0165 - tp: 1397.0000 - fp: 19.0000 - tn: 3088.0000 - fn: 32.0000 - accuracy: 0.9888 - precision: 0.9866 - recall: 0.9776 - auc: 0.9997 - prc: 0.9994 - val_loss: 4.0478 - val_tp: 159.0000 - val_fp: 141.0000 - val_tn: 636.0000 - val_fn: 198.0000 - val_accuracy: 0.7011 - val_precision: 0.5300 - val_recall: 0.4454 - val_auc: 0.6588 - val_prc: 0.4796\n",
      "Epoch 197/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0163 - tp: 1398.0000 - fp: 14.0000 - tn: 3093.0000 - fn: 31.0000 - accuracy: 0.9901 - precision: 0.9901 - recall: 0.9783 - auc: 0.9997 - prc: 0.9994 - val_loss: 4.0220 - val_tp: 185.0000 - val_fp: 170.0000 - val_tn: 607.0000 - val_fn: 172.0000 - val_accuracy: 0.6984 - val_precision: 0.5211 - val_recall: 0.5182 - val_auc: 0.6706 - val_prc: 0.4787\n",
      "Epoch 198/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0163 - tp: 1394.0000 - fp: 16.0000 - tn: 3091.0000 - fn: 35.0000 - accuracy: 0.9888 - precision: 0.9887 - recall: 0.9755 - auc: 0.9997 - prc: 0.9994 - val_loss: 4.0598 - val_tp: 154.0000 - val_fp: 132.0000 - val_tn: 645.0000 - val_fn: 203.0000 - val_accuracy: 0.7046 - val_precision: 0.5385 - val_recall: 0.4314 - val_auc: 0.6582 - val_prc: 0.4800\n",
      "Epoch 199/200\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 0.0162 - tp: 1399.0000 - fp: 15.0000 - tn: 3092.0000 - fn: 30.0000 - accuracy: 0.9901 - precision: 0.9894 - recall: 0.9790 - auc: 0.9997 - prc: 0.9995 - val_loss: 4.0446 - val_tp: 187.0000 - val_fp: 174.0000 - val_tn: 603.0000 - val_fn: 170.0000 - val_accuracy: 0.6966 - val_precision: 0.5180 - val_recall: 0.5238 - val_auc: 0.6661 - val_prc: 0.4705\n",
      "Epoch 200/200\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 0.0168 - tp: 1398.0000 - fp: 16.0000 - tn: 3091.0000 - fn: 31.0000 - accuracy: 0.9896 - precision: 0.9887 - recall: 0.9783 - auc: 0.9997 - prc: 0.9994 - val_loss: 4.2391 - val_tp: 138.0000 - val_fp: 97.0000 - val_tn: 680.0000 - val_fn: 219.0000 - val_accuracy: 0.7213 - val_precision: 0.5872 - val_recall: 0.3866 - val_auc: 0.6488 - val_prc: 0.4836\n"
     ]
    }
   ],
   "source": [
    "# Deep learnig Model\n",
    "def nn_builder(text_vectorizer):\n",
    "    nn = Sequential()\n",
    "    nn.add(Input(shape=(1,), dtype=\"string\"))\n",
    "    nn.add(text_vectorizer)\n",
    "    nn.add(Dense(1500, activation=\"relu\"))\n",
    "    nn.add(Dense(500, activation=\"relu\"))\n",
    "    nn.add(Dropout(0.40))\n",
    "    nn.add(Dense(1, activation=\"sigmoid\"))\n",
    "    nn.compile(loss=experiment_parameters['loss'],\n",
    "               optimizer=experiment_parameters['optimizer'],\n",
    "               metrics=METRICS)\n",
    "    return nn\n",
    "\n",
    "\n",
    "deep_model = nn_builder(tfidf_vectorizer)\n",
    "\n",
    "history = deep_model.fit(X_train, y_train,\n",
    "                         experiment_parameters['batch_size'],\n",
    "                         experiment_parameters['epochs'],\n",
    "                         validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.756396</td>\n",
       "      <td>0.587234</td>\n",
       "      <td>0.72134</td>\n",
       "      <td>0.671815</td>\n",
       "      <td>0.703141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.875161</td>\n",
       "      <td>0.386555</td>\n",
       "      <td>0.72134</td>\n",
       "      <td>0.630858</td>\n",
       "      <td>0.721340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.811456</td>\n",
       "      <td>0.466216</td>\n",
       "      <td>0.72134</td>\n",
       "      <td>0.638836</td>\n",
       "      <td>0.702769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>777.000000</td>\n",
       "      <td>357.000000</td>\n",
       "      <td>0.72134</td>\n",
       "      <td>1134.000000</td>\n",
       "      <td>1134.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0           1  accuracy    macro avg  weighted avg\n",
       "precision    0.756396    0.587234   0.72134     0.671815      0.703141\n",
       "recall       0.875161    0.386555   0.72134     0.630858      0.721340\n",
       "f1-score     0.811456    0.466216   0.72134     0.638836      0.702769\n",
       "support    777.000000  357.000000   0.72134  1134.000000   1134.000000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds = deep_model.predict(X_test)\n",
    "pd.DataFrame(classification_report(\n",
    "    y_test, np.where(test_preds >= 0.5, 1, 0), output_dict=True))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('hate-seepch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7304d3c1a35396b9e299acc644b89f0e56d4154029b20ed6ab08effb23ac070c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
